Domain,Query_Year,Rank_in_Year,Title,Citations,ArXiv_ID,URL,Authors,Abstract
AI (cs.AI),2019,2,"Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI",7377,1910.10045,https://www.semanticscholar.org/paper/530a059cb48477ad1e3d4f8f4b153274c8997332,"Alejandro Barredo Arrieta, Natalia Díaz Rodríguez, J. Ser et al.",No Abstract
AI (cs.AI),2019,1,High-performance medicine: the convergence of human and artificial intelligence,5534,N/A,https://www.semanticscholar.org/paper/f134abeaf9bfd41f29b97aec675ec31895bf541d,E. Topol,No Abstract
AI (cs.AI),2019,3,Systematic review of research on artificial intelligence applications in higher education – where are the educators?,3142,N/A,https://www.semanticscholar.org/paper/04de4d9eb0d53025c8ab6c99d1e743f4c1bc1eb6,"Olaf Zawacki-Richter, Victoria I. Marín, Melissa Bond et al.","According to various international reports, Artificial Intelligence in Education (AIEd) is one of the currently emerging fields in educational technology. Whilst it has been around for about 30 years, it is still unclear for educators how to make pedagogical advantage of it on a broader scale, and how it can actually impact meaningfully on teaching and learning in higher education. This paper seeks to provide an overview of research on AI applications in higher education through a systematic review. Out of 2656 initially identified publications for the period between 2007 and 2018, 146 articles were included for final synthesis, according to explicit inclusion and exclusion criteria. The descriptive results show that most of the disciplines involved in AIEd papers come from Computer Science and STEM, and that quantitative methods were the most frequently used in empirical studies. The synthesis of results presents four areas of AIEd applications in academic support services, and institutional and administrative services: 1. profiling and prediction, 2. assessment and evaluation, 3. adaptive systems and personalisation, and 4. intelligent tutoring systems. The conclusions reflect on the almost lack of critical reflection of challenges and risks of AIEd, the weak connection to theoretical pedagogical perspectives, and the need for further exploration of ethical and educational approaches in the application of AIEd in higher education."
AI (cs.AI),2019,5,"Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",2793,N/A,https://www.semanticscholar.org/paper/6a132499ca1dc0d23cfe7d5db841b819df63b51b,"Yogesh Kumar Dwivedi, Laurie Hughes, Elvira Ismagilova et al.",No Abstract
AI (cs.AI),2019,4,The potential for artificial intelligence in healthcare,2491,N/A,https://www.semanticscholar.org/paper/ddf4172cad889f178c2db9b1b6302b3c7d5c0147,"T. Davenport, R. Kalakota","ABSTRACT The complexity and rise of data in healthcare means that artificial intelligence (AI) will increasingly be applied within the field. Several types of AI are already being employed by payers and providers of care, and life sciences companies. The key categories of applications involve diagnosis and treatment recommendations, patient engagement and adherence, and administrative activities. Although there are many instances in which AI can perform healthcare tasks as well or better than humans, implementation factors will prevent large-scale automation of healthcare professional jobs for a considerable period. Ethical issues in the application of AI to healthcare are also discussed."
AI (cs.AI),2019,6,Artificial Intelligence: the global landscape of ethics guidelines,2080,1906.11668,https://www.semanticscholar.org/paper/7bf47af1f989c1a999d7dab24d86d19f13e8ba55,"Anna Jobin, M. Ienca, E. Vayena","In the last five years, private companies, research institutions as well as public sector organisations have issued principles and guidelines for ethical AI, yet there is debate about both what constitutes ""ethical AI"" and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analyzed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies."
AI (cs.AI),2019,14,"Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence",2011,N/A,https://www.semanticscholar.org/paper/da75921084a1fe49c43023fe5a2b15cb2b9a36e8,"A. Kaplan, M. Haenlein",No Abstract
AI (cs.AI),2019,19,"Artificial intelligence for decision making in the era of Big Data - evolution, challenges and research agenda",1817,N/A,https://www.semanticscholar.org/paper/0574a3abc98f0e6bd035a4ff4ea107cfba45d3d4,"Y. Duan, J. Edwards, Yogesh Kumar Dwivedi",No Abstract
AI (cs.AI),2019,7,The role of artificial intelligence in achieving the Sustainable Development Goals,1789,1905.00501,https://www.semanticscholar.org/paper/3ce5a172a96008cbdc5ffedf4572b783301fd468,"Ricardo Vinuesa, Hossein Azizpour, Iolanda Leite et al.","The emergence of artificial intelligence (AI) and its progressively wider impact on many sectors requires an assessment of its effect on the achievement of the Sustainable Development Goals. Using a consensus-based expert elicitation process, we find that AI can enable the accomplishment of 134 targets across all the goals, but it may also inhibit 59 targets. However, current research foci overlook important aspects. The fast development of AI needs to be supported by the necessary regulatory insight and oversight for AI-based technologies to enable sustainable development. Failure to do so could result in gaps in transparency, safety, and ethical standards. Artificial intelligence (AI) is becoming more and more common in people’s lives. Here, the authors use an expert elicitation method to understand how AI may affect the achievement of the Sustainable Development Goals."
AI (cs.AI),2019,16,Key challenges for delivering clinical impact with artificial intelligence,1743,N/A,https://www.semanticscholar.org/paper/f1bc43932beb14a00cd47feac4e40951601dd7a9,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman et al.","BackgroundArtificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice.Main bodyKey challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes.ConclusionThe safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational."
AI (cs.AI),2019,11,A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI,1735,1907.07374,https://www.semanticscholar.org/paper/38f23fe236b152cd4983c8f30d305a568afd0d3e,"Erico Tjoa, Cuntai Guan","Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged."
AI (cs.AI),2019,10,The practical implementation of artificial intelligence technologies in medicine,1662,N/A,https://www.semanticscholar.org/paper/d55e70a42579c7895938b6c43736163dbaf55145,"J. He, Sally L. Baxter, Jie Xu et al.",No Abstract
AI (cs.AI),2019,8,Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing,1613,1905.10083,https://www.semanticscholar.org/paper/928cd808aba140ec298508df87c5579811ff2f41,"Zhi Zhou, Xu Chen, En Li et al.","With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI."
AI (cs.AI),2019,9,"A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence",1580,N/A,https://www.semanticscholar.org/paper/8b835a6dedd55e57c2d5328b94b839faa25faca8,"M. Haenlein, A. Kaplan","This introduction to this special issue discusses artificial intelligence (AI), commonly defined as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.” It summarizes seven articles published in this special issue that present a wide variety of perspectives on AI, authored by several of the world’s leading experts and specialists in AI. It concludes by offering a comprehensive outlook on the future of AI, drawing on micro-, meso-, and macro-perspectives."
AI (cs.AI),2019,15,XAI—Explainable artificial intelligence,1495,N/A,https://www.semanticscholar.org/paper/f7774f83d0dca26b0403fc76912af3484eb6c4b7,"David Gunning, M. Stefik, Jaesik Choi et al.","Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications. Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications."
AI (cs.AI),2019,13,How artificial intelligence will change the future of marketing,1457,N/A,https://www.semanticscholar.org/paper/1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7,"T. Davenport, Abhijit Guha, Dhruv Grewal et al.","In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors. Building from not only extant research but also extensive interactions with practice, the authors propose a multidimensional framework for understanding the impact of AI involving intelligence levels, task types, and whether AI is embedded in a robot. Prior research typically addresses a subset of these dimensions; this paper integrates all three into a single framework. Next, the authors propose a research agenda that addresses not only how marketing strategies and customer behaviors will change in the future, but also highlights important policy questions relating to privacy, bias and ethics. Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers."
AI (cs.AI),2019,12,DARPA's Explainable Artificial Intelligence (XAI) Program,1455,N/A,https://www.semanticscholar.org/paper/06645d735b59b14479ae1d0392136bbf44227d0f,"David Gunning, D. Aha","Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA’s explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human-computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4-year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems’ explanations improve user understanding, user trust, and user task performance."
AI (cs.AI),2019,17,Artificial intelligence in cancer imaging: Clinical challenges and applications,1431,N/A,https://www.semanticscholar.org/paper/4955335096c038f2cf39fdb4cc2bc79edaf363f9,"W. Bi, A. Hosny, M. Schabath et al.","Judgement, as one of the core tenets of medicine, relies upon the integration of multilayered data with nuanced decision making. Cancer offers a unique context for medical decisions given not only its variegated forms with evolution of disease but also the need to take into account the individual condition of patients, their ability to receive treatment, and their responses to treatment. Challenges remain in the accurate detection, characterization, and monitoring of cancers despite improved technologies. Radiographic assessment of disease most commonly relies upon visual evaluations, the interpretations of which may be augmented by advanced computational analyses. In particular, artificial intelligence (AI) promises to make great strides in the qualitative interpretation of cancer imaging by expert clinicians, including volumetric delineation of tumors over time, extrapolation of the tumor genotype and biological course from its radiographic phenotype, prediction of clinical outcome, and assessment of the impact of disease and treatment on adjacent organs. AI may automate processes in the initial interpretation of images and shift the clinical workflow of radiographic detection, management decisions on whether or not to administer an intervention, and subsequent observation to a yet to be envisioned paradigm. Here, the authors review the current state of AI as applied to medical imaging of cancer and describe advances in 4 tumor types (lung, brain, breast, and prostate) to illustrate how common clinical problems are being addressed. Although most studies evaluating AI applications in oncology to date have not been vigorously validated for reproducibility and generalizability, the results do highlight increasingly concerted efforts in pushing AI technology to clinical use and to impact future directions in cancer care."
AI (cs.AI),2019,18,Causability and explainability of artificial intelligence in medicine,1273,N/A,https://www.semanticscholar.org/paper/6e80e4b2f2a09bdbc20c63af5d85e6fc333746a0,"Andreas Holzinger, G. Langs, H. Denk et al.","Explainable artificial intelligence (AI) is attracting much interest in medicine. Technically, the problem of explainability is as old as AI itself and classic AI represented comprehensible retraceable approaches. However, their weakness was in dealing with uncertainties of the real world. Through the introduction of probabilistic learning, applications became increasingly successful, but increasingly opaque. Explainable AI deals with the implementation of transparency and traceability of statistical black‐box machine learning methods, particularly deep learning (DL). We argue that there is a need to go beyond explainable AI. To reach a level of explainable medicine we need causability. In the same way that usability encompasses measurements for the quality of use, causability encompasses measurements for the quality of explanations. In this article, we provide some necessary definitions to discriminate between explainability and causability as well as a use‐case of DL interpretation and of human explanation in histopathology. The main contribution of this article is the notion of causability, which is differentiated from explainability in that causability is a property of a person, while explainability is a property of a system"
AI (cs.AI),2019,20,Artificial intelligence in digital pathology — new tools for diagnosis and precision oncology,1199,N/A,https://www.semanticscholar.org/paper/847ada64e867bd2a6ac272b5efb89c914d4b4375,"K. Bera, K. Schalper, D. Rimm et al.",No Abstract
AI (cs.AI),2020,1,Artificial Intelligence in Education: A Review,2010,N/A,https://www.semanticscholar.org/paper/a7a407968c13ced804a063259d72315a43b84f29,"Lijia Chen, Pingping Chen, Zhijian Lin","The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors’ duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students’ assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students’ needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning."
AI (cs.AI),2020,3,Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT,1647,N/A,https://www.semanticscholar.org/paper/1daa2c7115ab38b045c8347c698bd1ee9c45e141,"Lin Li, Lixin Qin, Zeguo Xu et al.","Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases."
AI (cs.AI),2020,2,Human Trust in Artificial Intelligence: Review of Empirical Research,1460,N/A,https://www.semanticscholar.org/paper/ef0c62ff070a476f216fe478cc190c773f12a1f6,"Ella Glikson, A. Woolley",Artificial intelligence (AI) characterizes a new generation of technologies capable of interacting with the environment and aiming to simulate human intelligence. The success of integrating AI into...
AI (cs.AI),2020,4,Photonics for artificial intelligence and neuromorphic computing,1408,2011.00111,https://www.semanticscholar.org/paper/5e7a7fb69ef7447c2cb8966589e49a5acbee416e,"B. Shastri, A. Tait, T. F. D. Lima et al.","Research in photonic computing has flourished due to the proliferation of optoelectronic components on photonic integration platforms. Photonic integrated circuits have enabled ultrafast artificial neural networks, providing a framework for a new class of information processing machines. Algorithms running on such hardware have the potential to address the growing demand for machine learning and artificial intelligence in areas such as medical diagnosis, telecommunications, and high-performance and scientific computing. In parallel, the development of neuromorphic electronics has highlighted challenges in that domain, particularly related to processor latency. Neuromorphic photonics offers sub-nanosecond latencies, providing a complementary opportunity to extend the domain of artificial intelligence. Here, we review recent advances in integrated photonic neuromorphic systems, discuss current and future challenges, and outline the advances in science and technology needed to meet those challenges. Photonics offers an attractive platform for implementing neuromorphic computing due to its low latency, multiplexing capabilities and integrated on-chip technology."
AI (cs.AI),2020,5,Explainability for artificial intelligence in healthcare: a multidisciplinary perspective,1234,N/A,https://www.semanticscholar.org/paper/d7f1a885e32faa2194ccd5f85da4c4fb5d788392,"J. Amann, A. Blasimme, E. Vayena et al.","Background Explainability is one of the most heavily debated topics when it comes to the application of artificial intelligence (AI) in healthcare. Even though AI-driven systems have been shown to outperform humans in certain analytical tasks, the lack of explainability continues to spark criticism. Yet, explainability is not a purely technological issue, instead it invokes a host of medical, legal, ethical, and societal questions that require thorough exploration. This paper provides a comprehensive assessment of the role of explainability in medical AI and makes an ethical evaluation of what explainability means for the adoption of AI-driven tools into clinical practice. Methods Taking AI-based clinical decision support systems as a case in point, we adopted a multidisciplinary approach to analyze the relevance of explainability for medical AI from the technological, legal, medical, and patient perspectives. Drawing on the findings of this conceptual analysis, we then conducted an ethical assessment using the “Principles of Biomedical Ethics” by Beauchamp and Childress (autonomy, beneficence, nonmaleficence, and justice) as an analytical framework to determine the need for explainability in medical AI. Results Each of the domains highlights a different set of core considerations and values that are relevant for understanding the role of explainability in clinical practice. From the technological point of view, explainability has to be considered both in terms how it can be achieved and what is beneficial from a development perspective. When looking at the legal perspective we identified informed consent, certification and approval as medical devices, and liability as core touchpoints for explainability. Both the medical and patient perspectives emphasize the importance of considering the interplay between human actors and medical AI. We conclude that omitting explainability in clinical decision support systems poses a threat to core ethical values in medicine and may have detrimental consequences for individual and public health. Conclusions To ensure that medical AI lives up to its promises, there is a need to sensitize developers, healthcare professionals, and legislators to the challenges and limitations of opaque algorithms in medical AI and to foster multidisciplinary collaboration moving forward."
AI (cs.AI),2020,6,Artificial Intelligence and Management: The Automation–Augmentation Paradox,1128,N/A,https://www.semanticscholar.org/paper/9c145390e6073c96e89cf03d3df3b559f0bb0496,"Sebastian Raisch, Sebastian Krakowski","Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that..."
AI (cs.AI),2020,8,"Review of Artificial Intelligence Techniques in Imaging Data Acquisition, Segmentation, and Diagnosis for COVID-19",1092,2004.02731,https://www.semanticscholar.org/paper/4e95ce827049a350819c5c87caf992f27f9ff792,"Feng Shi, Jun Wang, Jun Shi et al.","The pandemic of coronavirus disease 2019 (COVID-19) is spreading all over the world. Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists. We hereby review the rapid responses in the community of medical imaging (empowered by AI) toward COVID-19. For example, AI-empowered image acquisition can significantly help automate the scanning procedure and also reshape the workflow with minimal contact to patients, providing the best protection to the imaging technicians. Also, AI can improve work efficiency by accurate delineation of infections in X-ray and CT images, facilitating subsequent quantification. Moreover, the computer-aided platforms help radiologists make clinical decisions, i.e., for disease diagnosis, tracking, and prognosis. In this review paper, we thus cover the entire pipeline of medical imaging and analysis techniques involved with COVID-19, including image acquisition, segmentation, diagnosis, and follow-up. We particularly focus on the integration of AI with X-ray and CT, both of which are widely used in the frontline hospitals, in order to depict the latest progress of medical imaging and radiology fighting against COVID-19."
AI (cs.AI),2020,7,Artificial Intelligence A Modern Approach 3rd Edition,932,N/A,https://www.semanticscholar.org/paper/8603193192a64f0c9943989d209e7492689045c1,Unknown,No Abstract
AI (cs.AI),2020,14,A strategic framework for artificial intelligence in marketing,912,N/A,https://www.semanticscholar.org/paper/d020b66a033ab1adc121010e116c594415cb2cea,"Ming-Hui Huang, R. Rust","The authors develop a three-stage framework for strategic marketing planning, incorporating multiple artificial intelligence (AI) benefits: mechanical AI for automating repetitive marketing functions and activities, thinking AI for processing data to arrive at decisions, and feeling AI for analyzing interactions and human emotions. This framework lays out the ways that AI can be used for marketing research, strategy (segmentation, targeting, and positioning, STP), and actions. At the marketing research stage, mechanical AI can be used for data collection, thinking AI for market analysis, and feeling AI for customer understanding. At the marketing strategy (STP) stage, mechanical AI can be used for segmentation (segment recognition), thinking AI for targeting (segment recommendation), and feeling AI for positioning (segment resonance). At the marketing action stage, mechanical AI can be used for standardization, thinking AI for personalization, and feeling AI for relationalization. We apply this framework to various areas of marketing, organized by marketing 4Ps/4Cs, to illustrate the strategic use of AI."
AI (cs.AI),2020,9,"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",882,2002.04087,https://www.semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,B. Shneiderman,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility."
AI (cs.AI),2020,15,Artificial intelligence–enabled rapid diagnosis of patients with COVID-19,837,N/A,https://www.semanticscholar.org/paper/4d0b7f66b75cb87ed3da5ffc024ff56b10303dcc,"X. Mei, Hao-Chih Lee, Kai-yue Diao et al.",No Abstract
AI (cs.AI),2020,11,Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI,698,N/A,https://www.semanticscholar.org/paper/58bb24b72fea6d0ce172bdaf9c2f16c2bd7649e9,"Jessica Fjeld, Nele Achten, Hannah Hilligoss et al.","The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.  To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus."
AI (cs.AI),2020,16,Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey,691,2006.11371,https://www.semanticscholar.org/paper/c483beec0afae8d08f011182460095049025b8d1,"Arun Das, P. Rad","Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation."
AI (cs.AI),2020,17,Consumers and Artificial Intelligence: An Experiential Perspective,648,N/A,https://www.semanticscholar.org/paper/5ab9776bf67a6470951a932d5f9a1beaf1cec184,"S. Puntoni, R. W. Reczek, M. Giesler et al.","Artificial intelligence (AI) helps companies offer important benefits to consumers, such as health monitoring with wearable devices, advice with recommender systems, peace of mind with smart household products, and convenience with voice-activated virtual assistants. However, although AI can be seen as a neutral tool to be evaluated on efficiency and accuracy, this approach does not consider the social and individual challenges that can occur when AI is deployed. This research aims to bridge these two perspectives: on one side, the authors acknowledge the value that embedding AI technology into products and services can provide to consumers. On the other side, the authors build on and integrate sociological and psychological scholarship to examine some of the costs consumers experience in their interactions with AI. In doing so, the authors identify four types of consumer experiences with AI: (1) data capture, (2) classification, (3) delegation, and (4) social. This approach allows the authors to discuss policy and managerial avenues to address the ways in which consumers may fail to experience value in organizations’ investments into AI and to lay out an agenda for future research."
AI (cs.AI),2020,18,Influence of artificial intelligence (AI) on firm performance: the business value of AI-based transformation projects,648,N/A,https://www.semanticscholar.org/paper/75994ebb52094581dcb7d145795f6bafe6e276bb,"Serge-Lopez Wamba-Taguimdje, S. Wamba, Jean Robert Kala Kamdjoug et al.","PurposeThe main purpose of our study is to analyze the influence of Artificial Intelligence (AI) on firm performance, notably by building on the business value of AI-based transformation projects. This study was conducted using a four-step sequential approach: (1) analysis of AI and AI concepts/technologies; (2) in-depth exploration of case studies from a great number of industrial sectors; (3) data collection from the databases (websites) of AI-based solution providers; and (4) a review of AI literature to identify their impact on the performance of organizations while highlighting the business value of AI-enabled projects transformation within organizations.Design/methodology/approachThis study has called on the theory of IT capabilities to seize the influence of AI business value on firm performance (at the organizational and process levels). The research process (responding to the research question, making discussions, interpretations and comparisons, and formulating recommendations) was based on a review of 500 case studies from IBM, AWS, Cloudera, Nvidia, Conversica, Universal Robots websites, etc. Studying the influence of AI on the performance of organizations, and more specifically, of the business value of such organizations’ AI-enabled transformation projects, required us to make an archival data analysis following the three steps, namely the conceptual phase, the refinement and development phase, and the assessment phase.FindingsAI covers a wide range of technologies, including machine translation, chatbots and self-learning algorithms, all of which can allow individuals to better understand their environment and act accordingly. Organizations have been adopting AI technological innovations with a view to adapting to or disrupting their ecosystem while developing and optimizing their strategic and competitive advantages. AI fully expresses its potential through its ability to optimize existing processes and improve automation, information and transformation effects, but also to detect, predict and interact with humans. Thus, the results of our study have highlighted such AI benefits in organizations, and more specifically, its ability to improve on performance at both the organizational (financial, marketing and administrative) and process levels. By building on these AI attributes, organizations can, therefore, enhance the business value of their transformed projects. The same results also showed that organizations achieve performance through AI capabilities only when they use their features/technologies to reconfigure their processes.Research limitations/implicationsAI obviously influences the way businesses are done today. Therefore, practitioners and researchers need to consider AI as a valuable support or even a pilot for a new business model. For the purpose of our study, we adopted a research framework geared toward a more inclusive and comprehensive approach so as to better account for the intangible benefits of AI within organizations. In terms of interest, this study nurtures a scientific interest, which aims at proposing a model for analyzing the influence of AI on the performance of organizations, and at the same time, filling the associated gap in the literature. As for the managerial interest, our study aims to provide managers with elements to be reconfigured or added in order to take advantage of the full benefits of AI, and therefore improve organizations’ performance, the profitability of their investments in AI transformation projects, and some competitive advantage. This study also allows managers to consider AI not as a single technology but as a set/combination of several different configurations of IT in the various company’s business areas because multiple key elements must be brought together to ensure the success of AI: data, talent mix, domain knowledge, key decisions, external partnerships and scalable infrastructure.Originality/valueThis article analyses case studies on the reuse of secondary data from AI deployment reports in organizations. The transformation of projects based on the use of AI focuses mainly on business process innovations and indirectly on those occurring at the organizational level. Thus, 500 case studies are being examined to provide significant and tangible evidence about the business value of AI-based projects and the impact of AI on firm performance. More specifically, this article, through these case studies, exposes the influence of AI at both the organizational and process performance levels, while considering it not as a single technology but as a set/combination of the several different configurations of IT in various industries."
AI (cs.AI),2020,10,In AI we trust? Perceptions about automated decision-making by artificial intelligence,646,N/A,https://www.semanticscholar.org/paper/2fe4b15267f76c39cf60c0ed8e697d11c7050391,"Theo B. Araujo, N. Helberger, S. Kruikemeier et al.",No Abstract
AI (cs.AI),2020,19,Recommendation of the Council on Artificial Intelligence (OECD),505,N/A,https://www.semanticscholar.org/paper/04c902a91806288af4c7646e95cc2c94d9f15d97,K. Yeung,"On May 22, 2019, the Organisation for Economic Co-operation and Development (OECD) Ministerial Council Meeting adopted the Recommendation on Artificial Intelligence, signed by all 36 OECD member countries and non-member countries Argentina, Brazil, Columbia, Costa Rica, Peru, and Romania. Its aim is to foster innovation and trust in artificial intelligence (AI) by promoting the “responsible stewardship of trustworthy AI.”"
AI (cs.AI),2020,20,Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence,495,2007.04068,https://www.semanticscholar.org/paper/d3e8b100038c2bf3983ffae96a56c6af0793a62f,"Shakir Mohamed, Marie-Therese Png, William S. Isaac","This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. While the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us, ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all."
AI (cs.AI),2020,13,COVID-19 Artificial Intelligence Diagnosis Using Only Cough Recordings,433,N/A,https://www.semanticscholar.org/paper/971ee735f8f259b220d35a252ee20f74b82c6371,"Jordi Laguarta, F. Hueto, B. Subirana","Goal: We hypothesized that COVID-19 subjects, especially including asymptomatics, could be accurately discriminated only from a forced-cough cell phone recording using Artificial Intelligence. To train our MIT Open Voice model we built a data collection pipeline of COVID-19 cough recordings through our website (opensigma.mit.edu) between April and May 2020 and created the largest audio COVID-19 cough balanced dataset reported to date with 5,320 subjects. Methods: We developed an AI speech processing framework that leverages acoustic biomarker feature extractors to pre-screen for COVID-19 from cough recordings, and provide a personalized patient saliency map to longitudinally monitor patients in real-time, non-invasively, and at essentially zero variable cost. Cough recordings are transformed with Mel Frequency Cepstral Coefficient and inputted into a Convolutional Neural Network (CNN) based architecture made up of one Poisson biomarker layer and 3 pre-trained ResNet50's in parallel, outputting a binary pre-screening diagnostic. Our CNN-based models have been trained on 4256 subjects and tested on the remaining 1064 subjects of our dataset. Transfer learning was used to learn biomarker features on larger datasets, previously successfully tested in our Lab on Alzheimer's, which significantly improves the COVID-19 discrimination accuracy of our architecture. Results: When validated with subjects diagnosed using an official test, the model achieves COVID-19 sensitivity of 98.5% with a specificity of 94.2% (AUC: 0.97). For asymptomatic subjects it achieves sensitivity of 100% with a specificity of 83.2%. Conclusions: AI techniques can produce a free, non-invasive, real-time, any-time, instantly distributable, large-scale COVID-19 asymptomatic screening tool to augment current approaches in containing the spread of COVID-19. Practical use cases could be for daily screening of students, workers, and public as schools, jobs, and transport reopen, or for pool testing to quickly alert of outbreaks in groups. General speech biomarkers may exist that cover several disease categories, as we demonstrated using the same ones for COVID-19 and Alzheimer's."
AI (cs.AI),2020,12,"Industrial Artificial Intelligence in Industry 4.0 - Systematic Review, Challenges and Outlook",362,N/A,https://www.semanticscholar.org/paper/63b90ba84e6c881166085bf2e838a7fc84428904,"Ricardo Silva Peres, Xiaodong Jia, J. Lee et al.","The advent of the Industry 4.0 initiative has made it so that manufacturing environments are becoming more and more dynamic, connected but also inherently more complex, with additional inter-dependencies, uncertainties and large volumes of data being generated. Recent advances in Industrial Artificial Intelligence have showcased the potential of this technology to assist manufacturers in tackling the challenges associated with this digital transformation of Cyber-Physical Systems, through its data-driven predictive analytics and capacity to assist decision-making in highly complex, non-linear and often multistage environments. However, the industrial adoption of such solutions is still relatively low beyond the experimental pilot stage, as real environments provide unique and difficult challenges for which organizations are still unprepared. The aim of this paper is thus two-fold. First, a systematic review of current Industrial Artificial Intelligence literature is presented, focusing on its application in real manufacturing environments to identify the main enabling technologies and core design principles. Then, a set of key challenges and opportunities to be addressed by future research efforts are formulated along with a conceptual framework to bridge the gap between research in this field and the manufacturing industry, with the goal of promoting industrial adoption through a successful transition towards a digitized and data-driven company-wide culture. This paper is among the first to provide a clear definition and holistic view of Industrial Artificial Intelligence in the Industry 4.0 landscape, identifying and analysing its fundamental building blocks and ongoing trends. Its findings are expected to assist and empower researchers and manufacturers alike to better understand the requirements and steps necessary for a successful transition into Industry 4.0 supported by AI, as well as the challenges that may arise during this process."
AI (cs.AI),2021,7,Artificial intelligence: A powerful paradigm for scientific research,1172,N/A,https://www.semanticscholar.org/paper/6e4d9cd2da1e3667da2cc303c5549a7773f07fa7,"Yongjun Xu, Qi Wang, Zhulin An et al.",No Abstract
AI (cs.AI),2021,4,Artificial intelligence in healthcare: transforming the practice of medicine,977,N/A,https://www.semanticscholar.org/paper/2b6d375d8abea91d46894ebfa7051077253834d5,"Junaid Bajwa, Usman Munir, A. Nori et al.","ABSTRACT Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction of AI augmented healthcare systems."
AI (cs.AI),2021,9,The false hope of current approaches to explainable artificial intelligence in health care.,899,N/A,https://www.semanticscholar.org/paper/634ed64dd2d4c53381fbcc53f4d0fa339711d799,"M. Ghassemi, Luke Oakden-Rayner, Andrew Beam",No Abstract
AI (cs.AI),2021,11,Artificial intelligence to deep learning: machine intelligence approach for drug discovery,890,N/A,https://www.semanticscholar.org/paper/29409efa04ac99ccf01d2a011d21d5d14e870000,"Rohan Gupta, Devesh Srivastava, Mehar Sahu et al.","Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind. The primary concern associated with drug design and development is time consumption and production cost. Further, inefficiency, inaccurate target delivery, and inappropriate dosage are other hurdles that inhibit the process of drug delivery and development. With advancements in technology, computer-aided drug design integrating artificial intelligence algorithms can eliminate the challenges and hurdles of traditional drug design and development. Artificial intelligence is referred to as superset comprising machine learning, whereas machine learning comprises supervised learning, unsupervised learning, and reinforcement learning. Further, deep learning, a subset of machine learning, has been extensively implemented in drug design and development. The artificial neural network, deep neural network, support vector machines, classification and regression, generative adversarial networks, symbolic learning, and meta-learning are examples of the algorithms applied to the drug design and discovery process. Artificial intelligence has been applied to different areas of drug design and development process, such as from peptide synthesis to molecule design, virtual screening to molecular docking, quantitative structure–activity relationship to drug repositioning, protein misfolding to protein–protein interactions, and molecular pathway identification to polypharmacology. Artificial intelligence principles have been applied to the classification of active and inactive, monitoring drug release, pre-clinical and clinical development, primary and secondary drug screening, biomarker development, pharmaceutical manufacturing, bioactivity identification and physiochemical properties, prediction of toxicity, and identification of mode of action."
AI (cs.AI),2021,6,"Artificial intelligence capability: Conceptualization, measurement calibration, and empirical study on its impact on organizational creativity and firm performance",831,N/A,https://www.semanticscholar.org/paper/8d9f4b3f299b8f93e2b73dfd25f6d7420471c83f,"Patrick Mikalef, Manjul Gupta",No Abstract
AI (cs.AI),2021,10,A Review of Artificial Intelligence (AI) in Education from 2010 to 2020,784,N/A,https://www.semanticscholar.org/paper/83311744b174550032cfe09cb2940703dc9c9245,"Xuesong Zhai, Xiaoyan Chu, C. Chai et al.","This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research."
AI (cs.AI),2021,3,Artificial intelligence in education: Addressing ethical challenges in K-12 settings,768,N/A,https://www.semanticscholar.org/paper/c0a8fe3ac767c0911f10296bce29cb97a7382266,"Selin Akgun, Christine Greenhow","Artificial intelligence (AI) is a field of study that combines the applications of machine learning, algorithm productions, and natural language processing. Applications of AI transform the tools of education. AI has a variety of educational applications, such as personalized learning platforms to promote students’ learning, automated assessment systems to aid teachers, and facial recognition systems to generate insights about learners’ behaviors. Despite the potential benefits of AI to support students’ learning experiences and teachers’ practices, the ethical and societal drawbacks of these systems are rarely fully considered in K-12 educational contexts. The ethical challenges of AI in education must be identified and introduced to teachers and students. To address these issues, this paper (1) briefly defines AI through the concepts of machine learning and algorithms; (2) introduces applications of AI in educational settings and benefits of AI systems to support students’ learning processes; (3) describes ethical challenges and dilemmas of using AI in education; and (4) addresses the teaching and understanding of AI by providing recommended instructional resources from two providers—i.e., the Massachusetts Institute of Technology’s (MIT) Media Lab and Code.org. The article aims to help practitioners reap the benefits and navigate ethical challenges of integrating AI in K-12 classrooms, while also introducing instructional resources that teachers can use to advance K-12 students’ understanding of AI and ethics."
AI (cs.AI),2021,13,"Artificial intelligence, robotics, advanced technologies and human resource management: a systematic review",713,N/A,https://www.semanticscholar.org/paper/bd3d0238549555bd07fd25ff61b3d7e01eb02296,"D. Vrontis, M. Christofi, V. Pereira et al.","Abstract Although academic production in intelligent automation (e.g. artificial intelligence, robotics) has grown rapidly, we still lack a comprehensive understanding of the impacts of the utilization of these technologies in human resource management (HRM) at an organizational (firms) and individual (employees) level. This study therefore aims to systematize the academic inputs on intelligent automation so far and to clarify what are its main contributions to and challenges for HRM. In a systematic search of 13,136 potentially relevant studies published in the top HRM, international business (IB), general management (GM) and information management (IM) journals, we found 45 articles studying artificial intelligence, robotics and other advanced technologies within HRM settings. Results show that intelligent automation technologies constitute a new approach to managing employees and enhancing firm performance, thus offering several opportunities for HRM but also considerable challenges at a technological and ethical level. The impact of these technologies has been identified to concentrate on HRM strategies, namely, job replacement, human-robot/AI collaboration, decision-making and learning opportunities, and HRM activities, namely, recruiting, training and job performance. This study discusses these shifts in detail, along with the main contributions to theory and practice and directions for future research."
AI (cs.AI),2021,2,"Atlas of AI: Power, Politics and the Planetary Costs of Artificial Intelligence",677,N/A,https://www.semanticscholar.org/paper/c18ff70a0a0ac21b22e9736ecebc627707924fa7,Kate Crawford,"ATLAS OF AI: Power, Politics, and the Planetary Costs of Artificial Intelligence by Kate Crawford. New Haven, CT: Yale University Press, 2021. 336 pages. Hardcover; $28.00. ISBN: 9780300209570. *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence is Kate Crawford's analysis of the state of the AI industry. A central idea of her book is the importance of redefining Artificial Intelligence (AI). She states, ""I've argued that there is much at stake in how we define AI, what its boundaries are, and who determines them: it shapes what can be seen and contested"" (p. 217). *My own definition of AI goes something like this: I¬†imagine a future where I'm sitting in a cafe drinking coffee with my friends, but in this future, one of my friends is a robot, who like me is trying to make a living in this world. A future where humans and robots live in harmony. Crawford views this definition as mythological: ""These mythologies are particularly strong in the field of artificial intelligence, where the belief that human intelligence can be formalized and reproduced by machines has been axiomatic since the mid-twentieth century"" (p.¬†5). I do not know if my definition of artificial intelligence can come true, but I am enjoying the process of building, experimenting, and dreaming. *In her book, she asks me to consider that I may be unknowingly participating, as she states, in ""a material product of colonialism, with its patterns of extraction, conflict, and environmental destruction"" (p. 38). The book's subtitle illuminates the purpose of the book: specifically, the power, politics, and planetary costs of usurping artificial intelligence. Of course, this is not exactly Crawford's subtitle, and this is where I both agree and disagree with her. The book's subtitle is actually Power, Politics, and the Planetary Costs of Artificial Intelligence. In my opinion, AI is more the canary in the coal mine. We can use the canary to detect the poisonous gases, but we cannot blame the canary for the poisonous gas. It risks missing the point. Is AI itself to be feared? Should we no longer teach or learn AI? Or is this more about how we discern responsible use and direction for AI technology? *There is another author who speaks to similar issues. In Weapons of Math Destruction, Cathy O'Neil states it this way, ""If we had been clear-headed, we all would have taken a step back at this point to figure out how math had been misused ... But instead ... new mathematical techniques were hotter than ever ... A computer program could speed through thousands of resumes or loan applications in a second or two and sort them into neat lists, with the most promising candidates on top"" (p. 13). *Both Crawford and O'Neil point to human flaws that often lead to well-intentioned software developers creating code that results in unfair and discriminatory decisions. AI models encode unintended human biases that may not evaluate candidates as fairly as we would expect, yet there is a widespread notion that we can trust the algorithm. For example, the last time you registered an account on a website, did you click the checkbox confirming that ""yes, I read the disclaimer"" even though you did not? When we click ""yes"" we are accepting this disclaimer and placing trust in the software. Business owners place trust in software when they use it to make predictions. Engineers place trust in their algorithms when they write software without rigorous testing protocols. I¬†am just as guilty. *Crawford suggests that AI is often used in ways that are harmful. In the Atlas of AI we are given a tour of how technology is damaging our world: strip mining, labor injustice, the misuse of personal data, issues of state and power, to name a few of the concerns Crawford raises. The reality is that AI is built upon existing infrastructure. For example, Facebook, Instagram, YouTube, Amazon, TikTok have been collecting our information for profit even before AI became important to them. The data centers, CPU houses, and worldwide network infrastructure were already in place to meet consumer demand and geopolitics. But it is true that AI brings new technologies to the table, such as automated face recognition and decision tools to compare prospective employment applicants with diverse databases and employee monitoring tools that can make automatic recommendations. Governments, militaries, and intelligence agencies have taken notice. As invasion of privacy and social justice concerns emerge, Crawford calls us to consider these issues carefully. *Reading Crawford's words pricked my conscience, convicting me to reconsider my erroneous ways. For big tech to exist, to supply what we demand, it needs resources. She walks us through the many resources the technology industry needs to provide what we want, and AI is the ""new kid on the block."" This book is not about AI, per se; it is instead about the side effects of poor business/research practices, opportunist behavior, power politics, and how these behaviors not only exploit our planet but also unjustly affect marginalized people. The AI industry is simply a new example of this reality: data mining, low wages to lower costs, foreign workers with fewer rights, strip mining, relying on coal and oil for electricity (although some tech companies have made strides to improve sustainability). This sounds more like a parable about the sins of the tech industry than a critique about the dangers of AI. *Could the machine learning community, like the inventors of dynamite who wanted to simply help railroads excavate tunnels, be unintentionally causing harm? Should we, as a community, be on the lookout for these potential harms? Do we have a moral responsibility? Maybe the technology sector needs to look more inwardly to ensure that process efficiency and cost savings are not elevated as most important. *I did not agree with everything that Crawford classified as AI, but I do agree that as a community we are responsible for our actions. If there are injustices, then this should be important to us. In particular, as people of faith, we should heed the call of Micah 6:8 to act justly in this world, and this includes how we use AI. *Reviewed by Joseph Vybihal, Professor of Computer Science, McGill University, Montreal, PQ H3A 0G4."
AI (cs.AI),2021,19,The role of artificial intelligence in healthcare: a structured literature review,658,N/A,https://www.semanticscholar.org/paper/a81434e08ea760cc364c5a9d8aa8cdc09fcbc9f1,"Silvana Secinaro, D. Calandra, Aurelio Secinaro et al.","Background/Introduction Artificial intelligence (AI) in the healthcare sector is receiving attention from researchers and health professionals. Few previous studies have investigated this topic from a multi-disciplinary perspective, including accounting, business and management, decision sciences and health professions. Methods The structured literature review with its reliable and replicable research protocol allowed the researchers to extract 288 peer-reviewed papers from Scopus. The authors used qualitative and quantitative variables to analyse authors, journals, keywords, and collaboration networks among researchers. Additionally, the paper benefited from the Bibliometrix R software package. Results The investigation showed that the literature in this field is emerging. It focuses on health services management, predictive medicine, patient data and diagnostics, and clinical decision-making. The United States, China, and the United Kingdom contributed the highest number of studies. Keyword analysis revealed that AI can support physicians in making a diagnosis, predicting the spread of diseases and customising treatment paths. Conclusions The literature reveals several AI applications for health services and a stream of research that has not fully been covered. For instance, AI projects require skills and data quality awareness for data-intensive analysis and knowledge-based management. Insights can help researchers and health professionals understand and address future research on AI in the healthcare field."
AI (cs.AI),2021,20,Artificial intelligence-enhanced electrocardiography in cardiovascular disease management,642,N/A,https://www.semanticscholar.org/paper/a7a65aec0792126674544fdbdca1aff418de3add,"K. Siontis, P. Noseworthy, Z. Attia et al.","The application of artificial intelligence (AI) to the electrocardiogram (ECG), a ubiquitous and standardized test, is an example of the ongoing transformative effect of AI on cardiovascular medicine. Although the ECG has long offered valuable insights into cardiac and non-cardiac health and disease, its interpretation requires considerable human expertise. Advanced AI methods, such as deep-learning convolutional neural networks, have enabled rapid, human-like interpretation of the ECG, while signals and patterns largely unrecognizable to human interpreters can be detected by multilayer AI networks with precision, making the ECG a powerful, non-invasive biomarker. Large sets of digital ECGs linked to rich clinical data have been used to develop AI models for the detection of left ventricular dysfunction, silent (previously undocumented and asymptomatic) atrial fibrillation and hypertrophic cardiomyopathy, as well as the determination of a person’s age, sex and race, among other phenotypes. The clinical and population-level implications of AI-based ECG phenotyping continue to emerge, particularly with the rapid rise in the availability of mobile and wearable ECG technologies. In this Review, we summarize the current and future state of the AI-enhanced ECG in the detection of cardiovascular disease in at-risk populations, discuss its implications for clinical decision-making in patients with cardiovascular disease and critically appraise potential limitations and unknowns. In this Review, Friedman and colleagues summarize the use of artificial intelligence-enhanced electrocardiography in the detection of cardiovascular disease in at-risk populations, discuss its implications for clinical decision-making in patients with cardiovascular disease and critically appraise potential limitations and unknowns. The feasibility and potential value of the application of advanced artificial intelligence methods, particularly deep-learning convolutional neural networks (CNNs), to the electrocardiogram (ECG) have been demonstrated. CNNs developed with the use of large numbers of digital ECGs linked to rich clinical datasets might be able to perform accurate and nuanced, human-like interpretation of ECGs. CNNs have also been developed to detect asymptomatic left ventricular dysfunction, silent atrial fibrillation, hypertrophic cardiomyopathy and an individual’s age, sex and race on the basis of the ECG alone. CNNs to detect other cardiac conditions, such as aortic valve stenosis and amyloid heart disease, are in active development. These approaches might be applicable to the standard 12-lead ECG or to data obtained from single-lead or multilead mobile or wearable ECG technologies. Evidence on patient outcomes, as well as the challenges and potential limitations from the real-world implementation of the artificial intelligence-enhanced ECG, continues to emerge. The feasibility and potential value of the application of advanced artificial intelligence methods, particularly deep-learning convolutional neural networks (CNNs), to the electrocardiogram (ECG) have been demonstrated. CNNs developed with the use of large numbers of digital ECGs linked to rich clinical datasets might be able to perform accurate and nuanced, human-like interpretation of ECGs. CNNs have also been developed to detect asymptomatic left ventricular dysfunction, silent atrial fibrillation, hypertrophic cardiomyopathy and an individual’s age, sex and race on the basis of the ECG alone. CNNs to detect other cardiac conditions, such as aortic valve stenosis and amyloid heart disease, are in active development. These approaches might be applicable to the standard 12-lead ECG or to data obtained from single-lead or multilead mobile or wearable ECG technologies. Evidence on patient outcomes, as well as the challenges and potential limitations from the real-world implementation of the artificial intelligence-enhanced ECG, continues to emerge."
AI (cs.AI),2021,14,On evaluation metrics for medical applications of artificial intelligence,639,N/A,https://www.semanticscholar.org/paper/6256380fca2b6039df2449a1d35727f17933316b,"S. Hicks, I. StruÌke, Vajira Lasantha Thambawita et al.","Clinicians and software developers need to understand how proposed machine learning (ML) models could improve patient care. No single metric captures all the desirable properties of a model, which is why several metrics are typically reported to summarize a model’s performance. Unfortunately, these measures are not easily understandable by many clinicians. Moreover, comparison of models across studies in an objective manner is challenging, and no tool exists to compare models using the same performance metrics. This paper looks at previous ML studies done in gastroenterology, provides an explanation of what different metrics mean in the context of binary classification in the presented studies, and gives a thorough explanation of how different metrics should be interpreted. We also release an open source web-based tool that may be used to aid in calculating the most relevant metrics presented in this paper so that other researchers and clinicians may easily incorporate them into their research."
AI (cs.AI),2021,18,Explainable artificial intelligence: an analytical review,623,N/A,https://www.semanticscholar.org/paper/0ca9a5ef7695fdaa65325761164c70e56739a902,"P. Angelov, E. Soares, Richard Jiang et al.","This paper provides a brief analytical review of the current state‐of‐the‐art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested."
AI (cs.AI),2021,15,Artificial intelligence in supply chain management: A systematic literature review,613,N/A,https://www.semanticscholar.org/paper/9b58e7657d5cdebb665646532aec638dd0f18f4d,"Reza Toorajipour, Vahid Sohrabpour, Ali Nazarpour et al.",No Abstract
AI (cs.AI),2021,17,Artificial Intelligence and Business Value: a Literature Review,533,N/A,https://www.semanticscholar.org/paper/286a3bf8579deadd9b892bb800614b7c35d5d9a6,"Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef et al.","Artificial Intelligence (AI) are a wide-ranging set of technologies that promise several advantages for organizations in terms off added business value. Over the past few years, organizations are increasingly turning to AI in order to gain business value following a deluge of data and a strong increase in computational capacity. Nevertheless, organizations are still struggling to adopt and leverage AI in their operations. The lack of a coherent understanding of how AI technologies create business value, and what type of business value is expected, therefore necessitates a holistic understanding. This study provides a systematic literature review that attempts to explain how organizations can leverage AI technologies in their operations and elucidate the value-generating mechanisms. Our analysis synthesizes the current literature and highlights: (1) the key enablers and inhibitors of AI adoption and use; (2) the typologies of AI use in the organizational setting; and (3) the first- and second-order effects of AI. The paper concludes with an identification of the gaps in the literature and develops a research agenda that identifies areas that need to be addressed by future studies."
AI (cs.AI),2021,16,The impact of big data analytics and artificial intelligence on green supply chain process integration and hospital environmental performance,525,N/A,https://www.semanticscholar.org/paper/7b6ea9c9634f01d4a4eefa67f4401d79598a7830,"S. Benzidia, N. Makaoui, Omar Bentahar",No Abstract
AI (cs.AI),2021,5,A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence,512,N/A,https://www.semanticscholar.org/paper/139e90776bde3e2657497d5bb759f2514da1b53f,"Emily J. Allen, Ghislain St-Yves, Yihan Wu et al.","Extensive sampling of neural activity during rich cognitive phenomena is critical for robust understanding of brain function. Here we present the Natural Scenes Dataset (NSD), in which high-resolution functional magnetic resonance imaging responses to tens of thousands of richly annotated natural scenes were measured while participants performed a continuous recognition task. To optimize data quality, we developed and applied novel estimation and denoising techniques. Simple visual inspections of the NSD data reveal clear representational transformations along the ventral visual pathway. Further exemplifying the inferential power of the dataset, we used NSD to build and train deep neural network models that predict brain activity more accurately than state-of-the-art models from computer vision. NSD also includes substantial resting-state and diffusion data, enabling network neuroscience perspectives to constrain and enhance models of perception and memory. Given its unprecedented scale, quality and breadth, NSD opens new avenues of inquiry in cognitive neuroscience and artificial intelligence. The authors measured high-resolution fMRI activity from eight individuals who saw and memorized thousands of annotated natural images over 1 year. This massive dataset enables new paths of inquiry in cognitive neuroscience and artificial intelligence."
AI (cs.AI),2021,8,What Do We Want From Explainable Artificial Intelligence (XAI)? - A Stakeholder Perspective on XAI and a Conceptual Model Guiding Interdisciplinary XAI Research,489,2102.07817,https://www.semanticscholar.org/paper/9dae90ce317bc61eeeeb16a3589fe9201a799de0,"Markus Langer, Daniel Oster, Timo Speith et al.",No Abstract
AI (cs.AI),2021,12,Artificial intelligence-driven innovation for enhancing supply chain resilience and performance under the effect of supply chain dynamism: an empirical investigation,476,N/A,https://www.semanticscholar.org/paper/3c6067c120790b142e9b581bfc82ca02db2ce095,"Amine Belhadi, Venkatesh Mani, Sachin S. Kamble et al.","Supply chain resilience (SCRes) and performance have become increasingly important in the wake of the recent supply chain disruptions caused by subsequent pandemics and crisis. Besides, the context of digitalization, integration, and globalization of the supply chain has raised an increasing awareness of advanced information processing techniques such as Artificial Intelligence (AI) in building SCRes and improving supply chain performance (SCP). The present study investigates the direct and indirect effects of AI, SCRes, and SCP under a context of dynamism and uncertainty of the supply chain. In doing so, we have conceptualized the use of AI in the supply chain on the organizational information processing theory (OIPT). The developed framework was evaluated using a structural equation modeling (SEM) approach. Survey data was collected from 279 firms representing different sizes, operating in various sectors, and countries. Our findings suggest that while AI has a direct impact on SCP in the short-term, it is recommended to exploit its information processing capabilities to build SCRes for long-lasting SCP. This study is among the first to provide empirical evidence on maximizing the benefits of AI capabilities to generate sustained SCP. The study could be further extended using a longitudinal investigation to explore more facets of the phenomenon."
AI (cs.AI),2021,1,Design and Control of a Highly Redundant Rigid-flexible Coupling Robot to Assist the COVID-19 Oropharyngeal-Swab Sampling,52,2102.12726,https://www.semanticscholar.org/paper/137e10dad8ca3c119271cd8b1bb4303ea51afd36,"Yingbai Hu, Jian Li, Yongquan Chen et al.","The outbreak of novel coronavirus pneumonia (COVID-19) has caused mortality and morbidity worldwide. Oropharyngeal-swab (OP-swab) sampling is widely used for the diagnosis of COVID-19 in the world. To avoid the clinical staff from being affected by the virus, we developed a 9-degree-of-freedom (DOF) rigid-flexible coupling (RFC) robot to assist the COVID-19 OP-swab sampling. This robot is composed of a visual system, UR5 robot arm, micro-pneumatic actuator and force-sensing system. The robot is expected to reduce risk and free up the clinical staff from the long-term repetitive sampling work. Compared with a rigid sampling robot, the developed force-sensing RFC robot can facilitate OP-swab sampling procedures in a safer and softer way. In addition, a varying-parameter zeroing neural network-based optimization method is also proposed for motion planning of the 9-DOF redundant manipulator. The developed robot system is validated by OP-swab sampling on both oral cavity phantoms and volunteers."
AI (cs.AI),2022,2,"Atlas of AI: power, politics, and the planetary costs of artificial intelligence.",649,N/A,https://www.semanticscholar.org/paper/fc963363bcddfc1aeca07d44d7a9d0e53485662d,Muhammed Can,No Abstract
AI (cs.AI),2022,10,Ethical principles for artificial intelligence in education,612,N/A,https://www.semanticscholar.org/paper/ec13995de8797a4e977024942d79fc0d27e20b7b,"Andy Nguyen, H. Ngo, Yvonne Hong et al.","The advancement of artificial intelligence in education (AIED) has the potential to transform the educational landscape and influence the role of all involved stakeholders. In recent years, the applications of AIED have been gradually adopted to progress our understanding of students’ learning and enhance learning performance and experience. However, the adoption of AIED has led to increasing ethical risks and concerns regarding several aspects such as personal data and learner autonomy. Despite the recent announcement of guidelines for ethical and trustworthy AIED, the debate revolves around the key principles underpinning ethical AIED. This paper aims to explore whether there is a global consensus on ethical AIED by mapping and analyzing international organizations’ current policies and guidelines. In this paper, we first introduce the opportunities offered by AI in education and potential ethical issues. Then, thematic analysis was conducted to conceptualize and establish a set of ethical principles by examining and synthesizing relevant ethical policies and guidelines for AIED. We discuss each principle and associated implications for relevant educational stakeholders, including students, teachers, technology developers, policymakers, and institutional decision-makers. The proposed set of ethical principles is expected to serve as a framework to inform and guide educational stakeholders in the development and deployment of ethical and trustworthy AIED as well as catalyze future development of related impact studies in the field."
AI (cs.AI),2022,7,Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?,587,N/A,https://www.semanticscholar.org/paper/e8441a9d8c22f333b4092d3a95d3fbb64a36d428,"Nithesh Naik, B. Hameed, Dasharathraj K. Shetty et al.","The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries involved and cybersecurity of associated vulnerabilities."
AI (cs.AI),2022,12,The Promises and Challenges of Artificial Intelligence for Teachers: a Systematic Review of Research,553,N/A,https://www.semanticscholar.org/paper/80743a9fbea0767761d59fae1d209b7fc7ef3f28,"I. Celik, M. Dindar, H. Muukkonen et al.","This study provides an overview of research on teachers’ use of artificial intelligence (AI) applications and machine learning methods to analyze teachers’ data. Our analysis showed that AI offers teachers several opportunities for improved planning (e.g., by defining students’ needs and familiarizing teachers with such needs), implementation (e.g., through immediate feedback and teacher intervention), and assessment (e.g., through automated essay scoring) of their teaching. We also found that teachers have various roles in the development of AI technology. These roles include acting as models for training AI algorithms and participating in AI development by checking the accuracy of AI automated assessment systems. Our findings further underlined several challenges in AI implementation in teaching practice, which provide guidelines for developing the field."
AI (cs.AI),2022,1,"From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where",526,N/A,https://www.semanticscholar.org/paper/7c1933359a6860fe49d15c6353a241763879e81f,"Imran Ahmed, Gwanggil Jeon, F. Piccialli","Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit future research directions toward responsible or human-centric AI and XAI systems, essential for adopting high-stakes industry applications."
AI (cs.AI),2022,15,Artificial intelligence in online higher education: A systematic review of empirical research from 2011 to 2020,504,N/A,https://www.semanticscholar.org/paper/811c64131e009de84f0d92da6cc96e824a291bd5,"Ouyang Fan, Luyi Zheng, Pengcheng Jiao",No Abstract
AI (cs.AI),2022,16,Trustworthy Artificial Intelligence: A Review,495,N/A,https://www.semanticscholar.org/paper/2d93d27fb07fc43bb1e430c37f802586bc9aaf00,"Davinder Kaur, Suleyman Uslu, Kaley J. Rittichier et al.","Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions."
AI (cs.AI),2022,9,A Proposal For The Dartmouth Summer Research Project On Artificial Intelligence,485,N/A,https://www.semanticscholar.org/paper/ceceaabccaf61edfd1c924d419328f0c2bfe9f81,"J. McCarthy, Dartmouth College, M. Minsky et al.",No Abstract
AI (cs.AI),2022,4,Artificial intelligence for diagnosis and Gleason grading of prostate cancer: the PANDA challenge,478,N/A,https://www.semanticscholar.org/paper/551a32d6bb196127b75d256e8547b81ef67a7ad3,"W. Bulten, K. Kartasalo, Po-Hsuan Cameron Chen et al.","Artificial intelligence (AI) has shown promise for diagnosing prostate cancer in biopsies. However, results have been limited to individual studies, lacking validation in multinational settings. Competitions have been shown to be accelerators for medical imaging innovations, but their impact is hindered by lack of reproducibility and independent validation. With this in mind, we organized the PANDA challenge—the largest histopathology competition to date, joined by 1,290 developers—to catalyze development of reproducible AI algorithms for Gleason grading using 10,616 digitized prostate biopsies. We validated that a diverse set of submitted algorithms reached pathologist-level performance on independent cross-continental cohorts, fully blinded to the algorithm developers. On United States and European external validation sets, the algorithms achieved agreements of 0.862 (quadratically weighted κ, 95% confidence interval (CI), 0.840–0.884) and 0.868 (95% CI, 0.835–0.900) with expert uropathologists. Successful generalization across different patient populations, laboratories and reference standards, achieved by a variety of algorithmic approaches, warrants evaluating AI-based Gleason grading in prospective clinical trials. Through a community-driven competition, the PANDA challenge provides a curated diverse dataset and a catalog of models for prostate cancer pathology, and represents a blueprint for evaluating AI algorithms in digital pathology."
AI (cs.AI),2022,14,Artificial Intelligence and Jobs: Evidence from Online Vacancies,400,N/A,https://www.semanticscholar.org/paper/df5f3ffe15207eb6ae2f00f3ccc818625b9bfbe7,"D. Acemoglu, David Autor, J. Hazell et al.","We study the impact of artificial intelligence (AI) on labor markets using establishment-level data on the near universe of online vacancies in the United States from 2010 onward. There is rapid growth in AI-related vacancies over 2010–18 that is driven by establishments whose workers engage in tasks compatible with AI’s current capabilities. As these AI-exposed establishments adopt AI, they simultaneously reduce hiring in non-AI positions and change the skill requirements of remaining postings. While visible at the establishment level, the aggregate impacts of AI-labor substitution on employment and wage growth in more exposed occupations and industries is currently too small to be detectable."
AI (cs.AI),2022,3,Artificial Intelligence A Modern Approach 3rd,391,N/A,https://www.semanticscholar.org/paper/8ebd4ae177fb1a62298d19891fd6e45e2a5f7685,Unknown,No Abstract
AI (cs.AI),2022,8,Artificial Intelligence (AI) and Internet of Medical Things (IoMT) Assisted Biomedical Systems for Intelligent Healthcare,382,N/A,https://www.semanticscholar.org/paper/ff437a9a44dbce3faf9534454a9bbdbc12bac3c2,"Pandiaraj Manickam, Siva Ananth Mariappan, S. Murugesan et al.","Artificial intelligence (AI) is a modern approach based on computer science that develops programs and algorithms to make devices intelligent and efficient for performing tasks that usually require skilled human intelligence. AI involves various subsets, including machine learning (ML), deep learning (DL), conventional neural networks, fuzzy logic, and speech recognition, with unique capabilities and functionalities that can improve the performances of modern medical sciences. Such intelligent systems simplify human intervention in clinical diagnosis, medical imaging, and decision-making ability. In the same era, the Internet of Medical Things (IoMT) emerges as a next-generation bio-analytical tool that combines network-linked biomedical devices with a software application for advancing human health. In this review, we discuss the importance of AI in improving the capabilities of IoMT and point-of-care (POC) devices used in advanced healthcare sectors such as cardiac measurement, cancer diagnosis, and diabetes management. The role of AI in supporting advanced robotic surgeries developed for advanced biomedical applications is also discussed in this article. The position and importance of AI in improving the functionality, detection accuracy, decision-making ability of IoMT devices, and evaluation of associated risks assessment is discussed carefully and critically in this review. This review also encompasses the technological and engineering challenges and prospects for AI-based cloud-integrated personalized IoMT devices for designing efficient POC biomedical systems suitable for next-generation intelligent healthcare."
AI (cs.AI),2022,11,Artificial intelligence – challenges and opportunities for international HRM: a review and research agenda,366,N/A,https://www.semanticscholar.org/paper/facca3eff019a509ac88b0ce4b8cb60341f22d78,"P. Budhwar, A. Malik, M. T. Thedushika et al.","Abstract Artificial intelligence (AI) and other AI-based applications are being integrated into firms’ human resource management (HRM) approaches for managing people in domestic and international organisations. The last decade has seen a growth in AI-based applications proliferating the HRM function, triggering an exciting new stream of research on topics such as the social presence of AI and robotics, effects of AI adoption on individual and business level outcomes, and evaluating AI-enabled HRM practices. Adopting these technologies has resulted in how work is organised in local and international firms, noting opportunities for employees and firms’ resource utilisation, decision-making, and problem-solving. However, despite a growing interest in scholarship, research on AI-based technologies for HRM is limited and fragmented. Further research is needed that analyses the role of AI-assisted applications in HRM functions and human-AI interactions in large multinational enterprises diffusing such innovations. In response to these combined issues—the fragmented nature of research and limited extant literature, we present a systematic review on the theme of this special issue and offer a nuanced understating of what is known, yet to be known, and future research directions to frame a future research agenda for international HRM. We develop a conceptual framework that integrates research on AI applications in HRM and offers a cohesive base for future research endeavours. We also develop a set of testable propositions that serve as directions for future research."
AI (cs.AI),2022,13,"The Roles of Personality Traits, AI Anxiety, and Demographic Factors in Attitudes toward Artificial Intelligence",365,N/A,https://www.semanticscholar.org/paper/6fb5ca0ff6821a92b080d0654d245d2407484701,"Feridun Kaya, F. Aydın, A. Schepman et al.","Abstract The present study adapted the General Attitudes toward Artificial Intelligence Scale (GAAIS) to Turkish and investigated the impact of personality traits, artificial intelligence anxiety, and demographics on attitudes toward artificial intelligence. The sample consisted of 259 female (74%) and 91 male (26%) individuals aged between 18 and 51 (Mean = 24.23). Measures taken were demographics, the Ten-Item Personality Inventory, the Artificial Intelligence Anxiety Scale, and the General Attitudes toward Artificial Intelligence Scale. The Turkish GAAIS had good validity and reliability. Hierarchical Multiple Linear Regression Analyses showed that positive attitudes toward artificial intelligence were significantly predicted by the level of computer use (β = 0.139, p = 0.013), level of knowledge about artificial intelligence (β = 0.119, p = 0.029), and AI learning anxiety (β = −0.172, p = 0.004). Negative attitudes toward artificial intelligence were significantly predicted by agreeableness (β = 0.120, p = 0.019), AI configuration anxiety (β = −0.379, p < 0.001), and AI learning anxiety (β = −0.211, p < 0.001). Personality traits, AI anxiety, and demographics play important roles in attitudes toward AI. Results are discussed in light of the previous research and theoretical explanations."
AI (cs.AI),2022,6,"Artificial intelligence for industry 4.0: Systematic review of applications, challenges, and opportunities",348,N/A,https://www.semanticscholar.org/paper/c8b4dd24799080cce7431f320d8879d6b0fc2840,"Z. Jan, Farhad Ahamed, Wolfgang E Mayer et al.",No Abstract
AI (cs.AI),2022,17,"Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers",341,N/A,https://www.semanticscholar.org/paper/b36acdfc67612d707c95d1ed282672d3ca262be7,"C. Gao, F. Howard, N. Markov et al.","Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journal’s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94. Generated abstracts scored very high on originality using the plagiarism detector (100% [100, 100] originality). Generated abstracts had a similar patient cohort size as original abstracts, though the exact numbers were fabricated. When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, but that the generated abstracts were vaguer and had a formulaic feel to the writing. Conclusion ChatGPT writes believable scientific abstracts, though with completely generated data. These are original without any plagiarism detected but are often identifiable using an AI output detector and skeptical human reviewers. Abstract evaluation for journals and medical conferences must adapt policy and practice to maintain rigorous scientific standards; we suggest inclusion of AI output detectors in the editorial process and clear disclosure if these technologies are used. The boundaries of ethical and acceptable use of large language models to help scientific writing remain to be determined."
AI (cs.AI),2022,5,Measuring user competence in using artificial intelligence: validity and reliability of artificial intelligence literacy scale,339,N/A,https://www.semanticscholar.org/paper/767098d2e324258fec0d33148eec44f7955b56ce,"Bingcheng Wang, P. Rau, Tianyi Yuan","ABSTRACT As artificial intelligence (AI) became a part of daily life, it has become important to determine user competence in using AI technology. Here, we propose the concept of AI literacy and develop a quantitative scale for obtaining accurate data regarding the AI literacy of ordinary users. We first identified the primary core constructs of AI literacy, including awareness, use, evaluation, and ethics. Next, we generated 65 items to capture these four constructs; only 31 items were retained after a three-step content validation process. Then, we conducted a survey, and collected two samples of data. By reducing the number of items using the first sample and performing reliability and validity tests on the second sample, we obtained a 12-item instrument for the quantitative measurement of AI literacy. The results confirmed that the proposed four-construct model is an adequate representation of AI literacy. Further, AI literacy is significantly related to digital literacy, attitude towards robots, and users’ daily usage of AI. This study will not only aid researchers in understanding how user competence in using AI technology affects human–AI interactions but will also help designers develop AI applications that are aligned with the AI literacy levels of the target users."
AI (cs.AI),2022,19,Reporting guideline for the early stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI,327,N/A,https://www.semanticscholar.org/paper/3a8c344f67d5081ead5f7dd5ebf0f760d69fc01d,"B. Vasey, M. Nagendran, Bruce Campbell et al.","A growing number of artificial intelligence (AI)-based clinical decision support systems are showing promising performance in preclinical, in silico, evaluation, but few have yet demonstrated real benefit to patient care. Early stage clinical evaluation is important to assess an AI system’s actual clinical performance at small scale, ensure its safety, evaluate the human factors surrounding its use, and pave the way to further large scale trials. However, the reporting of these early studies remains inadequate. The present statement provides a multistakeholder, consensus-based reporting guideline for the Developmental and Exploratory Clinical Investigations of DEcision support systems driven by Artificial Intelligence (DECIDE-AI). We conducted a two round, modified Delphi process to collect and analyse expert opinion on the reporting of early clinical evaluation of AI systems. Experts were recruited from 20 predefined stakeholder categories. The final composition and wording of the guideline was determined at a virtual consensus meeting. The checklist and the Explanation & Elaboration (E&E) sections were refined based on feedback from a qualitative evaluation process. 123 experts participated in the first round of Delphi, 138 in the second, 16 in the consensus meeting, and 16 in the qualitative evaluation. The DECIDE-AI reporting guideline comprises 17 AI specific reporting items (made of 28 subitems) and 10 generic reporting items, with an E&E paragraph provided for each. Through consultation and consensus with a range of stakeholders, we have developed a guideline comprising key items that should be reported in early stage clinical studies of AI-based decision support systems in healthcare. By providing an actionable checklist of minimal reporting items, the DECIDE-AI guideline will facilitate the appraisal of these studies and replicability of their findings."
AI (cs.AI),2022,20,Aligning artificial intelligence with climate change mitigation,306,N/A,https://www.semanticscholar.org/paper/8e45e5d8e4d7ca24699b516105414b29f71431e2,"L. Kaack, P. Donti, Emma Strubell et al.",No Abstract
AI (cs.AI),2022,18,Artificial intelligence and the changing sources of competitive advantage,295,N/A,https://www.semanticscholar.org/paper/e86e95855ac23b70c1c6877b5eca079294c4ab02,"Sebastian Krakowski, Johannes Luger, Sebastian Raisch","Research Summary: We apply a resource-based view to investigate how the adoption of Artificial Intelligence (AI) affects competitive capabilities and performance. Following prior work on using chess as a controlled setting for studying competitive interactions, we compare the same players ’ capabilities and performance across conventional, centaur, and engine chess tournaments. Our analysis shows that AI adoption triggers interrelated sub-stitution and complementation dynamics, which make humans ’ traditional competitive capabilities obsolete, while creating new sources of persistent heterogeneity when humans interact with chess engines. These novel human-machine capabilities are unrelated, or even negatively related, to traditional capabilities. We contribute an integrated view of substitution and complementation, which identifies AI as the driver of these dynamics and explains how they jointly shift the sources of competitive advantage. Managerial Summary: AI-based technologies increasingly substitute and complement humans in managerial tasks such as decision making. We investigate how such change affects the sources of competitive advantage. AI-based engines ’ adoption in chess allows us to investigate competitive capabilities and performance in human, AI, and hybrid settings. We find that neither humans nor AI"
AI (cs.AI),2023,1,Sparks of Artificial General Intelligence: Early experiments with GPT-4,3769,2303.12712,https://www.semanticscholar.org/paper/8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c,"Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan et al.","Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions."
AI (cs.AI),2023,5,Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning,1940,N/A,https://www.semanticscholar.org/paper/7b6a8c6d44e0f77bf930484e438d77b7465a69fb,"David Baidoo-Anu, Leticia Owusu Ansah","Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning."
AI (cs.AI),2023,3,Revolutionizing healthcare: the role of artificial intelligence in clinical practice,1717,N/A,https://www.semanticscholar.org/paper/5cde474869cb230a29b3ba0f6f685f5162b1a1a1,"Shuroug A. Alowais, Sahar S. Alghamdi, Nada Alsuhebany et al.","Introduction Healthcare systems are complex and challenging for all stakeholders, but artificial intelligence (AI) has transformed various fields, including healthcare, with the potential to improve patient care and quality of life. Rapid AI advancements can revolutionize healthcare by integrating it into clinical practice. Reporting AI’s role in clinical practice is crucial for successful implementation by equipping healthcare providers with essential knowledge and tools. Research Significance This review article provides a comprehensive and up-to-date overview of the current state of AI in clinical practice, including its potential applications in disease diagnosis, treatment recommendations, and patient engagement. It also discusses the associated challenges, covering ethical and legal considerations and the need for human expertise. By doing so, it enhances understanding of AI’s significance in healthcare and supports healthcare organizations in effectively adopting AI technologies. Materials and Methods The current investigation analyzed the use of AI in the healthcare system with a comprehensive review of relevant indexed literature, such as PubMed/Medline, Scopus, and EMBASE, with no time constraints but limited to articles published in English. The focused question explores the impact of applying AI in healthcare settings and the potential outcomes of this application. Results Integrating AI into healthcare holds excellent potential for improving disease diagnosis, treatment selection, and clinical laboratory testing. AI tools can leverage large datasets and identify patterns to surpass human performance in several healthcare aspects. AI offers increased accuracy, reduced costs, and time savings while minimizing human errors. It can revolutionize personalized medicine, optimize medication dosages, enhance population health management, establish guidelines, provide virtual health assistants, support mental health care, improve patient education, and influence patient-physician trust. Conclusion AI can be used to diagnose diseases, develop personalized treatment plans, and assist clinicians with decision-making. Rather than simply automating tasks, AI is about developing technologies that can enhance patient care across healthcare settings. However, challenges related to data privacy, bias, and the need for human expertise must be addressed for the responsible and effective implementation of AI in healthcare."
AI (cs.AI),2023,2,Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum.,1634,N/A,https://www.semanticscholar.org/paper/a70c50bff01547f00ce341cd7e42797f11c4cdc7,"J. Ayers, Adam Poliak, Mark Dredze et al.","Importance The rapid expansion of virtual health care has caused a surge in patient messages concomitant with more work and burnout among health care professionals. Artificial intelligence (AI) assistants could potentially aid in creating answers to patient questions by drafting responses that could be reviewed by clinicians.   Objective To evaluate the ability of an AI chatbot assistant (ChatGPT), released in November 2022, to provide quality and empathetic responses to patient questions.   Design, Setting, and Participants In this cross-sectional study, a public and nonidentifiable database of questions from a public social media forum (Reddit's r/AskDocs) was used to randomly draw 195 exchanges from October 2022 where a verified physician responded to a public question. Chatbot responses were generated by entering the original question into a fresh session (without prior questions having been asked in the session) on December 22 and 23, 2022. The original question along with anonymized and randomly ordered physician and chatbot responses were evaluated in triplicate by a team of licensed health care professionals. Evaluators chose ""which response was better"" and judged both ""the quality of information provided"" (very poor, poor, acceptable, good, or very good) and ""the empathy or bedside manner provided"" (not empathetic, slightly empathetic, moderately empathetic, empathetic, and very empathetic). Mean outcomes were ordered on a 1 to 5 scale and compared between chatbot and physicians.   Results Of the 195 questions and responses, evaluators preferred chatbot responses to physician responses in 78.6% (95% CI, 75.0%-81.8%) of the 585 evaluations. Mean (IQR) physician responses were significantly shorter than chatbot responses (52 [17-62] words vs 211 [168-245] words; t = 25.4; P < .001). Chatbot responses were rated of significantly higher quality than physician responses (t = 13.3; P < .001). The proportion of responses rated as good or very good quality (≥ 4), for instance, was higher for chatbot than physicians (chatbot: 78.5%, 95% CI, 72.3%-84.1%; physicians: 22.1%, 95% CI, 16.4%-28.2%;). This amounted to 3.6 times higher prevalence of good or very good quality responses for the chatbot. Chatbot responses were also rated significantly more empathetic than physician responses (t = 18.9; P < .001). The proportion of responses rated empathetic or very empathetic (≥4) was higher for chatbot than for physicians (physicians: 4.6%, 95% CI, 2.1%-7.7%; chatbot: 45.1%, 95% CI, 38.5%-51.8%; physicians: 4.6%, 95% CI, 2.1%-7.7%). This amounted to 9.8 times higher prevalence of empathetic or very empathetic responses for the chatbot.   Conclusions In this cross-sectional study, a chatbot generated quality and empathetic responses to patient questions posed in an online forum. Further exploration of this technology is warranted in clinical settings, such as using chatbot to draft responses that physicians could then edit. Randomized trials could assess further if using AI assistants might improve responses, lower clinician burnout, and improve patient outcomes."
AI (cs.AI),2023,4,Foundation models for generalist medical artificial intelligence,1333,N/A,https://www.semanticscholar.org/paper/9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a,"Michael Moor, Oishi Banerjee, Zahra F H Abad et al.","The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices for medicine and will shift practices associated with the collection of large medical datasets. This review discusses generalist medical artificial intelligence, identifying potential applications and setting out specific technical capabilities and training datasets necessary to enable them, as well as highlighting challenges to its implementation."
AI (cs.AI),2023,7,Scientific discovery in the age of artificial intelligence,1255,N/A,https://www.semanticscholar.org/paper/f08060425aa8a212d74185ee23a08329b89abcd2,"Hanchen Wang, Tianfan Fu, Yuanqi Du et al.",No Abstract
AI (cs.AI),2023,6,ARTIFICIAL INTELLIGENCE FOR THE REAL WORLD,1091,N/A,https://www.semanticscholar.org/paper/7b72711ac2ea7bd7f519cac162a4a6578bbb7d0d,"Rajeev Ronanki, Andrew Nguyen",No Abstract
AI (cs.AI),2023,8,Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence,1031,N/A,https://www.semanticscholar.org/paper/bb01d7be9b49c8a018e134c7f132c39b7d9973ad,"Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh et al.",No Abstract
AI (cs.AI),2023,14,Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence,983,N/A,https://www.semanticscholar.org/paper/20c02c51420a69ae39b74d8d73148417819dacc1,"Vikas Hassija, V. Chamola, Atmesh Mahapatra et al.","Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy."
AI (cs.AI),2023,10,Experimental evidence on the productivity effects of generative artificial intelligence,956,N/A,https://www.semanticscholar.org/paper/8d020275181c69e5e768c6ffc40e09710a6f54f1,"Shakked Noy, Whitney Zhang","We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment. Description Editor’s summary Automation has historically displaced human workers in factories (e.g., automotive manufacturing) or in performing routine computational tasks. Will generative artificial intelligence (AI) tools such as ChatGPT disrupt the labor market by making educated professionals obsolete, or will these tools complement their skills and enhance productivity? Noy and Zhang examined this issue in an experiment that recruited college-educated professionals to complete incentivized writing tasks. Participants assigned to use ChatGPT were more productive, efficient, and enjoyed the tasks more. Participants with weaker skills benefited the most from ChatGPT, which carries policy implications for efforts to reduce productivity inequality through AI. —EEU The assistive chatbot ChatGPT raises productivity in professional writing tasks and reduces productivity inequality."
AI (cs.AI),2023,9,Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence,824,N/A,https://www.semanticscholar.org/paper/6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab,G. Cooper,"The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education."
AI (cs.AI),2023,13,Artificial intelligence in higher education: the state of the field,814,N/A,https://www.semanticscholar.org/paper/e251ba9fe7992fc07a01365a5f8f2b4d9020b875,"H. Crompton, D. Burke","This systematic review provides unique findings with an up-to-date examination of artificial intelligence (AI) in higher education (HE) from 2016 to 2022. Using PRISMA principles and protocol, 138 articles were identified for a full examination. Using a priori, and grounded coding, the data from the 138 articles were extracted, analyzed, and coded. The findings of this study show that in 2021 and 2022, publications rose nearly two to three times the number of previous years. With this rapid rise in the number of AIEd HE publications, new trends have emerged. The findings show that research was conducted in six of the seven continents of the world. The trend has shifted from the US to China leading in the number of publications. Another new trend is in the researcher affiliation as prior studies showed a lack of researchers from departments of education. This has now changed to be the most dominant department. Undergraduate students were the most studied students at 72%. Similar to the findings of other studies, language learning was the most common subject domain. This included writing, reading, and vocabulary acquisition. In examination of who the AIEd was intended for 72% of the studies focused on students, 17% instructors, and 11% managers. In answering the overarching question of how AIEd was used in HE, grounded coding was used. Five usage codes emerged from the data: (1) Assessment/Evaluation, (2) Predicting, (3) AI Assistant, (4) Intelligent Tutoring System (ITS), and (5) Managing Student Learning. This systematic review revealed gaps in the literature to be used as a springboard for future researchers, including new tools, such as Chat GPT. A systematic review examining AIEd in higher education (HE) up to the end of 2022. Unique findings in the switch from US to China in the most studies published. A two to threefold increase in studies published in 2021 and 2022 to prior years. AIEd was used for: Assessment/Evaluation, Predicting, AI Assistant, Intelligent Tutoring System, and Managing Student Learning."
AI (cs.AI),2023,16,Explainable Artificial Intelligence (XAI),750,N/A,https://www.semanticscholar.org/paper/e1d2f2a717aa03280126f87c8e5fad695f52bf7c,"Ranu Sewada, Ashwani Jangid, Piyush Kumar et al.","Explainable Artificial Intelligence (XAI) has emerged as a critical facet in the realm of machine learning and artificial intelligence, responding to the increasing complexity of models, particularly deep neural networks, and the subsequent need for transparent decision making processes. This research paper delves into the essence of XAI, unraveling its significance across diverse domains such as healthcare, finance, and criminal justice. As a countermeasure to the opacity of intricate models, the paper explores various XAI methods and techniques, including LIME and SHAP, weighing their interpretability against computational efficiency and accuracy. Through an examination of real-world applications, the research elucidates how XAI not only enhances decision-making processes but also influences user trust and acceptance in AI systems. However, the paper also scrutinizes the delicate balance between interpretability and performance, shedding light on instances where the pursuit of accuracy may compromise explain-ability. Additionally, it navigates through the current challenges and limitations in XAI, the regulatory landscape surrounding AI explain-ability, and offers insights into future trends and directions, fostering a comprehensive understanding of XAI's present state and future potential."
AI (cs.AI),2023,15,ChatGPT and a new academic reality: Artificial Intelligence‐written research papers and the ethics of the large language models in scholarly publishing,657,2303.13367,https://www.semanticscholar.org/paper/da9683e826c37a6383c124b5c6cddefcb35ee8fd,"Brady D. Lund, Ting Wang, Nishith Reddy Mannuru et al.","This article discusses OpenAI's ChatGPT, a generative pre‐trained transformer, which uses natural language processing to fulfill text‐based user requests (i.e., a “chatbot”). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT‐3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing."
AI (cs.AI),2023,19,From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing.,561,N/A,https://www.semanticscholar.org/paper/a3c0719d847a8cab836500a0ee3b9f4717ed136d,"Ismail Dergaa, K. Chamari, P. Żmijewski et al.","Natural language processing (NLP) has been studied in computing for decades. Recent technological advancements have led to the development of sophisticated artificial intelligence (AI) models, such as Chat Generative Pre-trained Transformer (ChatGPT). These models can perform a range of language tasks and generate human-like responses, which offers exciting prospects for academic efficiency. This manuscript aims at (i) exploring the potential benefits and threats of ChatGPT and other NLP technologies in academic writing and research publications; (ii) highlights the ethical considerations involved in using these tools, and (iii) consider the impact they may have on the authenticity and credibility of academic work. This study involved a literature review of relevant scholarly articles published in peer-reviewed journals indexed in Scopus as quartile 1. The search used keywords such as ""ChatGPT,"" ""AI-generated text,"" ""academic writing,"" and ""natural language processing."" The analysis was carried out using a quasi-qualitative approach, which involved reading and critically evaluating the sources and identifying relevant data to support the research questions. The study found that ChatGPT and other NLP technologies have the potential to enhance academic writing and research efficiency. However, their use also raises concerns about the impact on the authenticity and credibility of academic work. The study highlights the need for comprehensive discussions on the potential use, threats, and limitations of these tools, emphasizing the importance of ethical and academic principles, with human intelligence and critical thinking at the forefront of the research process. This study highlights the need for comprehensive debates and ethical considerations involved in their use. The study also recommends that academics exercise caution when using these tools and ensure transparency in their use, emphasizing the importance of human intelligence and critical thinking in academic work."
AI (cs.AI),2023,18,"Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",483,2304.07683,https://www.semanticscholar.org/paper/53b04ccd2a001467d7ce168e9ce20b16a9466a69,Emilio Ferrara,"The significant advancements in applying artificial intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems. This is particularly critical in areas like healthcare, employment, criminal justice, credit scoring, and increasingly, in generative AI models (GenAI) that produce synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including generative biases that affect the representation of individuals in synthetic data. This survey study offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases—highlighting the emergent issue of generative AI bias, where models may reproduce and amplify societal stereotypes. We assess the societal impact of biased AI systems, focusing on perpetuating inequalities and reinforcing harmful stereotypes, especially as generative AI becomes more prevalent in creating content that influences public perception. We explore various proposed mitigation strategies, discuss the ethical considerations of their implementation, and emphasize the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, including a detailed look at generative AI bias. We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these. Addressing bias in AI requires a holistic approach involving diverse and representative datasets, enhanced transparency and accountability in AI systems, and the exploration of alternative AI paradigms that prioritize fairness and ethical considerations. This survey contributes to the ongoing discussion on developing fair and unbiased AI systems by providing an overview of the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the emerging field of generative AI."
AI (cs.AI),2023,20,"The effect of generative artificial intelligence (AI)-based tool use on students' computational thinking skills, programming self-efficacy and motivation",472,N/A,https://www.semanticscholar.org/paper/bba8881f49b43b5a6d018607162261606ee01c05,"Ramazan Yılmaz, F. Yilmaz",No Abstract
AI (cs.AI),2023,17,Teacher support and student motivation to learn with Artificial Intelligence (AI) based chatbot,432,N/A,https://www.semanticscholar.org/paper/baedb763204fb1b35330d3ba706539b9f90dc738,"Thomas K. F. Chiu, Benjamin Luke Moorhouse, C. Chai et al.","ABSTRACT As Artificial Intelligence (AI) advances technologically, it will inevitably bring many changes to classroom practices. However, research on AI in education reflects a weak connection to pedagogical perspectives or instructional approaches, particularly in K-12 education. AI technologies may benefit motivated and advanced students. Understanding the teacher’s role of student motivation in mediating and supporting learning with AI technologies in the classroom is needed. This study used self-determination theory as the undergirding framework to investigate how teacher support moderates the effects of student expertise on needs satisfactions and intrinsic motivation to learn with AI technologies. This experimental study involved 123 Grade 10 students, and used chatbots as AI-based technologies in the experiment. The analyses revealed that intrinsic motivation and competence to learn with the chatbot depended on both teacher support and student expertise (i.e. self-regulated learning and digital literacy), and the teacher support better satisfied the need for relatedness, and it less satisfied the need for autonomy. The findings refined our understanding about the application of self-determination theory and expand the pedagogical and design considerations of AI application and instructional practices."
AI (cs.AI),2023,11,Artificial Intelligence Risk Management Framework (AI RMF 1.0),425,N/A,https://www.semanticscholar.org/paper/791522e891976ae6dae427b215f04df58be33298,"AI Nist, Secretary Gina M. Raimondo, L. Locascio",No Abstract
AI (cs.AI),2023,12,Managing artificial intelligence,364,N/A,https://www.semanticscholar.org/paper/31f76619329aba7987394ccb8cac6c9a6dd58a56,P. Krausman,No Abstract
Computer Vision (cs.CV),2022,1,Design and Development of Cost-Effective Child Surveillance System using Computer Vision Technology,3012,N/A,https://www.semanticscholar.org/paper/290f40b6e5ad78a7f5c2cb226e48f98132843d9f,"Vedavyas Peddiraju, Ramchandar Rao Pamulaparthi, Chakaradhar Adupa et al.","The project's primary goal is to ensure child surveillance, continuous monitor and alert system for safety. Pre-defined navigation is one of the primary challenges in the robotic industry. Many technologies have been developed to overcome these problems. The project utilizes a high-quality night vision camera that is installed on a navigation robot that moves in the pre-defined path. The night vision camera captures the image and video of child activity, and transmits the data to the main system. The navigation robot is also equipped with the passive infrared (PIR) sensor to monitor any unauthorized human face intervention for child abuduction, and sound sensor for cry detection. The sound sensor detects the crying of the child and gives alert to the parent for immediate assistance.re will be developed using Python in the Google Colab."
Computer Vision (cs.CV),2022,3,"Computer Vision - Algorithms and Applications, Second Edition",433,N/A,https://www.semanticscholar.org/paper/bb4f529b5bc26f39e6b144fc4cf4d545fb836b89,R. Szeliski,No Abstract
Computer Vision (cs.CV),2022,2,Plant Leaf Disease Detection using Computer Vision and Machine Learning Algorithms,341,N/A,https://www.semanticscholar.org/paper/2b55d9ee470af28b2c23e1bc52b5eb0cea34c9af,"Sunil S. Harakannanavar, J. Rudagi, Veena I. Puranikmath et al.",No Abstract
Computer Vision (cs.CV),2022,4,WilDect-YOLO: An efficient and robust computer vision-based accurate object localization model for automated endangered wildlife detection,212,N/A,https://www.semanticscholar.org/paper/31d293f796c7a4ba8d8a8c15b4ee266323015d43,"Anisha Roy, Jayabrata Bhaduri, Teerath Kumar et al.",No Abstract
Computer Vision (cs.CV),2022,10,Deep learning based computer vision approaches for smart agricultural applications,202,N/A,https://www.semanticscholar.org/paper/34180b2b253139d620a8ccbaf7f369aabad45f94,"V. G. Dhanya, A. Subeesh, N.L. Kushwaha et al.",No Abstract
Computer Vision (cs.CV),2022,5,A Review on Machine Learning Styles in Computer Vision—Techniques and Future Directions,154,N/A,https://www.semanticscholar.org/paper/59694d8b594ac2bb0f91dd4a0d681133f976939a,"Supriya V. Mahadevkar, Bharti Khemani, S. Patil et al.","Computer applications have considerably shifted from single data processing to machine learning in recent years due to the accessibility and availability of massive volumes of data obtained through the internet and various sources. Machine learning is automating human assistance by training an algorithm on relevant data. Supervised, Unsupervised, and Reinforcement Learning are the three fundamental categories of machine learning techniques. In this paper, we have discussed the different learning styles used in the field of Computer vision, Deep Learning, Neural networks, and machine learning. Some of the most recent applications of machine learning in computer vision include object identification, object classification, and extracting usable information from images, graphic documents, and videos. Some machine learning techniques frequently include zero-shot learning, active learning, contrastive learning, self-supervised learning, life-long learning, semi-supervised learning, ensemble learning, sequential learning, and multi-view learning used in computer vision until now. There is a lack of systematic reviews about all learning styles. This paper presents literature analysis of how different machine learning styles evolved in the field of Artificial Intelligence (AI) for computer vision. This research examines and evaluates machine learning applications in computer vision and future forecasting. This paper will be helpful for researchers working with learning styles as it gives a deep insight into future directions."
Computer Vision (cs.CV),2022,7,Computer vision in surgery: from potential to clinical value,137,N/A,https://www.semanticscholar.org/paper/a41cf49d132f821927f4c06d4944fa87f60f1278,"P. Mascagni, Deepak Alapatt, Luca Sestini et al.","Hundreds of millions of operations are performed worldwide each year, and the rising uptake in minimally invasive surgery has enabled fiber optic cameras and robots to become both important tools to conduct surgery and sensors from which to capture information about surgery. Computer vision (CV), the application of algorithms to analyze and interpret visual data, has become a critical technology through which to study the intraoperative phase of care with the goals of augmenting surgeons’ decision-making processes, supporting safer surgery, and expanding access to surgical care. While much work has been performed on potential use cases, there are currently no CV tools widely used for diagnostic or therapeutic applications in surgery. Using laparoscopic cholecystectomy as an example, we reviewed current CV techniques that have been applied to minimally invasive surgery and their clinical applications. Finally, we discuss the challenges and obstacles that remain to be overcome for broader implementation and adoption of CV in surgery."
Computer Vision (cs.CV),2022,8,"A Comprehensive Review of Computer Vision in Sports: Open Issues, Future Trends and Research Directions",131,2203.02281,https://www.semanticscholar.org/paper/050f3f3770dd600fd99644bccdf60719a4a2bf4d,"Banoth Thulasya Naik, Mohammad Farukh Hashmi, N. Bokde","Recent developments in video analysis of sports and computer vision techniques have achieved significant improvements to enable a variety of critical operations. To provide enhanced information, such as detailed complex analysis in sports like soccer, basketball, cricket, badminton, etc., studies have focused mainly on computer vision techniques employed to carry out different tasks. This paper presents a comprehensive review of sports video analysis for various applications high-level analysis such as detection and classification of players, tracking player or ball in sports and predicting the trajectories of player or ball, recognizing the teams strategies, classifying various events in sports. The paper further discusses published works in a variety of application-specific tasks related to sports and the present researchers views regarding them. Since there is a wide research scope in sports for deploying computer vision techniques in various sports, some of the publicly available datasets related to a particular sport have been provided. This work reviews a detailed discussion on some of the artificial intelligence(AI)applications in sports vision, GPU-based work stations, and embedded platforms. Finally, this review identifies the research directions, probable challenges, and future trends in the area of visual recognition in sports."
Computer Vision (cs.CV),2022,6,"Computer vision and machine learning for medical image analysis: recent advances, challenges, and way forward",128,N/A,https://www.semanticscholar.org/paper/7fe995a220a9a1f3fad5539b71d12b13ea6c943a,"Eyad Elyan, Pattaramon Vuttipittayamongkol, Pamela Johnston et al.","The recent development in the areas of deep learning and deep convolutional neural networks has significantly progressed and advanced the field of computer vision (CV) and image analysis and understanding. Complex tasks such as classifying and segmenting medical images and localising and recognising objects of interest have become much less challenging. This progress has the potential of accelerating research and deployment of multitudes of medical applications that utilise CV. However, in reality, there are limited practical examples being physically deployed into front-line health facilities. In this paper, we examine the current state of the art in CV as applied to the medical domain. We discuss the main challenges in CV and intelligent data-driven medical applications and suggest future directions to accelerate research, development, and deployment of CV applications in health practices. First, we critically review existing literature in the CV domain that addresses complex vision tasks, including: medical image classification; shape and object recognition from images; and medical segmentation. Second, we present an in-depth discussion of the various challenges that are considered barriers to accelerating research, development, and deployment of intelligent CV methods in real-life medical applications and hospitals. Finally, we conclude by discussing future directions."
Computer Vision (cs.CV),2022,9,A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective,122,2209.13232,https://www.semanticscholar.org/paper/741a7faf9dbefd418cda878c61c5b839ecc02977,"Chaoqi Chen, Yushuang Wu, Qiyuan Dai et al.","Graph Neural Networks (GNNs) have gained momentum in graph representation learning and boosted the state of the art in a variety of areas, such as data mining (e.g., social network analysis and recommender systems), computer vision (e.g., object detection and point cloud learning), and natural language processing (e.g., relation extraction and sequence learning), to name a few. With the emergence of Transformers in natural language processing and computer vision, graph Transformers embed a graph structure into the Transformer architecture to overcome the limitations of local neighborhood aggregation while avoiding strict structural inductive biases. In this paper, we present a comprehensive review of GNNs and graph Transformers in computer vision from a task-oriented perspective. Specifically, we divide their applications in computer vision into five categories according to the modality of input data, i.e., 2D natural images, videos, 3D data, vision + language, and medical images. In each category, we further divide the applications according to a set of vision tasks. Such a task-oriented taxonomy allows us to examine how each task is tackled by different GNN-based approaches and how well these approaches perform. Based on the necessary preliminaries, we provide the definitions and challenges of the tasks, in-depth coverage of the representative approaches, as well as discussions regarding insights, limitations, and future directions."
Computer Vision (cs.CV),2022,11,Physical Adversarial Attack Meets Computer Vision: A Decade Survey,106,2209.15179,https://www.semanticscholar.org/paper/2a89dbafb45e4f811114685a6327558bdb4d1141,"Hui Wei, Hao Tang, Xuemei Jia et al.","Despite the impressive achievements of Deep Neural Networks (DNNs) in computer vision, their vulnerability to adversarial attacks remains a critical concern. Extensive research has demonstrated that incorporating sophisticated perturbations into input images can lead to a catastrophic degradation in DNNs’ performance. This perplexing phenomenon not only exists in the digital space but also in the physical world. Consequently, it becomes imperative to evaluate the security of DNNs-based systems to ensure their safe deployment in real-world scenarios, particularly in security-sensitive applications. To facilitate a profound understanding of this topic, this paper presents a comprehensive overview of physical adversarial attacks. First, we distill four general steps for launching physical adversarial attacks. Building upon this foundation, we uncover the pervasive role of artifacts carrying adversarial perturbations in the physical world. These artifacts influence each step. To denote them, we introduce a new term: adversarial medium. Then, we take the first step to systematically evaluate the performance of physical adversarial attacks, taking the adversarial medium as a first attempt. Our proposed evaluation metric, hiPAA, comprises six perspectives: Effectiveness, Stealthiness, Robustness, Practicability, Aesthetics, and Economics. We also provide comparative results across task categories, together with insightful observations and suggestions for future research directions."
Computer Vision (cs.CV),2022,12,Computer Vision for Road Imaging and Pothole Detection: A State-of-the-Art Review of Systems and Algorithms,101,2204.13590,https://www.semanticscholar.org/paper/50ac326df96467408c7531446e9c57e2d9ac4407,"Nachuan Ma, Jiahe Fan, Wenshuo Wang et al.","  Computer vision algorithms have been utilized for 3-D road imaging and pothole detection for over two decades. Nonetheless, there is a lack of systematic survey articles on state-of-the-art (SoTA) computer vision techniques, especially deep learning models, developed to tackle these problems. This article first introduces the sensing systems employed for 2-D and 3-D road data acquisition, including camera(s), laser scanners and Microsoft Kinect. It then comprehensively reviews the SoTA computer vision algorithms, including (1) classical 2-D image processing, (2) 3-D point cloud modelling and segmentation and (3) machine/deep learning, developed for road pothole detection. The article also discusses the existing challenges and future development trends of computer vision-based road pothole detection approaches: classical 2-D image processing-based and 3-D point cloud modelling and segmentation-based approaches have already become history; and convolutional neural networks (CNNs) have demonstrated compelling road pothole detection results and are promising to break the bottleneck with future advances in self/un-supervised learning for multi-modal semantic segmentation. We believe that this survey can serve as practical guidance for developing the next-generation road condition assessment systems."
Computer Vision (cs.CV),2022,14,A Review of Synthetic Image Data and Its Use in Computer Vision,97,N/A,https://www.semanticscholar.org/paper/07ca0f873aba7b71283bf6aeddb4025a5d5e2b9f,"Keith Man, J. Chahl","Development of computer vision algorithms using convolutional neural networks and deep learning has necessitated ever greater amounts of annotated and labelled data to produce high performance models. Large, public data sets have been instrumental in pushing forward computer vision by providing the data necessary for training. However, many computer vision applications cannot rely on general image data provided in the available public datasets to train models, instead requiring labelled image data that is not readily available in the public domain on a large scale. At the same time, acquiring such data from the real world can be difficult, costly to obtain, and manual labour intensive to label in large quantities. Because of this, synthetic image data has been pushed to the forefront as a potentially faster and cheaper alternative to collecting and annotating real data. This review provides general overview of types of synthetic image data, as categorised by synthesised output, common methods of synthesising different types of image data, existing applications and logical extensions, performance of synthetic image data in different applications and the associated difficulties in assessing data performance, and areas for further research."
Computer Vision (cs.CV),2022,15,Vision Transformers in Medical Computer Vision - A Contemplative Retrospection,94,2203.15269,https://www.semanticscholar.org/paper/224ecc21a917dd246420d2da0b3edee5834f3391,"Arshi Parvaiz, Muhammad Anwaar Khalid, Rukhsana Zafar et al.","Recent escalation in the field of computer vision underpins a huddle of algorithms with the magnificent potential to unravel the information contained within images. These computer vision algorithms are being practised in medical image analysis and are transfiguring the perception and interpretation of Imaging data. Among these algorithms, Vision Transformers are evolved as one of the most contemporary and dominant architectures that are being used in the field of computer vision. These are immensely utilized by a plenty of researchers to perform new as well as former experiments. Here, in this article we investigate the intersection of Vision Transformers and Medical images and proffered an overview of various ViTs based frameworks that are being used by different researchers in order to decipher the obstacles in Medical Computer Vision. We surveyed the application of Vision transformers in different areas of medical computer vision such as image-based disease classification, anatomical structure segmentation, registration, region-based lesion Detection, captioning, report generation, reconstruction using multiple medical imaging modalities that greatly assist in medical diagnosis and hence treatment process. Along with this, we also demystify several imaging modalities used in Medical Computer Vision. Moreover, to get more insight and deeper understanding, self-attention mechanism of transformers is also explained briefly. Conclusively, we also put some light on available data sets, adopted methodology, their performance measures, challenges and their solutions in form of discussion. We hope that this review article will open future directions for researchers in medical computer vision."
Computer Vision (cs.CV),2022,13,Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers,86,2203.04913,https://www.semanticscholar.org/paper/1b3142ee576017e5aa34aac94c658f948b75dbcd,"Dominik Zietlow, Michael Lohaus, Guha Balakrishnan et al.","Algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. Contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the performance of classifiers across all groups (with increased degradation on the best performing groups). Extending the bias-variance decomposition for classification to fairness, we theoretically explain why the majority of fairness methods designed for low capacity models should not be used in settings involving high-capacity models, a scenario common to computer vision. We corroborate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. Building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups."
Computer Vision (cs.CV),2022,16,A Computer Vision-Based Intelligent Fish Feeding System Using Deep Learning Techniques for Aquaculture,84,N/A,https://www.semanticscholar.org/paper/e68df12423e2a7b64511c04c5958e79679c86157,"Wu-Chih Hu, Liang-Bi Chen, Bo-Kai Huang et al.","The decisions made regarding traditional fish feeding systems mainly depend on experience and simple time control. Most previous works have focused on image-based analysis of the leftover feed at the bottom of the pond to determine whether to continue or to stop feeding. However, the feasibility of such a method in an actual outdoor aquaculture pond is low. The main reason for this is that real outdoor aquaculture ponds have turbid water quality, small feed targets, interference from intense fish activity, overlapping images of fish and feed, etc. Therefore, image-based recognition is not easy to implement in actual outdoor aquaculture. To overcome this problem, this article proposes an automatic fish feeding system based on deep learning computer vision technology. In contrast to traditional computer-vision-based systems for recognizing fish feed underwater, the proposed system uses deep learning technology to recognize the size of the waves caused by fish eating feed to determine whether to continue or to stop feeding. Furthermore, several water quality sensors are adopted to assist in feeding decisions. As a result, the proposed system uses deep learning technology to recognize the size of the water waves caused by fish eating feed to determine whether to continue to cast feed or to stop feeding. Experimental results show that an accuracy of up to 93.2% can be achieved."
Computer Vision (cs.CV),2022,17,Deep grading of mangoes using Convolutional Neural Network and Computer Vision,83,N/A,https://www.semanticscholar.org/paper/5c2c0f90e1b540d2b56e6218ff4c635816b7ad0f,"N. Gururaj, Viji Vinod, K. Vijayakumar",No Abstract
Computer Vision (cs.CV),2022,18,Computer Vision System for Mango Fruit Defect Detection Using Deep Convolutional Neural Network,78,N/A,https://www.semanticscholar.org/paper/76c1051aff56c89383843a76b014888cd6fbf72b,"R. Nithya, B. Santhi, R. Manikandan et al.","Machine learning techniques play a significant role in agricultural applications for computerized grading and quality evaluation of fruits. In the agricultural domain, automation improves the quality, productivity, and economic growth of a country. The quality grading of fruits is an essential measure in the export market, especially defect detection of a fruit’s surface. This is especially pertinent for mangoes, which are highly popular in India. However, the manual grading of mango is a time-consuming, inconsistent, and subjective process. Therefore, a computer-assisted grading system has been developed for defect detection in mangoes. Recently, machine learning techniques, such as the deep learning method, have been used to achieve efficient classification results in digital image classification. Specifically, the convolution neural network (CNN) is a deep learning technique that is employed for automated defect detection in mangoes. This study proposes a computer-vision system, which employs CNN, for the classification of quality mangoes. After training and testing the system using a publicly available mango database, the experimental results show that the proposed method acquired an accuracy of 98%."
Computer Vision (cs.CV),2022,19,A Comprehensive Survey of Transformers for Computer Vision,78,2211.06004,https://www.semanticscholar.org/paper/55025dbf6e26a868356bd3c03dde5b10e1a6cbd7,"Sonain Jamil, Md. Jalil Piran, Oh-Jin Kwon","As a special type of transformer, Vision Transformers (ViTs) are used to various computer vision applications (CV), such as image recognition. There are several potential problems with convolutional neural networks (CNNs) that can be solved with ViTs. For image coding tasks like compression, super-resolution, segmentation, and denoising, different variants of the ViTs are used. The purpose of this survey is to present the first application of ViTs in CV. The survey is the first of its kind on ViTs for CVs to the best of our knowledge. In the first step, we classify different CV applications where ViTs are applicable. CV applications include image classification, object detection, image segmentation, image compression, image super-resolution, image denoising, and anomaly detection. Our next step is to review the state-of-the-art in each category and list the available models. Following that, we present a detailed analysis and comparison of each model and list its pros and cons. After that, we present our insights and lessons learned for each category. Moreover, we discuss several open research challenges and future research directions."
Computer Vision (cs.CV),2022,20,Dissecting Self-Supervised Learning Methods for Surgical Computer Vision,65,2207.00449,https://www.semanticscholar.org/paper/c118fd58ee236828baab90e4aba660df88ea4174,"Sanat Ramesh, V. Srivastav, Deepak Alapatt et al.","The field of surgical computer vision has undergone considerable breakthroughs in recent years with the rising popularity of deep neural network-based methods. However, standard fully-supervised approaches for training such models require vast amounts of annotated data, imposing a prohibitively high cost; especially in the clinical domain. Self-Supervised Learning (SSL) methods, which have begun to gain traction in the general computer vision community, represent a potential solution to these annotation costs, allowing to learn useful representations from only unlabeled data. Still, the effectiveness of SSL methods in more complex and impactful domains, such as medicine and surgery, remains limited and unexplored. In this work, we address this critical need by investigating four state-of-the-art SSL methods (MoCo v2, SimCLR, DINO, SwAV) in the context of surgical computer vision. We present an extensive analysis of the performance of these methods on the Cholec80 dataset for two fundamental and popular tasks in surgical context understanding, phase recognition and tool presence detection. We examine their parameterization, then their behavior with respect to training data quantities in semi-supervised settings. Correct transfer of these methods to surgery, as described and conducted in this work, leads to substantial performance gains over generic uses of SSL - up to 7.4% on phase recognition and 20% on tool presence detection - as well as state-of-the-art semi-supervised phase recognition approaches by up to 14%. Further results obtained on a highly diverse selection of surgical datasets exhibit strong generalization properties. The code is available at https://github.com/CAMMA-public/SelfSupSurg."
Computer Vision (cs.CV),2023,1,A Comprehensive Review of YOLO Architectures in Computer Vision: From YOLOv1 to YOLOv8 and YOLO-NAS,1979,2304.00501,https://www.semanticscholar.org/paper/913d86a84afae61b51281a1bce2edbd72b7c7acb,"Juan R. Terven, Diana-Margarita Córdova-Esparza, J. Romero-González","YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO’s evolution, examining the innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS, and YOLO with transformers. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO’s development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems."
Computer Vision (cs.CV),2023,5,Computer vision framework for crack detection of civil infrastructure - A review,205,N/A,https://www.semanticscholar.org/paper/6a70ca3a50eeee6cf776bfa3fed88bba84ba6739,"Dihao Ai, Guiyuan Jiang, Siew-Kei Lam et al.",No Abstract
Computer Vision (cs.CV),2023,4,Computer vision-based hand gesture recognition for human-robot interaction: a review,159,N/A,https://www.semanticscholar.org/paper/bb289f2b87a666eda971075dbc95b82920260aa8,"Jing Qi, Li Ma, Zhenchao Cui et al.","As robots have become more pervasive in our daily life, natural human-robot interaction (HRI) has had a positive impact on the development of robotics. Thus, there has been growing interest in the development of vision-based hand gesture recognition for HRI to bridge human-robot barriers. The aim is for interaction with robots to be as natural as that between individuals. Accordingly, incorporating hand gestures in HRI is a significant research area. Hand gestures can provide natural, intuitive, and creative methods for communicating with robots. This paper provides an analysis of hand gesture recognition using both monocular cameras and RGB-D cameras for this purpose. Specifically, the main process of visual gesture recognition includes data acquisition, hand gesture detection and segmentation, feature extraction and gesture classification, which are discussed in this paper. Experimental evaluations are also reviewed. Furthermore, algorithms of hand gesture recognition for human-robot interaction are examined in this study. In addition, the advances required for improvement in the present hand gesture recognition systems, which can be applied for effective and efficient human-robot interaction, are discussed."
Computer Vision (cs.CV),2023,9,Intelligent metasurface system for automatic tracking of moving targets and wireless communications based on computer vision,116,N/A,https://www.semanticscholar.org/paper/b134e72ffea299e6e4fbe47c326bd9afa31c7dc6,"Weihan Li, Qian Ma, Che Liu et al.","The fifth-generation (5G) wireless communication has an urgent need for target tracking. Digital programmable metasurface (DPM) may offer an intelligent and efficient solution owing to its powerful and flexible controls of electromagnetic waves and advantages of lower cost, less complexity and smaller size than the traditional antenna array. Here, we report an intelligent metasurface system to perform target tracking and wireless communications, in which computer vision integrated with a convolutional neural network (CNN) is used to automatically detect the locations of moving targets, and the dual-polarized DPM integrated with a pre-trained artificial neural network (ANN) serves to realize the smart beam tracking and wireless communications. Three groups of experiments are conducted for demonstrating the intelligent system: detection and identification of moving targets, detection of radio-frequency signals, and real-time wireless communications. The proposed method sets the stage for an integrated implementation of target identification, radio environment tracking, and wireless communications. This strategy opens up an avenue for intelligent wireless networks and self-adaptive systems. The authors present an intelligent metasurface system that uses a target detection algorithm combined with a depth camera, to automatically detect the position of moving targets and achieve real-time wireless communications. The system can operate for multiple targets in limited ambient light, outdoor and other realistic environments."
Computer Vision (cs.CV),2023,3,A study on computer vision for facial emotion recognition,100,N/A,https://www.semanticscholar.org/paper/e176b5bd3af6e9d628ddaf49b4f23742fc6dc613,"Ziqiang Huang, Chia-Chin Chiang, Jian-Hao Chen et al.","Artificial intelligence has been successfully applied in various fields, one of which is computer vision. In this study, a deep neural network (DNN) was adopted for Facial emotion recognition (FER). One of the objectives in this study is to identify the critical facial features on which the DNN model focuses for FER. In particular, we utilized a convolutional neural network (CNN), the combination of squeeze-and-excitation network and the residual neural network, for the task of FER. We utilized AffectNet and the Real-World Affective Faces Database (RAF-DB) as the facial expression databases that provide learning samples for the CNN. The feature maps were extracted from the residual blocks for further analysis. Our analysis shows that the features around the nose and mouth are critical facial landmarks for the neural networks. Cross-database validations were conducted between the databases. The network model trained on AffectNet achieved 77.37% accuracy when validated on the RAF-DB, while the network model pretrained on AffectNet and then transfer learned on the RAF-DB results in validation accuracy of 83.37%. The outcomes of this study would improve the understanding of neural networks and assist with improving computer vision accuracy."
Computer Vision (cs.CV),2023,10,Computer Vision-Based Bridge Inspection and Monitoring: A Review,98,N/A,https://www.semanticscholar.org/paper/7c35889fad5a22fa6b899c600716d539ef38f541,"Kui Luo, Xuan Kong, J. Zhang et al.","Bridge inspection and monitoring are usually used to evaluate the status and integrity of bridge structures to ensure their safety and reliability. Computer vision (CV)-based methods have the advantages of being low cost, simple to operate, remote, and non-contact, and have been widely used in bridge inspection and monitoring in recent years. Therefore, this paper reviews three significant aspects of CV-based methods, including surface defect detection, vibration measurement, and vehicle parameter identification. Firstly, the general procedure for CV-based surface defect detection is introduced, and its application for the detection of cracks, concrete spalling, steel corrosion, and multi-defects is reviewed, followed by the robot platforms for surface defect detection. Secondly, the basic principle of CV-based vibration measurement is introduced, followed by the application of displacement measurement, modal identification, and damage identification. Finally, the CV-based vehicle parameter identification methods are introduced and their application for the identification of temporal and spatial parameters, weight parameters, and multi-parameters are summarized. This comprehensive literature review aims to provide guidance for selecting appropriate CV-based methods for bridge inspection and monitoring."
Computer Vision (cs.CV),2023,2,Computer Vision Applications in Intelligent Transportation Systems: A Survey,94,N/A,https://www.semanticscholar.org/paper/c988c6631df77482313dac577e3b02d8b696d85d,"Esma Dilek, Murat Dener","As technology continues to develop, computer vision (CV) applications are becoming increasingly widespread in the intelligent transportation systems (ITS) context. These applications are developed to improve the efficiency of transportation systems, increase their level of intelligence, and enhance traffic safety. Advances in CV play an important role in solving problems in the fields of traffic monitoring and control, incident detection and management, road usage pricing, and road condition monitoring, among many others, by providing more effective methods. This survey examines CV applications in the literature, the machine learning and deep learning methods used in ITS applications, the applicability of computer vision applications in ITS contexts, the advantages these technologies offer and the difficulties they present, and future research areas and trends, with the goal of increasing the effectiveness, efficiency, and safety level of ITS. The present review, which brings together research from various sources, aims to show how computer vision techniques can help transportation systems to become smarter by presenting a holistic picture of the literature on different CV applications in the ITS context."
Computer Vision (cs.CV),2023,7,Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks,91,2310.19909,https://www.semanticscholar.org/paper/f1c6aaf4a01c859eb3dcd1c66b8397a643fbcf11,"Micah Goldblum, Hossein Souri, Renkun Ni et al.","Neural network based computer vision systems are typically built on a backbone, a pretrained or randomly initialized feature extractor. Several years ago, the default option was an ImageNet-trained convolutional neural network. However, the recent past has seen the emergence of countless backbones pretrained using various algorithms and datasets. While this abundance of choice has led to performance increases for a range of systems, it is difficult for practitioners to make informed decisions about which backbone to choose. Battle of the Backbones (BoB) makes this choice easier by benchmarking a diverse suite of pretrained models, including vision-language models, those trained via self-supervised learning, and the Stable Diffusion backbone, across a diverse set of computer vision tasks ranging from classification to object detection to OOD generalization and more. Furthermore, BoB sheds light on promising directions for the research community to advance computer vision by illuminating strengths and weakness of existing approaches through a comprehensive analysis conducted on more than 1500 training runs. While vision transformers (ViTs) and self-supervised learning (SSL) are increasingly popular, we find that convolutional neural networks pretrained in a supervised fashion on large training sets still perform best on most tasks among the models we consider. Moreover, in apples-to-apples comparisons on the same architectures and similarly sized pretraining datasets, we find that SSL backbones are highly competitive, indicating that future works should perform SSL pretraining with advanced architectures and larger pretraining datasets. We release the raw results of our experiments along with code that allows researchers to put their own backbones through the gauntlet here: https://github.com/hsouri/Battle-of-the-Backbones"
Computer Vision (cs.CV),2023,6,"Quantifying the movement, behaviour and environmental context of group-living animals using drones and computer vision.",89,N/A,https://www.semanticscholar.org/paper/584230862bbd5f73b6f374efb67fbbd584d84e52,"Benjamin Koger, Adwait Deshpande, Jeffrey T. Kerby et al.","Methods for collecting animal behaviour data in natural environments, such as direct observation and biologging, are typically limited in spatiotemporal resolution, the number of animals that can be observed and information about animals' social and physical environments. Video imagery can capture rich information about animals and their environments, but image-based approaches are often impractical due to the challenges of processing large and complex multi-image datasets and transforming resulting data, such as animals' locations, into geographical coordinates. We demonstrate a new system for studying behaviour in the wild that uses drone-recorded videos and computer vision approaches to automatically track the location and body posture of free-roaming animals in georeferenced coordinates with high spatiotemporal resolution embedded in contemporaneous 3D landscape models of the surrounding area. We provide two worked examples in which we apply this approach to videos of gelada monkeys and multiple species of group-living African ungulates. We demonstrate how to track multiple animals simultaneously, classify individuals by species and age-sex class, estimate individuals' body postures (poses) and extract environmental features, including topography of the landscape and animal trails. By quantifying animal movement and posture while reconstructing a detailed 3D model of the landscape, our approach opens the door to studying the sensory ecology and decision-making of animals within their natural physical and social environments."
Computer Vision (cs.CV),2023,12,A Survey on Underwater Computer Vision,89,N/A,https://www.semanticscholar.org/paper/266ac45f466ae00d17cc6e6d24746d1afae886cd,"Salma González-Sabbagh, A. Robles-Kelly","Underwater computer vision has attracted increasing attention in the research community due to the recent advances in underwater platforms such as of rovers, gliders, autonomous underwater vehicles (AUVs), and the like, that now make possible the acquisition of vast amounts of imagery and video for applications such as biodiversity assessment, environmental monitoring, and search and rescue. Despite growing interest, underwater computer vision is still a relatively under-researched area, where the attention in the literature has been paid to the use of computer vision techniques for image restoration and reconstruction, where image formation models and image processing methods are used to recover colour corrected or enhanced images. This is due to the notion that these methods can be used to achieve photometric invariants to perform higher-level vision tasks such as shape recovery and recognition under the challenging and widely varying imaging conditions that apply to underwater scenes. In this paper, we review underwater computer vision techniques for image reconstruction, restoration, recognition, depth, and shape recovery. Further, we review current applications such as biodiversity assessment, management and protection, infrastructure inspection and AUVs navigation, amongst others. We also delve upon the current trends in the field and examine the challenges and opportunities in the area."
Computer Vision (cs.CV),2023,8,Hyperbolic Deep Learning in Computer Vision: A Survey,85,2305.06611,https://www.semanticscholar.org/paper/c6f331f7f6ae81efcc114b011539cf224f88465b,"Pascal Mettes, Mina Ghadimi Atigh, Martin Keller-Ressel et al.","Deep representation learning is a ubiquitous part of modern computer vision. While Euclidean space has been the de facto standard manifold for learning visual representations, hyperbolic space has recently gained rapid traction for learning in computer vision. Specifically, hyperbolic learning has shown a strong potential to embed hierarchical structures, learn from limited samples, quantify uncertainty, add robustness, limit error severity, and more. In this paper, we provide a categorization and in-depth overview of current literature on hyperbolic learning for computer vision. We research both supervised and unsupervised literature and identify three main research themes in each direction. We outline how hyperbolic learning is performed in all themes and discuss the main research problems that benefit from current advances in hyperbolic learning for computer vision. Moreover, we provide a high-level intuition behind hyperbolic geometry and outline open research questions to further advance research in this direction."
Computer Vision (cs.CV),2023,11,The accuracy of markerless motion capture combined with computer vision techniques for measuring running kinematics,60,N/A,https://www.semanticscholar.org/paper/0a925ad8e50df1c984678b1f6c29e821beb501df,"Bas Van Hooren, N.J.J. Pecasse, K. Meijer et al.","Markerless motion capture based on low‐cost 2‐D video analysis in combination with computer vision techniques has the potential to provide accurate analysis of running technique in both a research and clinical setting. However, the accuracy of markerless motion capture for assessing running kinematics compared to a gold‐standard approach remains largely unexplored."
Computer Vision (cs.CV),2023,13,Computer Vision and Deep Learning-enabled Weed Detection Model for Precision Agriculture,58,N/A,https://www.semanticscholar.org/paper/c5a0decba6813c78ec35223d5a9977b1d6a6e9ad,"R. Punithavathi, A. D. C. Rani, K. R. Sughashini et al.","Presently, precision agriculture processes like plant disease, crop yield prediction, species recognition, weed detection, and irrigation can be accomplished by the use of computer vision (CV) approaches. Weed plays a vital role in influencing crop productivity. The wastage and pollution of farmland's natural atmosphere instigated by full coverage chemical herbicide spraying are increased. Since the proper identification of weeds from crops helps to reduce the usage of herbicide and improve productivity, this study presents a novel computer vision and deep learning based weed detection and classification (CVDL-WDC) model for precision agriculture. The proposed CVDL-WDC technique intends to properly discriminate the plants as well as weeds. The proposed CVDL-WDC technique involves two processes namely multiscale Faster RCNN based object detection and optimal extreme learning machine (ELM) based weed classification. The parameters of the ELM model are optimally adjusted by the use of farmland fertility optimization (FFO) algorithm. A comprehensive simulation analysis of the CVDL-WDC technique against benchmark dataset reported the enhanced outcomes over its recent approaches interms of several measures."
Computer Vision (cs.CV),2023,15,FACET: Fairness in Computer Vision Evaluation Benchmark,58,2309.00035,https://www.semanticscholar.org/paper/7143623c7f1886ba67cc71692cc963741306ae4f,"Laura Gustafson, Chloé Rolland, Nikhila Ravi et al.","Computer vision models have known performance disparities across attributes such as gender and skin tone. This means during tasks such as classification and detection, model performance differs for certain classes based on the demographics of the people in the image. These disparities have been shown to exist, but until now there has not been a unified approach to measure these differences for common use-cases of computer vision models. We present a new benchmark named FACET (FAirness in Computer Vision EvaluaTion), a large, publicly available evaluation set of 32k images for some of the most common vision tasks - image classification, object detection and segmentation. For every image in FACET, we hired expert reviewers to manually annotate person-related attributes such as perceived skin tone and hair type, manually draw bounding boxes and label fine-grained person-related classes such as disk jockey or guitarist. In addition, we use FACET to benchmark state-of-the-art vision models and present a deeper understanding of potential performance disparities and challenges across sensitive demographic attributes. With the exhaustive annotations collected, we probe models using single demographics attributes as well as multiple attributes using an intersectional approach (e.g. hair color and perceived skin tone). Our results show that classification, detection, segmentation, and visual grounding models exhibit performance disparities across demographic attributes and intersections of attributes. These harms suggest that not all people represented in datasets receive fair and equitable treatment in these vision tasks. We hope current and future results using our benchmark will contribute to fairer, more robust vision models. FACET is available publicly at https://facet.metademolab.com."
Computer Vision (cs.CV),2023,16,Physics-Informed Computer Vision: A Review and Perspectives,55,2305.18035,https://www.semanticscholar.org/paper/763fd38d01fb5804aa576ebcb28d123e643d1874,"C. Banerjee, Kien Nguyen, C. Fookes et al.","The incorporation of physical information in machine learning frameworks is opening and transforming many application domains. Here the learning process is augmented through the induction of fundamental knowledge and governing physical laws. In this work, we explore their utility for computer vision tasks in interpreting and understanding visual data. We present a systematic literature review of more than 250 papers on formulation and approaches to computer vision tasks guided by physical laws. We begin by decomposing the popular computer vision pipeline into a taxonomy of stages and investigate approaches to incorporate governing physical equations in each stage. Existing approaches are analyzed in terms of modeling and formulation of governing physical processes, including modifying input data (observation bias), network architectures (inductive bias), and training losses (learning bias). The taxonomy offers a unified view of the application of the physics-informed capability, highlighting where physics-informed learning has been conducted and where the gaps and opportunities are. Finally, we highlight open problems and challenges to inform future research. While still in its early days, the study of physics-informed computer vision has the promise to develop better computer vision models that can improve physical plausibility, accuracy, data efficiency, and generalization in increasingly realistic applications."
Computer Vision (cs.CV),2023,14,MedShapeNet – a large-scale dataset of 3D medical shapes for computer vision,52,2308.16139,https://www.semanticscholar.org/paper/58722fd568e30615ce242d85ad1ecea576320c1c,"Jianning Li, Antonio Pepe, C. Gsaxner et al.","Abstract Objectives The shape is commonly used to describe the objects. State-of-the-art algorithms in medical imaging are predominantly diverging from computer vision, where voxel grids, meshes, point clouds, and implicit surface models are used. This is seen from the growing popularity of ShapeNet (51,300 models) and Princeton ModelNet (127,915 models). However, a large collection of anatomical shapes (e.g., bones, organs, vessels) and 3D models of surgical instruments is missing. Methods We present MedShapeNet to translate data-driven vision algorithms to medical applications and to adapt state-of-the-art vision algorithms to medical problems. As a unique feature, we directly model the majority of shapes on the imaging data of real patients. We present use cases in classifying brain tumors, skull reconstructions, multi-class anatomy completion, education, and 3D printing. Results By now, MedShapeNet includes 23 datasets with more than 100,000 shapes that are paired with annotations (ground truth). Our data is freely accessible via a web interface and a Python application programming interface and can be used for discriminative, reconstructive, and variational benchmarks as well as various applications in virtual, augmented, or mixed reality, and 3D printing. Conclusions MedShapeNet contains medical shapes from anatomy and surgical instruments and will continue to collect data for benchmarks and applications. The project page is: https://medshapenet.ikim.nrw/."
Computer Vision (cs.CV),2023,17,Prevalence of computer vision syndrome: a systematic review and meta-analysis,49,N/A,https://www.semanticscholar.org/paper/703fc66257ac5dd81b4e27036890d35dc622e55d,"Etsay Woldu Anbesu, Asamene Kelelom Lema","Although computer vision syndromes are becoming a major public health concern, less emphasis is given to them, particularly in developing countries. There are primary studies on different continents; however, there are inconsistent findings in prevalence among the primary studies. Therefore, this systematic review and meta-analysis aimed to estimate the pooled prevalence of computer vision syndrome. In this study, the review was developed using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Online electronic databases, including PubMed/Medline, CINAHL, and Google Scholar, were used to retrieve published and unpublished studies. The study was conducted from December 1 to April 9/2022. Study selection, quality assessment, and data extraction were performed independently by two authors. Quality assessment of the studies was performed using the Joanna Briggs Institute Meta-Analysis of Statistics Assessment and Review Instrument tool. Heterogeneity was assessed using the statistical test I^2. STATA 14 software was used for statistical analysis. A total of 7,35 studies were retrieved, and 45 studies were included in the final meta-analysis. The pooled prevalence of computer vision syndrome was 66% (95% CI: 59, 74). Subgroup analysis based on country was highest in Pakistan (97%, 95% CI: 96, 98) and lowest in Japan (12%, 95% CI: 9, 15). Subgroup analysis based on country showed that studies in Saudi Arabia (I^2 = 99.41%, p value < 0.001), Ethiopia (I^2 = 72.6%, p value < 0.001), and India (I^2 = 98.04%, p value < 0.001) had significant heterogeneity. In the sensitivity analysis, no single study unduly influenced the overall effect estimate. Nearly two in three participants had computer vision syndrome. Thus, preventive practice strategic activities for computer vision syndrome are important interventions."
Computer Vision (cs.CV),2023,18,Tuning computer vision models with task rewards,48,2302.08242,https://www.semanticscholar.org/paper/efa06fe7c6a4abbe465dbea4f7130f45720ac6f0,"André Susano Pinto, Alexander Kolesnikov, Yuge Shi et al.","Misalignment between model predictions and intended usage can be detrimental for the deployment of computer vision models. The issue is exacerbated when the task involves complex structured outputs, as it becomes harder to design procedures which address this misalignment. In natural language processing, this is often addressed using reinforcement learning techniques that align models with a task reward. We adopt this approach and show its surprising effectiveness across multiple computer vision tasks, such as object detection, panoptic segmentation, colorization and image captioning. We believe this approach has the potential to be widely useful for better aligning models with a diverse range of computer vision tasks."
Computer Vision (cs.CV),2023,19,Tackling class imbalance in computer vision: a contemporary review,47,N/A,https://www.semanticscholar.org/paper/d0f5be7a3e65101ed0958b65e7ce94e4fbd49b39,"Manisha Saini, Seba Susan",No Abstract
Computer Vision (cs.CV),2023,20,Computer vision quantification of whole-body Parkinsonian bradykinesia using a large multi-site population,44,N/A,https://www.semanticscholar.org/paper/40e6e2a44964a8ab6c31c3e93b7dba4879234d76,"Gareth Morinan, Yuriy Dushin, Grzegorz Sarapata et al.","Parkinson’s disease (PD) is a common neurological disorder, with bradykinesia being one of its cardinal features. Objective quantification of bradykinesia using computer vision has the potential to standardise decision-making, for patient treatment and clinical trials, while facilitating remote assessment. We utilised a dataset of part-3 MDS-UPDRS motor assessments, collected at four independent clinical and one research sites on two continents, to build computer-vision-based models capable of inferring the correct severity rating robustly and consistently across all identifiable subgroups of patients. These results contrast with previous work limited by small sample sizes and small numbers of sites. Our bradykinesia estimation corresponded well with clinician ratings (interclass correlation 0.74). This agreement was consistent across four clinical sites. This result demonstrates how such technology can be successfully deployed into existing clinical workflows, with consumer-grade smartphone or tablet devices, adding minimal equipment cost and time."
Computer Vision (cs.CV),2024,1,A review of convolutional neural networks in computer vision,560,N/A,https://www.semanticscholar.org/paper/ad06c8a5fd292af518f878c7ced132b61739cdd8,"Xia Zhao, Limin Wang, Yufei Zhang et al.","In computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (CNN). The CNN has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training CNN models that match practical applications. Due to the rapid progress in deep learning technology, the structure of CNN is becoming more and more complex and diverse. Consequently, it gradually replaces the traditional machine learning methods. This paper presents an elementary understanding of CNN components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. On this basis, this paper gives a comprehensive overview of the past and current research status of the applications of CNN models in computer vision fields, e.g., image classification, object detection, and video prediction. In addition, we summarize the challenges and solutions of the deep CNN, and future research directions are also discussed."
Computer Vision (cs.CV),2024,2,Computer vision in smart agriculture and precision farming: Techniques and applications,126,N/A,https://www.semanticscholar.org/paper/a223e57609d5a4ce286936871bc403833a4d43bc,"Sumaira Ghazal, Arslan Munir, W. S. Qureshi",No Abstract
Computer Vision (cs.CV),2024,3,Automated estimation of cementitious sorptivity via computer vision,90,N/A,https://www.semanticscholar.org/paper/92ffc1064e4ea31207ee70a655cbcfdfe2aaf6b7,"Hossein Kabir, Jordan Wu, Sunav Dahal et al.","Monitoring water uptake in cementitious systems is crucial to assess their durability against corrosion, salt attack, and freeze-thaw damage. However, gauging absorption currently relies on labor-intensive and infrequent weight measurements, as outlined in ASTM C1585. To address this issue, we introduce a custom computer vision model trained on 6234 images, consisting of 4000 real and 2234 synthetic, that automatically detects the water level in prismatic samples absorbing water. This model provides accurate and frequent estimations of water penetration values every minute. After training the model on 1440 unique data points, including 15 paste mixtures with varying water-to-cement ratios from 0.4 to 0.8 and curing periods of 1 to 7 days, we can now predict initial and secondary sorptivities in real time with high confidence, achieving R² > 0.9. Finally, we demonstrate its application on mortar and concrete systems, opening a pathway toward low-cost and automated durability assessment of construction materials. Monitoring water uptake in cementitious materials is important to assess their durability. Here, the authors introduce a low-cost computer vision method to predict initial and secondary sorptivity in real time in paste, mortar, and concrete systems."
Computer Vision (cs.CV),2024,4,Deep Learning and Computer Vision Techniques for Enhanced Quality Control in Manufacturing Processes,70,N/A,https://www.semanticscholar.org/paper/233b57d63838168aa05dba9a25ab505c80b8d7ac,"Md Raisul Islam, Md. Zakir Hossain Zamil, Md Eshmam Rayed et al.","Ensuring product quality and integrity is paramount in the rapidly evolving landscape of industrial manufacturing. Although effective to a certain degree, traditional quality control methods often fail to meet the demands for efficiency, accuracy, and adaptability in today’s fast-paced production environments. The advent of Deep Learning (DL) and Computer Vision (CV) technologies has opened new vistas for automated defect detection, promising to revolutionize the way industries approach quality control and inspection. This systematic review focuses on recent advancements in DL and CV applications for automated defect detection in manufacturing processes. It provides a comprehensive overview of state-of-the-art techniques for detecting, classifying, and predicting defects, highlighting the significant strides made in addressing challenges such as varying lighting conditions, complex defect patterns, and the seamless integration of these technologies into existing manufacturing workflows. Through a critical analysis of current methodologies, this study identifies key areas of opportunity, outlines the challenges that persist and suggests directions for future research. This review synthesizes findings from a broad spectrum of industrial applications, offering insights into the potential of DL and CV to enhance quality control mechanisms. By charting the progress and pinpointing the gaps in current practices, this paper aims to serve as a valuable resource for researchers, practitioners, and policymakers seeking to leverage the benefits of DL and CV for improved product management and manufacturing excellence."
Computer Vision (cs.CV),2024,5,"Plant Leaf Disease Detection, Classification, and Diagnosis Using Computer Vision and Artificial Intelligence: A Review",66,N/A,https://www.semanticscholar.org/paper/411108b1e44d0f4b8ba954d8123862b9d45ee4e2,"Anuja Bhargava, Aasheesh Shukla, Om Prakash Goswami et al.","Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Thus, recognition of plant disease is essential. The plant disease syndrome is noticeable in distinct parts of plants. Nonetheless, commonly the infection is detected in distinct leaves of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed."
Computer Vision (cs.CV),2024,10,A Comprehensive Review on Deep Learning Assisted Computer Vision Techniques for Smart Greenhouse Agriculture,52,N/A,https://www.semanticscholar.org/paper/9520af722e0a1cac1fe9b1aaced734f890253a2a,"Jalal Uddin Md Akbar, Syafiq Fauzi Bin Kamarulzaman, Abu Jafar Md. Muzahid et al.","With the escalating global challenges of food security and resource sustainability, innovative solutions like deep learning and computer vision are transforming agricultural practices by enabling data-driven decision-making. This paper provides a focused review of recent advancements in deep learning-enabled computer vision techniques tailored specifically for greenhouse environments. First, deep learning and computer vision fundamentals are briefly introduced. Over 100 studies from 2020 to date are then comprehensively reviewed in which these technologies were applied within greenhouses for growth monitoring, disease detection, yield estimation, and other tasks. The techniques, datasets, models, and overall performance results reported in the literature are analyzed. Tables and figures showcase real-world implementations and results synthesized from current research. Key challenges are also outlined related to aspects like model adaptability, lack of sufficient labeled greenhouse data, computational constraints, the need for multi-modal sensor fusion, and other areas needing further investigation. Future trends and prospects are discussed to provide guidance for researchers exploring computer vision in the niche greenhouse domain. By condensing prior work and elucidating the state-of-the-art, this timely review aims to promote continued progress in smart greenhouse agriculture. The focused analysis, specifically on greenhouse environments, fills a gap compared to previous agricultural surveys. Overall, this paper highlights the immense potential of computer vision and deep learning in driving the emergence of data-driven, smart greenhouse farming worldwide."
Computer Vision (cs.CV),2024,11,A Short Review on Supervised Machine Learning and Deep Learning Techniques in Computer Vision,52,N/A,https://www.semanticscholar.org/paper/6220f298497aca77ef4fbb531c78ec57e78ff41a,"Ahmed Adil Nafea, S. A. Alameri, Russel R Majeed et al.","In last years, computer vision has shown important advances, mainly using the application of supervised machine learning (ML) and deep learning (DL) techniques. The objective of this review is to show a brief review of the current state of the field of supervised ML and DL techniques, especially on computer vision tasks. This study focuses on the main ideas, advantages, and applications of DL in computer vision and highlights their main concepts and advantages. This study showed the strengths, limitations, and effects of computer vision supervised ML and DL techniques."
Computer Vision (cs.CV),2024,9,Deep learning for computer vision based activity recognition and fall detection of the elderly: a systematic review,45,2401.11790,https://www.semanticscholar.org/paper/611910944ab1c1be27cda5fb8cd615939d8fbb30,"F. X. Gaya-Morey, Cristina Manresa-Yee, Jose Maria Buades Rubio","As the proportion of elderly individuals in developed countries continues to rise globally, addressing their healthcare needs, particularly in preserving their autonomy, is of paramount concern. A growing body of research focuses on Ambient Assisted Living (AAL) systems, aimed at alleviating concerns related to the independent living of the elderly. This systematic review examines the literature pertaining to fall detection and Human Activity Recognition (HAR) for the elderly, two critical tasks for ensuring their safety when living alone. Specifically, this review emphasizes the utilization of Deep Learning (DL) approaches on computer vision data, reflecting current trends in the field. A comprehensive search yielded 2,616 works from five distinct sources, spanning the years 2019 to 2023 (inclusive). From this pool, 151 relevant works were selected for detailed analysis. The review scrutinizes the employed DL models, datasets, and hardware configurations, with particular emphasis on aspects such as privacy preservation and real-world deployment. The main contribution of this study lies in the synthesis of recent advancements in DL-based fall detection and HAR for the elderly, providing insights into the state-of-the-art techniques and identifying areas for further improvement. Given the increasing importance of AAL systems in enhancing the quality of life for the elderly, this review serves as a valuable resource for researchers, practitioners, and policymakers involved in developing and implementing such technologies."
Computer Vision (cs.CV),2024,15,A Review of Computer Vision-Based Crack Detection Methods in Civil Infrastructure: Progress and Challenges,41,N/A,https://www.semanticscholar.org/paper/d5b82bd7c9f1fb4ae8463957e6eae897a396b6aa,"Qi Yuan, Yufeng Shi, Mingyue Li","Cracks are a common defect in civil infrastructures, and their occurrence is often closely related to structural loading conditions, material properties, design and construction, and other factors. Therefore, detecting and analyzing cracks in civil infrastructures can effectively determine the extent of damage, which is crucial for safe operation. In this paper, Web of Science (WOS) and Google Scholar were used as literature search tools and “crack”, “civil infrastructure”, and “computer vision” were selected as search terms. With the keyword “computer vision”, 325 relevant documents were found in the study period from 2020 to 2024. A total of 325 documents were searched again and matched with the keywords, and 120 documents were selected for analysis and research. Based on the main research methods of the 120 documents, we classify them into three crack detection methods: fusion of traditional methods and deep learning, multimodal data fusion, and semantic image understanding. We examine the application characteristics of each method in crack detection and discuss its advantages, challenges, and future development trends."
Computer Vision (cs.CV),2024,16,Suitability of KANs for Computer Vision: A preliminary investigation,41,2406.09087,https://www.semanticscholar.org/paper/c192a6bcb307207ac791251cf6e7a827d25d6bb3,"Basim Azam, Naveed Akhtar","Kolmogorov-Arnold Networks (KANs) introduce a paradigm of neural modeling that implements learnable functions on the edges of the networks, diverging from the traditional node-centric activations in neural networks. This work assesses the applicability and efficacy of KANs in visual modeling, focusing on fundamental recognition and segmentation tasks. We mainly analyze the performance and efficiency of different network architectures built using KAN concepts along with conventional building blocks of convolutional and linear layers, enabling a comparative analysis with the conventional models. Our findings are aimed at contributing to understanding the potential of KANs in computer vision, highlighting both their strengths and areas for further research. Our evaluation point toward the fact that while KAN-based architectures perform in line with the original claims, it may often be important to employ more complex functions on the network edges to retain the performance advantage of KANs on more complex visual data."
Computer Vision (cs.CV),2024,13,Prediction and visualization of moisture content in Tencha drying processes by computer vision and deep learning.,40,N/A,https://www.semanticscholar.org/paper/b929fb8ad48f4bca05fe8b1dcf2ceedc18ae2667,"Jie You, Dengshan Li, Zhen Wang et al.","BACKGROUND Monitoring and controlling the moisture content throughout the Tencha drying processing procedure is crucial for ensuring its quality. Workers often rely on their senses to perceive the moisture content, leading to relative subjectivity and low reproducibility. The traditional drying methods for measuring moisture content is destructive to samples. This research was conducted using computer vision combined with deep learning for detecting moisture content during the Tencha drying process. Different color space components of Tencha drying samples' image were first extracted by computer vision. The color components were preprocessed using MinMax and Z-score. Subsequently, one-dimensional convolutional neural network (1D-CNN), partial least squares, and backpropagation artificial neural network models were built and compared.   RESULTS The 1D-CNN model and Z-score preprocessing achieved superior predictive accuracy, with correlation coefficient of prediction (Rp ) = 0.9548 for moisture content. Furthermore, the migration of moisture content during the Tencha drying process was eventually visualized by mapping its spatial and temporal distributions.   CONCLUSION The results indicated computer vision combined with 1D-CNN was feasible for moisture prediction during Tencha drying process. This study provides technical support for the industrial and intelligent production of Tencha. This article is protected by copyright. All rights reserved."
Computer Vision (cs.CV),2024,14,Intelligent Robotic Control System Based on Computer Vision Technology,36,2404.01116,https://www.semanticscholar.org/paper/d06a0c38c6d8296e4758296c07be7a51ec285965,"Chang Che, Haotian Zheng, Zengyi Huang et al.","Computer vision is a kind of simulation of biological vision using computers and related equipment. It is an important part of the field of artificial intelligence. Its research goal is to make computers have the ability to recognize three-dimensional environmental information through two-dimensional images. Computer vision is based on image processing technology, signal processing technology, probability statistical analysis, computational geometry, neural network, machine learning theory and computer information processing technology, through computer analysis and processing of visual information.The article explores the intersection of computer vision technology and robotic control, highlighting its importance in various fields such as industrial automation, healthcare, and environmental protection. Computer vision technology, which simulates human visual observation, plays a crucial role in enabling robots to perceive and understand their surroundings, leading to advancements in tasks like autonomous navigation, object recognition, and waste management. By integrating computer vision with robot control, robots gain the ability to interact intelligently with their environment, improving efficiency, quality, and environmental sustainability. The article also discusses methodologies for developing intelligent garbage sorting robots, emphasizing the application of computer vision image recognition, feature extraction, and reinforcement learning techniques. Overall, the integration of computer vision technology with robot control holds promise for enhancing human-computer interaction, intelligent manufacturing, and environmental protection efforts."
Computer Vision (cs.CV),2024,19,Applied Artificial Intelligence in Healthcare: A Review of Computer Vision Technology Application in Hospital Settings,35,N/A,https://www.semanticscholar.org/paper/97d6ed19723b4c66b44f1ad235b7d4cf0cd2a611,"H. Lindroth, Keivan Nalaie, Roshini Raghu et al.","Computer vision (CV), a type of artificial intelligence (AI) that uses digital videos or a sequence of images to recognize content, has been used extensively across industries in recent years. However, in the healthcare industry, its applications are limited by factors like privacy, safety, and ethical concerns. Despite this, CV has the potential to improve patient monitoring, and system efficiencies, while reducing workload. In contrast to previous reviews, we focus on the end-user applications of CV. First, we briefly review and categorize CV applications in other industries (job enhancement, surveillance and monitoring, automation, and augmented reality). We then review the developments of CV in the hospital setting, outpatient, and community settings. The recent advances in monitoring delirium, pain and sedation, patient deterioration, mechanical ventilation, mobility, patient safety, surgical applications, quantification of workload in the hospital, and monitoring for patient events outside the hospital are highlighted. To identify opportunities for future applications, we also completed journey mapping at different system levels. Lastly, we discuss the privacy, safety, and ethical considerations associated with CV and outline processes in algorithm development and testing that limit CV expansion in healthcare. This comprehensive review highlights CV applications and ideas for its expanded use in healthcare."
Computer Vision (cs.CV),2024,18,A Review of Computer Vision-Based Monitoring Approaches for Construction Workers’ Work-Related Behaviors,33,N/A,https://www.semanticscholar.org/paper/ae04406985760c01aab866922b238996291d5f81,"Jiaqi Li, Qi Miao, Zheng Zou et al.","Construction workers’ behaviors directly affects labor productivity and their own safety, thereby influencing project quality. Recognizing and monitoring the construction-related behaviors is therefore crucial for high-quality management and orderly construction site operation. Recent strides in computer vision technology suggest its potential to replace traditional manual supervision approaches. This paper explores research on monitoring construction workers’ behaviors using computer vision. Through bibliometrics and content-based analysis, the authors present the latest research in this area from three perspectives: “Detection, Localization, and Tracking for Construction Workers,” “Recognition of Workers’ Construction Activities,” and “Occupational Health and Safety Behavior Monitoring.” In terms of the literature’s volume, there has been a notable increase in this field. Notably, the focus on safety-related literature is predominant, underscoring the concern for occupational health. Vision algorithms have witnessed an increase in the utilization of object detection. The ongoing and future research trajectory is anticipated to involve multi-algorithm integration and an emphasis on enhancing robustness. Then the authors summarize the review from engineering impact and technical suitability, and analyze the limitations of current research from the perspectives of technical approaches and application scenarios. Finally, it discusses future research directions in this field together with generative AI models. Furthermore, the authors hope this paper can serves as a valuable reference for both scholars and engineers."
Computer Vision (cs.CV),2024,17,A Review of Transformer-Based Models for Computer Vision Tasks: Capturing Global Context and Spatial Relationships,31,2408.15178,https://www.semanticscholar.org/paper/c67e1825cdaa2e8875bf0de90fb918af246ba6e1,"Gracile Astlin Pereira, Muhammad Hussain","Transformer-based models have transformed the landscape of natural language processing (NLP) and are increasingly applied to computer vision tasks with remarkable success. These models, renowned for their ability to capture long-range dependencies and contextual information, offer a promising alternative to traditional convolutional neural networks (CNNs) in computer vision. In this review paper, we provide an extensive overview of various transformer architectures adapted for computer vision tasks. We delve into how these models capture global context and spatial relationships in images, empowering them to excel in tasks such as image classification, object detection, and segmentation. Analyzing the key components, training methodologies, and performance metrics of transformer-based models, we highlight their strengths, limitations, and recent advancements. Additionally, we discuss potential research directions and applications of transformer-based models in computer vision, offering insights into their implications for future advancements in the field."
Computer Vision (cs.CV),2024,20,Systematic Review of Emotion Detection with Computer Vision and Deep Learning,29,N/A,https://www.semanticscholar.org/paper/ad2f32747c557836fffe3adf565fdea75b7e3305,"Rafael Pereira, Carla Mendes, José Ribeiro et al.","Emotion recognition has become increasingly important in the field of Deep Learning (DL) and computer vision due to its broad applicability by using human–computer interaction (HCI) in areas such as psychology, healthcare, and entertainment. In this paper, we conduct a systematic review of facial and pose emotion recognition using DL and computer vision, analyzing and evaluating 77 papers from different sources under Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Our review covers several topics, including the scope and purpose of the studies, the methods employed, and the used datasets. The scope of this work is to conduct a systematic review of facial and pose emotion recognition using DL methods and computer vision. The studies were categorized based on a proposed taxonomy that describes the type of expressions used for emotion detection, the testing environment, the currently relevant DL methods, and the datasets used. The taxonomy of methods in our review includes Convolutional Neural Network (CNN), Faster Region-based Convolutional Neural Network (R-CNN), Vision Transformer (ViT), and “Other NNs”, which are the most commonly used models in the analyzed studies, indicating their trendiness in the field. Hybrid and augmented models are not explicitly categorized within this taxonomy, but they are still important to the field. This review offers an understanding of state-of-the-art computer vision algorithms and datasets for emotion recognition through facial expressions and body poses, allowing researchers to understand its fundamental components and trends."
Computer Vision (cs.CV),2024,6,Beyond AI Exposure: Which Tasks are Cost-Effective to Automate with Computer Vision?,24,N/A,https://www.semanticscholar.org/paper/9f92c87bae74334c1ff2e1340902031da8882cc6,"Maja S. Svanberg, Wensu Li, Martin Fleming et al.",". The faster AI automation spreads through the economy, the more profound its potential impacts, both positive (improved productivity) and negative (worker displacement). The previous literature on “AI Exposure” cannot predict this pace of automation since it attempts to measure an overall potential for AI to affect an area, not the technical feasibility and economic attractiveness of building such systems. In this article, we present a new type of AI task automation model that is end-to-end, estimating: the level of technical performance needed to do a task, the characteristics of an AI system capable of that performance, and the economic choice of whether to build and deploy such a system. The result is a first estimate of which tasks are technically feasible and economically attractive to automate - and which are not. We focus on computer vision, where cost modeling is more developed. We find that at today’s costs U.S. businesses would choose not to automate most vision tasks that have “AI Exposure,” and that only 23% of worker wages being paid for vision tasks would be attractive to automate. This slower roll-out of AI can be accelerated if costs falls rapidly or if it is deployed via AI-as-a-service platforms that have greater scale than individual firms, both of which we quantify. Overall, our findings suggest that AI job displacement will be substantial, but also gradual – and therefore there is room for policy and retraining to mitigate unemployment impacts."
Computer Vision (cs.CV),2024,7,Balancing Privacy and Accuracy: Exploring the Impact of Data Anonymization on Deep Learning Models in Computer Vision,20,N/A,https://www.semanticscholar.org/paper/414d313ae0a5a25db853a7b338904264a153992e,"Jun Ha Lee, Sujeong You","Computer vision has become indispensable in various applications, including autonomous driving, medical imaging, security and surveillance, robotics, and pattern recognition. In recent years, the quality of training data has emerged as a critical factor for ensuring effectiveness in real-world scenarios. However, the increasing stringency of privacy regulations in various regions necessitates careful handling of collected images for computer vision. Personal information within images is typically anonymized by applying anonymization patterns to remove it. Empirical findings underscore the significant influence of data quality on the training of deep learning models. Striking the right balance between privacy and recognition performance becomes paramount. Therefore, it is essential to understand how the anonymization of image datasets affects deep learning model performance. In this paper, we thoroughly analyze the effects of different anonymization techniques on the performance of deep learning-based models in computer vision tasks, with a particular emphasis on presenting a model-centric perspective, such as the type of deep learning model and the number of parameters. We aim to provide valuable insights and guidelines for selecting the optimal level of anonymization that strikes a balance between recognition accuracy and privacy protection."
Computer Vision (cs.CV),2024,8,Real-Time Network Packet Classification Exploiting Computer Vision Architectures,15,N/A,https://www.semanticscholar.org/paper/05db6083443b3829c882bc1b35abccc97fb1e3f7,"E. Paolini, L. Valcarenghi, Luca Maggiani et al.","Forthcoming 6G/NextG networks highlight the need for advanced Artificial Intelligence (AI)-based security mechanisms to identify malicious activities and adapt to emerging threats. In this context, the integration of computer vision techniques into the cybersecurity field is promising due to their potential for sophisticated pattern recognition. In this paper we introduce a computationally efficient classification scheme acting directly on the raw packets collected at base stations and enforcing real-time conversion of packets into images. The innovative points of the proposed solution are the lightweight implementation, aligning well with the demands of future 6G networks, and the operation at network edge, enabling early threat identification as close as possible to the packet origin. We investigate the performance of this approach both in terms of F1-score and prediction time using state-of-the-art computer vision architectures and a customized Convolutional Neural Network (CNN) in an intrusion detection problem using a 5G dataset. Experimental results show the superiority of the CNN architecture over complex models. Across multiple packet window sizes $N$ (i.e., 10, 50, 100 packets), the CNN consistently outperforms the other state-of-the-art computer vision models, achieving very high F1-scores (namely, 0.99593, 0.99860, 0.99895). A scalability analysis highlights a trade-off between CNN scalability and performance, where larger $N$ values lead to increased prediction time. On the other hand, the other computer vision models exhibit better scalability, enabling an optimal model selection without trade-offs."
Computer Vision (cs.CV),2024,12,Diabetic Retinopathy Features Segmentation without Coding Experience with Computer Vision Models YOLOv8 and YOLOv9,15,N/A,https://www.semanticscholar.org/paper/6832a2c1d2fc74711bd3d8b07d99de14cd4d3bca,"Nicola Rizzieri, Luca Dall’Asta, Maris Ozoliņš","Computer vision is a powerful tool in medical image analysis, supporting the early detection and classification of eye diseases. Diabetic retinopathy (DR), a severe eye disease secondary to diabetes, accompanies several early signs of eye-threatening conditions, such as microaneurysms (MAs), hemorrhages (HEMOs), and exudates (EXs), which have been widely studied and targeted as objects to be detected by computer vision models. In this work, we tested the performances of the state-of-the-art YOLOv8 and YOLOv9 architectures on DR fundus features segmentation without coding experience or a programming background. We took one hundred DR images from the public MESSIDOR database, manually labelled and prepared them for pixel segmentation, and tested the detection abilities of different model variants. We increased the diversity of the training sample by data augmentation, including tiling, flipping, and rotating the fundus images. The proposed approaches reached an acceptable mean average precision (mAP) in detecting DR lesions such as MA, HEMO, and EX, as well as a hallmark of the posterior pole of the eye, such as the optic disc. We compared our results with related works in the literature involving different neural networks. Our results are promising, but far from being ready for implementation into clinical practice. Accurate lesion detection is mandatory to ensure early and correct diagnoses. Future works will investigate lesion detection further, especially MA segmentation, with improved extraction techniques, image pre-processing, and standardized datasets."
Databases (cs.DB),2019,2,Network Pharmacology Databases for Traditional Chinese Medicine: Review and Assessment,993,N/A,https://www.semanticscholar.org/paper/f80aac3eb39b739205b87bb0e9b411a5d35067fe,"Run-zhi Zhang, Xue Zhu, Hong Bai et al.","The research field of systems biology has greatly advanced and, as a result, the concept of network pharmacology has been developed. This advancement, in turn, has shifted the paradigm from a “one-target, one-drug” mode to a “network-target, multiple-component-therapeutics” mode. Network pharmacology is more effective for establishing a “compound-protein/gene-disease” network and revealing the regulation principles of small molecules in a high-throughput manner. This approach makes it very powerful for the analysis of drug combinations, especially Traditional Chinese Medicine (TCM) preparations. In this work, we first summarized the databases and tools currently used for TCM research. Second, we focused on several representative applications of network pharmacology for TCM research, including studies on TCM compatibility, TCM target prediction, and TCM network toxicology research. Third, we compared the general statistics of several current TCM databases and evaluated and compared the search results of these databases based on 10 famous herbs. In summary, network pharmacology is a rational approach for TCM studies, and with the development of TCM research, powerful and comprehensive TCM databases have emerged but need further improvements. Additionally, given that several diseases could be treated by TCMs, with the mediation of gut microbiota, future studies should focus on both the microbiome and TCMs to better understand and treat microbiome-related diseases."
Databases (cs.DB),2019,1,CoordinateCleaner: Standardized cleaning of occurrence records from biological collection databases,736,N/A,https://www.semanticscholar.org/paper/cc15144bf41900588a6f62dc8aeca53a01c5135f,"Alexander Zizka, D. Silvestro, Tobias Andermann et al.","Species occurrence records from online databases are an indispensable resource in ecological, biogeographical and palaeontological research. However, issues with data quality, especially incorrect geo‐referencing or dating, can diminish their usefulness. Manual cleaning is time‐consuming, error prone, difficult to reproduce and limited to known geographical areas and taxonomic groups, making it impractical for datasets with thousands or millions of records. Here, we present CoordinateCleaner, an r‐package to scan datasets of species occurrence records for geo‐referencing and dating imprecisions and data entry errors in a standardized and reproducible way. CoordinateCleaner is tailored to problems common in biological and palaeontological databases and can handle datasets with millions of records. The software includes (a) functions to flag potentially problematic coordinate records based on geographical gazetteers, (b) a global database of 9,691 geo‐referenced biodiversity institutions to identify records that are likely from horticulture or captivity, (c) novel algorithms to identify datasets with rasterized data, conversion errors and strong decimal rounding and (d) spatio‐temporal tests for fossils. We describe the individual functions available in CoordinateCleaner and demonstrate them on more than 90 million occurrences of flowering plants from the Global Biodiversity Information Facility (GBIF) and 19,000 fossil occurrences from the Palaeobiology Database (PBDB). We find that in GBIF more than 3.4 million records (3.7%) are potentially problematic and that 179 of the tested contributing datasets (18.5%) might be biased by rasterized coordinates. In PBDB, 1205 records (6.3%) are potentially problematic. All cleaning functions and the biodiversity institution database are open‐source and available within the CoordinateCleaner r‐package."
Databases (cs.DB),2019,3,"The EFI Web Resource for Genomic Enzymology Web Tools: Leveraging Protein, Genome, and Metagenome Databases to Discover Novel Enzymes and Metabolic Pathways.",571,N/A,https://www.semanticscholar.org/paper/a61aa61c2330cc652dabc5b1055e5c64fdf0809c,"Rémi Zallot, Nils Oberg, J. Gerlt","The assignment of functions to uncharacterized proteins discovered in genome projects requires easily accessible tools and computational resources for large-scale, user-friendly leveraging of the protein, genome, and metagenome databases by experimentalists. This article describes the web resource developed by the Enzyme Function Initiative (EFI; accessed at https://efi.igb.illinois.edu/) that provides ""genomic enzymology"" tools (""web tools"") for 1) generating sequence similarity networks (SSNs) for protein families (EFI-EST); 2) analyzing and visualizing genome context of the proteins in clusters in SSNs (in genome neighborhood networks, GNNs, and genome neighborhood diagrams, GNDs) (EFI-GNT); and 3) prioritizing uncharacterized SSN clusters for functional assignment based on metagenome abundance (chemically guided functional profiling, CGFP) (EFI-CGFP). The SSNs generated by EFI-EST are used as the input for EFI-GNT and EFI-CGFP, enabling easy transfer of information among the tools. The networks are visualized and analyzed using Cytoscape, a widely used desktop application; GNDs and CGFP heatmaps summarizing metagenome abundance are viewed within the tools. We provide a detailed example of the integrated use of the tools with an analysis of glycyl radical enzyme superfamily (IPR004184) found in the human gut microbiome. This analysis demonstrates that 1) SwissProt annotations are not always correct, 2) large-scale genome context analyses allow the prediction of novel metabolic pathways, and 3) metagenome abundance can be used to identify/prioritize uncharacterized proteins for functional investigation."
Databases (cs.DB),2019,4,"Comparing Bibliometric Analysis Using PubMed, Scopus, and Web of Science Databases.",555,N/A,https://www.semanticscholar.org/paper/0d177f9d26e4b2a3d5edc75e131ef3f5b55839ee,"S. A. S. AlRyalat, Lna Malkawi, S. Momani","Literature databases (i.e., PubMed, Scopus, and Web of Science) differ in terms of their coverage, focus, and the tool they provide. PubMed focuses mainly on life sciences and biomedical disciplines, whereas Scopus and Web of Science are multidisciplinary. The protocol described in the current study was used to search for publications from Jordanian authors in the years 2013-2017. In this protocol, how to use each database to conduct this type of search is explained in detail. A Scopus search resulted in the highest number of documents (11,444 documents), followed by a Web of Science search (10,943 documents). PubMed resulted in a smaller number of documents due to its narrower scope and coverage (4,363 documents). The results also show a yearly trend in: (1) the number of publications, (2) the disciplines that have the most publications, (3) the countries of collaboration, and (4) the number of open access publications. In contrast, PubMed has a sophisticated keyword optimization service (i.e., Medical Subject Heading, or MeSH), while both Scopus and Web of Science provide search analysis tools that can produce representative figures. Finally, the features of each database are explained in detail and several indices that can be extracted using the search results are provided. This study provides a base for using literature databases for bibliometric analysis."
Databases (cs.DB),2019,5,A review of methods and databases for metagenomic classification and assembly,426,N/A,https://www.semanticscholar.org/paper/ecebf0a47fac30859adad2b42c68f1ed17b5bd32,"F. Breitwieser, Jennifer Lu, S. Salzberg",No Abstract
Databases (cs.DB),2019,6,Use of hormone replacement therapy and risk of venous thromboembolism: nested case-control studies using the QResearch and CPRD databases,353,N/A,https://www.semanticscholar.org/paper/249cc96bf3274b82cbcc27b74e4aa8195aa2aee0,"Y. Vinogradova, C. Coupland, J. Hippisley-Cox","Abstract Objective To assess the association between risk of venous thromboembolism and use of different types of hormone replacement therapy. Design Two nested case-control studies. Setting UK general practices contributing to the QResearch or Clinical Practice Research Datalink (CPRD) databases, and linked to hospital, mortality, and social deprivation data. Participants 80 396 women aged 40-79 with a primary diagnosis of venous thromboembolism between 1998 and 2017, matched by age, general practice, and index date to 391 494 female controls. Main outcome measures Venous thromboembolism recorded on general practice, mortality, or hospital records. Odds ratios were adjusted for demographics, smoking status, alcohol consumption, comorbidities, recent medical events, and other prescribed drugs. Results Overall, 5795 (7.2%) women who had venous thromboembolism and 21 670 (5.5%) controls had been exposed to hormone replacement therapy within 90 days before the index date. Of these two groups, 4915 (85%)and 16 938 (78%) women used oral therapy, respectively, which was associated with a significantly increased risk of venous thromboembolism compared with no exposure (adjusted odds ratio 1.58, 95% confidence interval 1.52 to 1.64), for both oestrogen only preparations (1.40, 1.32 to 1.48) and combined preparations (1.73, 1.65 to 1.81). Estradiolhad a lower risk than conjugated equine oestrogen for oestrogen only preparations (0.85, 0.76 to 0.95) and combined preparations (0.83, 0.76 to 0.91). Compared with no exposure, conjugated equine oestrogen with medroxyprogesterone acetate had the highest risk (2.10, 1.92 to 2.31), and estradiol with dydrogesterone had the lowest risk (1.18, 0.98 to 1.42). Transdermal preparations were not associated with risk of venous thromboembolism, which was consistent for different regimens (overall adjusted odds ratio 0.93, 95% confidence interval 0.87 to 1.01). Conclusions In the present study, transdermal treatment was the safest type of hormone replacement therapy when risk of venous thromboembolism was assessed. Transdermal treatment appears to be underused, with the overwhelming preference still for oral preparations."
Databases (cs.DB),2019,11,Sequenceserver: A Modern Graphical User Interface for Custom BLAST Databases,286,N/A,https://www.semanticscholar.org/paper/cc14ea3d9d7fcd57308c677f409ce292e7e71385,"Anurag Priyam, Bennet Woodcroft, Vivek Rai et al.","Abstract Comparing newly obtained and previously known nucleotide and amino-acid sequences underpins modern biological research. BLAST is a well-established tool for such comparisons but is challenging to use on new data sets. We combined a user-centric design philosophy with sustainable software development approaches to create Sequenceserver, a tool for running BLAST and visually inspecting BLAST results for biological interpretation. Sequenceserver uses simple algorithms to prevent potential analysis errors and provides flexible text-based and visual outputs to support researcher productivity. Our software can be rapidly installed for use by individuals or on shared servers."
Databases (cs.DB),2019,7,CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases,266,1909.05378,https://www.semanticscholar.org/paper/545e60873b0fad25407bb6d647f92c905bd2483d,"Tao Yu, Rui Zhang, H. Er et al.","We present CoSQL, a corpus for building cross-domain, general-purpose database (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k dialogues querying 200 complex DBs spanning 138 domains. Each dialogue simulates a real-world DB query scenario with a crowd worker as a user exploring the DB and a SQL expert retrieving answers with SQL, clarifying ambiguous questions, or otherwise informing of unanswerable questions. When user questions are answerable by SQL, the expert describes the SQL and execution results to the user, hence maintaining a natural interaction flow. CoSQL introduces new challenges compared to existing task-oriented dialogue datasets: (1) the dialogue states are grounded in SQL, a domain-independent executable representation, instead of domain-specific slot value pairs, and (2) because testing is done on unseen databases, success requires generalizing to new domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking, response generation from query results, and user dialogue act prediction. We evaluate a set of strong baselines for each task and show that CoSQL presents significant challenges for future research. The dataset, baselines, and leaderboard will be released at https://yale-lily.github.io/cosql."
Databases (cs.DB),2019,9,Tandem repeats lead to sequence assembly errors and impose multi-level challenges for genome and protein databases,254,N/A,https://www.semanticscholar.org/paper/d59465a4c7ce2255d5dd5a71622f09d423941f0f,"O. K. Tørresen, Bastiaan Star, Pablo Mier et al.","Abstract The widespread occurrence of repetitive stretches of DNA in genomes of organisms across the tree of life imposes fundamental challenges for sequencing, genome assembly, and automated annotation of genes and proteins. This multi-level problem can lead to errors in genome and protein databases that are often not recognized or acknowledged. As a consequence, end users working with sequences with repetitive regions are faced with ‘ready-to-use’ deposited data whose trustworthiness is difficult to determine, let alone to quantify. Here, we provide a review of the problems associated with tandem repeat sequences that originate from different stages during the sequencing-assembly-annotation-deposition workflow, and that may proliferate in public database repositories affecting all downstream analyses. As a case study, we provide examples of the Atlantic cod genome, whose sequencing and assembly were hindered by a particularly high prevalence of tandem repeats. We complement this case study with examples from other species, where mis-annotations and sequencing errors have propagated into protein databases. With this review, we aim to raise the awareness level within the community of database users, and alert scientists working in the underlying workflow of database creation that the data they omit or improperly assemble may well contain important biological information valuable to others."
Databases (cs.DB),2019,10,Data Mining and Knowledge Discovery in Databases,232,N/A,https://www.semanticscholar.org/paper/14d6147907e95cc9b081dece9d20837be6e1e5e5,A. Azevedo,"The term knowledge discovery in databases or KDD, for short, was coined in 1989 to refer to the broad process of finding knowledge in data, and to emphasize the “high-level” application of particular data mining (DM) methods. The DM phase concerns, mainly, the means by which the patterns are extracted and enumerated from data. Nowadays, the two terms are, usually, indistinctly used. Efforts are being developed in order to create standards and rules in the field of DM with great relevance being given to the subject of inductive databases. Within the context of inductive databases, a great relevance is given to the so-called DM languages. This chapter explores DM in KDD."
Databases (cs.DB),2019,8,Graph Databases,228,N/A,https://www.semanticscholar.org/paper/d852660e15e82ae150dcde105639ba2c7d90f01f,"A. Silvescu, Doina Caragea",No Abstract
Databases (cs.DB),2019,14,Graphical Depiction of Longitudinal Study Designs in Health Care Databases,208,N/A,https://www.semanticscholar.org/paper/aa5de05f1d739c37dac7a0292f995589f5ddf1b1,"S. Schneeweiss, J. Rassen, Jeffrey S. Brown et al.","The pharmacoepidemiologic and pharmacoeconomic analysis of databases containing administrative claims and electronic health records has become a routine source of evidence to support regulatory (1) and reimbursement (2) decisions, as well as efficient management of health care organizations. When decision makers understand the study design and analytic choices of a nonrandomized database study and recognize those choices as valid, they have confidence in their decisions based on the study's evidence about the comparative effectiveness and safety of medical products (3, 4). Generally, they consider nonexperimental database studies more difficult to review than randomized trials and see the increased complexity, greater variability in design and analysis options, and lack of consistency in presentation of design choices as key barriers to using database evidence for high-stakes decisions. Unfortunately, some poorly designed studies have led to negative generalizations about the entire field of health care database research rather than a refined view that distinguishes robust evidence from less reliable evidence (5). Confounding from treatment selection based on outcome risk is well known to cause bias (6). Time-related study design flaws can also introduce large biases, including immortal time bias (7), reverse causation (8, 9), adjustment for causal intermediates, unobservable time bias (10), and depletion of susceptibles (11, 12). The methods sections of study reports should describe the study design and analytic choices clearly enough to allow the reader to judge the validity of findings. However, convoluted prose often makes it difficult for most readers to understand what methods were implemented or identify avoidable design flaws. Design diagrams provide key information that needs to be considered when evidence is interpreted from pharmacoepidemiologic and pharmacoeconomic studies done with health care databases. Improving transparency in how these studies are designed and implemented will make it easier for reviewers and decision makers to distinguish the useful from the flawed or irrelevant (13). Graphical study design representations were recommended by the most recent guidance for reporting on database studies from the REporting of studies Conducted using Observational Routinely collected health Data statement for pharmacoepidemiology (RECORD-PE) (14), as well as recently published consensus papers by 2 leading professional societies (15, 16). We propose a simple framework of graphical representations that will clarify critical design choices in database analyses of the effectiveness and safety of medical products. A recent consensus statement laid out a set of parameters that define decisions in database study implementation, which, if reported, would increase reproducibility of studies (16). Building on these parameters, we sought to develop a visualization framework that describes study design implementation in a comprehensive, unambiguous, and intuitive way; contains a level of detail that enables reproduction of key study design variables; and uses standardized structure and terminology to simplify review and communication to a broad audience of decision makers. Our multistakeholder group comprised international leaders with more than 75 years of combined experience in academia, regulatory decisions, health technology assessment, journal leadership, payer decision making, and analyses of distributed health care data networks. The example figures and templates are covered by a Creative Commons license. The PowerPoint figures are free to download and adapt, with appropriate attribution, from www.repeatinitiative.org/projects.html. Terminology The terminology we suggest for temporal anchors is frequently used in descriptions of database studies and in textbooks (17), as well as in the recently published consensus statement (15, 16). We define 3 categories of temporal anchors (Table): base anchors, first-order anchors, and second-order anchors. Base anchors are defined in calendar time and describe the source databasethat is, the longitudinal streams of administrative or clinical health care data from which an analyzable study data set is derived. First-order anchors are defined in patient event time rather than calendar time and specify the study entry or index date. Second-order anchors are also measured in patient event time and are defined relative to the first-order anchor. We provide more detail on each temporal anchor in the following section. Table. Temporal Anchors Study Design Implementation in Health Care Databases The Nature of Health Care Databases Relevant to Effectiveness Research Health care databases are derived from transactional databases that record clinical and administrative information for delivering and administering health care. As encounters occur and services are provided, records are generated and tallied. Each addition to the database comes with a service date stamp and is attributed to the patient via a unique patient identification number, thus generating longitudinal patient records of increasing duration. There is substantial literature describing the details of data integration, cleaning, and normalization (1820). For each patient, all encounters with the health care system that are reimbursable by health insurance (or are captured by the provider's electronic health record system) can be sorted by the service date in calendar time (Figure 1). Each encounter is associated with information on medical services, diagnoses, procedures, and similar events, plus information on payments (in claims data) or charges (in electronic health record data). The rules and algorithms that stem from a specific study implementation will then be applied to each patient's longitudinal data stream. The study implementation is usually oriented around an event-based timeline anchored to a key event, in contrast to the calendar time arrangement of the raw data (Figure 1) (21). Figure 1. From transactional data to study implementation. Individual patient data are documented as encounters from various sources and are arranged in calendar time. This work is licensed under CC BY, and the original versions can be found at www.repeatinitiative.org/projects.html. Dx= diagnosis; E= exposure; Lab= laboratory test; O= outcome; Rx= drug dispensing; V= visit. Dates and Time Windows Certain principles guide the design and implementation of studies in health care data streams. One of the most important is temporality. Unlike in primary data collection, many measurements in health care databasesfor example, patients' baseline characteristicsare measured by reviewing information recorded during multiple health care encounters over time. In primary data collection, a study participant's health state is usually established when the patient is thoroughly interviewed or examined at a study visit. Health care databases have no defined interview date with the investigator team; rather, studies rely on the occurrence of routine visits and other health care encounters to collect information that was recorded during provision of care. Thus, information that may be conceptualized as characterizing a point in time, such as baseline patient characteristics before the start of exposure, is actually recorded during a time window through a series of encounters. Anchors in Calendar Time For a database study to be reproducible, temporal anchors must be defined to specify the underlying longitudinal data used to create a study population (Table). The data extraction date is particularly important to record when working with recent data that are still fluid. The dynamic data flow in a health care database is stabilized by extracting and physically or virtually setting aside requested data for research purposes. However, some administrative records may be corrected or amended retroactively for up to 6 months or longer (22). If the underlying database has data that are dynamically updated over time, a study using the most recently available data extracted today will probably not be exactly replicated using data covering the same period but extracted a year later. The source data range reflects the calendar date boundaries beyond which encounter information is not captured for patients. Investigators must be clear about the lag between the most recent update to the data source and the calendar time boundaries for data included in their study (study period). For example, investigators may access a data source where the tables containing up-to-date information on patient health care contacts are extracted on 1 January 2019 (data extraction date). The source data range included in those tables covers 1 January 2003 to 31 December 2018. The investigators, however, choose a study period that focuses on time after market entry of a drug and does not use the most recent 6 months, a period during which the data may be more fluid. The data extraction date and source data range do not need to be included in visualization of study design, but reporting them and archiving extracted longitudinal data will make study implementation reproducible (16). Anchors in Patient Event Time When an effectiveness or safety study is implemented in a longitudinal database, the time scale shifts from calendar time to patient event time. Specific algorithms define events in the patient timeline. As in randomized controlled trials, where the randomization date is the anchor date, the cohort entry date (CED, also called the index date) is the primary anchor in a nonrandomized database study (Table). The CED is the date when patients enter the analytic study population. For some study designs, study entry can be defined by an event date (as described under Nested CaseControl Study and in Self-Controlled Study Design Visualization in the Appendix). The CED is considered a first-order anchor because most other anchors and parameters used in study implementation w"
Databases (cs.DB),2019,12,"Prevalence of Inflammatory Bowel Disease in Pediatric and Adult Populations: Recent Estimates From Large National Databases in the United States, 2007-2016.",202,N/A,https://www.semanticscholar.org/paper/951129e511d140ba879d3eed618e71868f0198b6,"Y. Ye, Sudhakar Manne, William R Treem et al.","BACKGROUND The latest estimate of the prevalence of inflammatory bowel disease (IBD) in the United States was based on 2009 data, which indicates a need for an up-to-date re-estimation. The objectives of this study were to investigate the prevalence of all forms of IBD including ulcerative colitis (UC), Crohn's disease (CD), and IBD unspecified (IBDU).   METHODS Pediatric (age 2-17) and adult (age ≥18) IBD patients were identified from 2 large claims databases. For each year between 2007 and 2016, prevalence was calculated per 100,000 population and standardized based on the 2016 national Census. A fixed-effects meta-analytical model was used for overall prevalence.   RESULTS The pediatric prevalence of IBD overall increased by 133%, from 33.0/100,000 in 2007 to 77.0/100,000 in 2016. Among children, CD was twice as prevalent as UC (45.9 vs 21.6). Prevalence was higher in boys than girls for all forms of IBD, in contrast to the adult population where the prevalence was higher in women than men. We also found that the 10-17 age subgroup was the major contributor to the rising pediatric IBD prevalence. For adults, the prevalence of IBD overall increased by 123%, from 214.9 in 2007 to 478.4 in 2016. The prevalence rates of UC and CD were similar (181.1 vs 197.7) in 2016.   CONCLUSIONS Inflammatory bowel disease continues to affect a substantial proportion of the US population. In 2016, 1 in 209 adults and 1 in 1299 children aged 2-17 were affected by IBD. Prevalence of IBD has been increasing compared with previously published 2009 data."
Databases (cs.DB),2019,13,Enhancing glycolysis attenuates Parkinson's disease progression in models and clinical databases.,202,N/A,https://www.semanticscholar.org/paper/22e73556f122d325b7e0c27b477d56fe8d3cbfbb,"R. Cai, Y. Zhang, J. Simmering et al.","Parkinson's disease (PD) is a common neurodegenerative disease that lacks therapies to prevent progressive neurodegeneration. Impaired energy metabolism and reduced ATP levels are common features of PD. Previous studies revealed that terazosin (TZ) enhances the activity of phosphoglycerate kinase 1 (PGK1), thereby stimulating glycolysis and increasing cellular ATP levels. Therefore, we asked whether enhancement of PGK1 activity would change the course of PD. In toxin-induced and genetic PD models in mice, rats, flies, and induced pluripotent stem cells, TZ increased brain ATP levels and slowed or prevented neuron loss. The drug increased dopamine levels and partially restored motor function. Because TZ is prescribed clinically, we also interrogated 2 distinct human databases. We found slower disease progression, decreased PD-related complications, and a reduced frequency of PD diagnoses in individuals taking TZ and related drugs. These findings suggest that enhancing PGK1 activity and increasing glycolysis may slow neurodegeneration in PD."
Databases (cs.DB),2019,15,"A New Global Database of Lunar Impact Craters >1–2 km: 1. Crater Locations and Sizes, Comparisons With Published Databases, and Global Analysis",196,N/A,https://www.semanticscholar.org/paper/2c11771a34bc1f93967acd6caddb5b39b88072e9,S. Robbins,"This paper presents a new, global database of lunar impact craters, estimated to be a complete census of all craters with diameters larger than 1–2 km. The database contains over 2 million craters, making it larger in number than any previously published lunar effort by more than a factor of 10. Of those craters, 1.3 million have diameters ≥1 km, approximately 83,000 are ≥5 km, and 6,972 craters are ≥20 km. How the database was constructed along with the reliability of features is described in detail. Comparisons are made with past published databases, demonstrating good agreement for crater size and location. An ellipticity analysis is conducted, illustrating there is no dominant direction for elliptical crater orientation based on location, diameter range, or ellipticity amount, consistent with randomness for craters ≥10 km. A spatial density analysis is described, comparing the spatial density of small versus large craters, and numerous observations about the nonuniformity of the size distributions of craters across the Moon are made. The spatial density is also used in a discussion about kilometer‐scale secondary impact craters and clearly shows that they dominate the crater population in some areas of the lunar surface. This paper presents just a tiny sample of the scientific investigations that could be done with this new crater database."
Databases (cs.DB),2019,16,Identification of Acinetobacter baumannii loci for capsular polysaccharide (KL) and lipooligosaccharide outer core (OCL) synthesis in genome assemblies using curated reference databases compatible with Kaptive,181,N/A,https://www.semanticscholar.org/paper/d29870b683e8f119a3b4ecb2d809bfcc6ced126c,"K. Wyres, S. M. Cahill, K. Holt et al.","Multiply antibiotic resistant Acinetobacter baumannii infections are a global public health concern and accurate tracking of the spread of specific lineages is needed. Variation in the composition and structure of capsular polysaccharide (CPS), a critical determinant of virulence and phage susceptibility, makes it an attractive epidemiological marker. The outer core (OC) of lipooligosaccharide also exhibits variation. To take better advantage of the untapped information available in whole genome sequences, we have created a curated reference database of the 92 publicly available gene clusters at the locus encoding proteins responsible for biosynthesis and export of CPS (K locus), and a second database for the 12 gene clusters at the locus for outer core biosynthesis (OC locus). Each entry has been assigned a unique KL or OCL number, and is fully annotated using a simple, transparent and standardised nomenclature. These databases are compatible with Kaptive, a tool for in silico typing of bacterial surface polysaccharide loci, and their utility was validated using a) >630 assembled A. baumannii draft genomes for which the KL and OCL regions had been previously typed manually, and b) 3386 A. baumannii genome assemblies downloaded from NCBI. Among the previously typed genomes, Kaptive was able to confidently assign KL and OCL types with 100% accuracy. Among the genomes retrieved from NCBI, Kaptive detected known KL and OCL in 87% and 90% of genomes, respectively indicating that the majority of common KL and OCL types are captured within the databases; 13 KL were not detected in any public genome assembly. The failure to assign a KL or OCL type may indicate incomplete or poor-quality genomes. However, further novel variants may remain to be documented. Combining outputs with multi-locus sequence typing (Institut Pasteur scheme) revealed multiple KL and OCL types in collections of a single sequence type (ST) representing each of the two predominant globally-distributed clones, ST1 of GC1 and ST2 of GC2, and in collections of other clones comprising >20 isolates each (ST10, ST25, and ST140), indicating extensive within-clone replacement of these loci. The databases are available at https://github.com/katholt/Kaptive and will be updated as further locus types become available. Data Summary 1. Databases including fully annotated gene cluster sequences for A. baumannii K loci and OC loci are available for download at https://github.com/katholt/Kaptive 2. The Kaptive software, which can be used to screen new genomes against the K and O locus database is available at https://github.com/katholt/Kaptive (command-line code) and http://kaptive.holtlab.net/ (interactive web service). 3. Details of the Kaptive search results validating in silico serotyping of K and O loci using our approach are provided as supplementary files, Dataset 1 (92 KL reference sequences and 12 OCL reference sequences), Dataset 2 (642 genomes assembled from reads available in NCBI SRA) and Dataset 3 (3415 genome assemblies downloaded from NCBI GenBank). Impact statement The ability to identify and track closely related isolates is key to understanding, and ultimately controlling, the spread of multiply antibiotic resistant A. baumannii causing difficult to treat infections, which are an urgent public health threat. Extensive variation in the KL and OCL gene clusters responsible for biosynthesis of capsule and the outer core of lipooligosaccharide, respectively, are potentially highly informative epidemiological markers. However, clear, well-documented identification of each variant and simple-to-use tools and procedures are needed to reliably identify them in genome sequence data. Here, we present curated databases compatible with the available web-based and command-line Kaptive tool to make KL and OCL typing readily accessible to assist epidemiological surveillance of this species. As many bacteriophage recognise specific properties of the capsule and attach to it, capsule typing is also important in assessing the potential of specific phage for therapy on a case by case basis."
Databases (cs.DB),2019,18,Challenges with quality of race and ethnicity data in observational databases,175,N/A,https://www.semanticscholar.org/paper/9eddb7001997af84f7204ce561221f27cbf8e305,"Fernanda C. G. Polubriaginof, P. Ryan, H. Salmasian et al.","OBJECTIVE We sought to assess the quality of race and ethnicity information in observational health databases, including electronic health records (EHRs), and to propose patient self-recording as an improvement strategy.   MATERIALS AND METHODS We assessed completeness of race and ethnicity information in large observational health databases in the United States (Healthcare Cost and Utilization Project and Optum Labs), and at a single healthcare system in New York City serving a racially and ethnically diverse population. We compared race and ethnicity data collected via administrative processes with data recorded directly by respondents via paper surveys (National Health and Nutrition Examination Survey and Hospital Consumer Assessment of Healthcare Providers and Systems). Respondent-recorded data were considered the gold standard for the collection of race and ethnicity information.   RESULTS Among the 160 million patients from the Healthcare Cost and Utilization Project and Optum Labs datasets, race or ethnicity was unknown for 25%. Among the 2.4 million patients in the single New York City healthcare system's EHR, race or ethnicity was unknown for 57%. However, when patients directly recorded their race and ethnicity, 86% provided clinically meaningful information, and 66% of patients reported information that was discrepant with the EHR.   DISCUSSION Race and ethnicity data are critical to support precision medicine initiatives and to determine healthcare disparities; however, the quality of this information in observational databases is concerning. Patient self-recording through the use of patient-facing tools can substantially increase the quality of the information while engaging patients in their health.   CONCLUSIONS Patient self-recording may improve the completeness of race and ethnicity information."
Databases (cs.DB),2019,17,A comparative survey of recent natural language interfaces for databases,162,1906.08990,https://www.semanticscholar.org/paper/c4e3955219e8b008e4a14fbd0a1aac17cdba568d,"Katrin Affolter, Kurt Stockinger, A. Bernstein","Over the last few years, natural language interfaces (NLI) for databases have gained significant traction both in academia and industry. These systems use very different approaches as described in recent survey papers. However, these systems have not been systematically compared against a set of benchmark questions in order to rigorously evaluate their functionalities and expressive power. In this paper, we give an overview over 24 recently developed NLIs for databases. Each of the systems is evaluated using a curated list of ten sample questions to show their strengths and weaknesses. We categorize the NLIs into four groups based on the methodology they are using: keyword-, pattern-, parsing- and grammar-based NLI. Overall, we learned that keyword-based systems are enough to answer simple questions. To solve more complex questions involving subqueries, the system needs to apply some sort of parsing to identify structural dependencies. Grammar-based systems are overall the most powerful ones, but are highly dependent on their manually designed rules. In addition to providing a systematic analysis of the major systems, we derive lessons learned that are vital for designing NLIs that can answer a wide range of user questions."
Databases (cs.DB),2019,19,Criteria2Query: a natural language interface to clinical databases for cohort definition,143,N/A,https://www.semanticscholar.org/paper/e5486b085230312722b872ae027803afb68dad28,"Chi Yuan, P. Ryan, Casey N. Ta et al.","Abstract Objective Cohort definition is a bottleneck for conducting clinical research and depends on subjective decisions by domain experts. Data-driven cohort definition is appealing but requires substantial knowledge of terminologies and clinical data models. Criteria2Query is a natural language interface that facilitates human-computer collaboration for cohort definition and execution using clinical databases. Materials and Methods Criteria2Query uses a hybrid information extraction pipeline combining machine learning and rule-based methods to systematically parse eligibility criteria text, transforms it first into a structured criteria representation and next into sharable and executable clinical data queries represented as SQL queries conforming to the OMOP Common Data Model. Users can interactively review, refine, and execute queries in the ATLAS web application. To test effectiveness, we evaluated 125 criteria across different disease domains from ClinicalTrials.gov and 52 user-entered criteria. We evaluated F1 score and accuracy against 2 domain experts and calculated the average computation time for fully automated query formulation. We conducted an anonymous survey evaluating usability. Results Criteria2Query achieved 0.795 and 0.805 F1 score for entity recognition and relation extraction, respectively. Accuracies for negation detection, logic detection, entity normalization, and attribute normalization were 0.984, 0.864, 0.514 and 0.793, respectively. Fully automatic query formulation took 1.22 seconds/criterion. More than 80% (11+ of 13) of users would use Criteria2Query in their future cohort definition tasks. Conclusions We contribute a novel natural language interface to clinical databases. It is open source and supports fully automated and interactive modes for autonomous data-driven cohort definition by researchers with minimal human effort. We demonstrate its promising user friendliness and usability."
Databases (cs.DB),2019,20,Mutation Hotspots in the β-Catenin Gene: Lessons from the Human Cancer Genome Databases,129,N/A,https://www.semanticscholar.org/paper/f1b058dada9f88c5fb86422139fd77cba59e72e4,"Sewoon Kim, Sunjoo Jeong","Mutations in the β-catenin gene (CTNNB1) have been implicated in the pathogenesis of some cancers. The recent development of cancer genome databases has facilitated comprehensive and focused analyses on the mutation status of cancer-related genes. We have used these databases to analyze the CTNNB1 mutations assembled from different tumor types. High incidences of CTNNB1 mutations were detected in endometrial, liver, and colorectal cancers. This finding agrees with the oncogenic role of aberrantly activated β-catenin in epithelial cells. Elevated frequencies of missense mutations were found in the exon 3 of CTNNB1, which is responsible for encoding the regulatory amino acids at the N-terminal region of the protein. In the case of metastatic colorectal cancers, inframe deletions were revealed in the region spanning exon 3. Thus, exon 3 of CTNNB1 can be considered to be a mutation hotspot in these cancers. Since the N-terminal region of the β-catenin protein forms a flexible structure, many questions arise regarding the structural and functional impacts of hotspot mutations. Clinical identification of hotspot mutations could provide the mechanistic basis for an oncogenic role of mutant β-catenin proteins in cancer cells. Furthermore, a systematic understanding of tumor-driving hotspot mutations could open new avenues for precision oncology."
Databases (cs.DB),2023,1,LIPID MAPS: update to databases and tools for the lipidomics community,149,N/A,https://www.semanticscholar.org/paper/61b17d2a5711734b8bf3f0adfa0141166dcc0ea3,"Matthew J Conroy, Robert M Andrews, Simon Andrews et al.","Abstract LIPID MAPS (LIPID Metabolites and Pathways Strategy), www.lipidmaps.org, provides a systematic and standardized approach to organizing lipid structural and biochemical data. Founded 20 years ago, the LIPID MAPS nomenclature and classification has become the accepted community standard. LIPID MAPS provides databases for cataloging and identifying lipids at varying levels of characterization in addition to numerous software tools and educational resources, and became an ELIXIR-UK data resource in 2020. This paper describes the expansion of existing databases in LIPID MAPS, including richer metadata with literature provenance, taxonomic data and improved interoperability to facilitate FAIR compliance. A joint project funded by ELIXIR-UK, in collaboration with WikiPathways, curates and hosts pathway data, and annotates lipids in the context of their biochemical pathways. Updated features of the search infrastructure are described along with implementation of programmatic access via API and SPARQL. New lipid-specific databases have been developed and provision of lipidomics tools to the community has been updated. Training and engagement have been expanded with webinars, podcasts and an online training school."
Databases (cs.DB),2023,2,ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory,136,2306.03901,https://www.semanticscholar.org/paper/50f44ef10335d59cec145b15effae20ff22c1fdb,"Chenxu Hu, Jie Fu, Chenzhuang Du et al.","Large language models (LLMs) with memory are computationally universal. However, mainstream LLMs are not taking full advantage of memory, and the designs are heavily influenced by biological brains. Due to their approximate nature and proneness to the accumulation of errors, conventional neural memory mechanisms cannot support LLMs to simulate complex reasoning. In this paper, we seek inspiration from modern computer architectures to augment LLMs with symbolic memory for complex multi-hop reasoning. Such a symbolic memory framework is instantiated as an LLM and a set of SQL databases, where the LLM generates SQL instructions to manipulate the SQL databases. We validate the effectiveness of the proposed memory framework on a synthetic dataset requiring complex reasoning. The project website is available at https://chatdatabase.github.io/ ."
Databases (cs.DB),2023,11,"Large language models should be used as scientific reasoning engines, not knowledge databases",84,N/A,https://www.semanticscholar.org/paper/f7ab8bafde4f32d63801f136ce575be62a41fb22,"D. Truhn, J. Reis-Filho, Jakob Nikolas Kather",No Abstract
Databases (cs.DB),2023,12,"Transcriptome-wide association studies: recent advances in methods, applications and available databases",83,N/A,https://www.semanticscholar.org/paper/3b18e7a6d8e58dd8f957d6c71b1e6c3ae6566ac6,"Jialin Mai, Mingming Lu, Qianwen Gao et al.","Genome-wide association study has identified fruitful variants impacting heritable traits. Nevertheless, identifying critical genes underlying those significant variants has been a great task. Transcriptome-wide association study (TWAS) is an instrumental post-analysis to detect significant gene-trait associations focusing on modeling transcription-level regulations, which has made numerous progresses in recent years. Leveraging from expression quantitative loci (eQTL) regulation information, TWAS has advantages in detecting functioning genes regulated by disease-associated variants, thus providing insight into mechanisms of diseases and other phenotypes. Considering its vast potential, this review article comprehensively summarizes TWAS, including the methodology, applications and available resources. This review provides a comprehensive summary of transcriptome-wide association study (TWAS) methods, applications and available resources."
Databases (cs.DB),2023,4,"Advanced Methods for Natural Products Discovery: Bioactivity Screening, Dereplication, Metabolomics Profiling, Genomic Sequencing, Databases and Informatic Tools, and Structure Elucidation",80,N/A,https://www.semanticscholar.org/paper/58c7d11645bf7aef2173000c66dd94ebd1fc1473,"Susana P. Gaudêncio, Engin Bayram, Lada Lukić Bilela et al.","Natural Products (NP) are essential for the discovery of novel drugs and products for numerous biotechnological applications. The NP discovery process is expensive and time-consuming, having as major hurdles dereplication (early identification of known compounds) and structure elucidation, particularly the determination of the absolute configuration of metabolites with stereogenic centers. This review comprehensively focuses on recent technological and instrumental advances, highlighting the development of methods that alleviate these obstacles, paving the way for accelerating NP discovery towards biotechnological applications. Herein, we emphasize the most innovative high-throughput tools and methods for advancing bioactivity screening, NP chemical analysis, dereplication, metabolite profiling, metabolomics, genome sequencing and/or genomics approaches, databases, bioinformatics, chemoinformatics, and three-dimensional NP structure elucidation."
Databases (cs.DB),2023,5,Spatial and temporal landslide distributions using global and open landslide databases,79,N/A,https://www.semanticscholar.org/paper/94ee8c76d475831d73c19319b043e2598c552222,"Derly Gómez, Edwin F. García, E. Aristizábal","Landslide databases are a potential tool for the analysis of landslide susceptibility, hazard, and risk. Additionally, the spatio-temporal distribution of landslides and their correlation with their triggering factors are inputs that facilitate the evaluation of landslide prediction models and the determination of thresholds necessary for early warning systems (EWS). This study presents an analysis of four widely known global databases—the International Disaster database (EM-DAT), the Disaster Inventory System (DesInventar), the Global Landslide Catalog (GLC), and the Global Fatal Landslide database (GFLD)—which contain relevant landslide information for different regions of the world. These databases were analysed and compared by means of the spatio-temporal distributions of their records. Subsequently, these databases were merged and depurated to obtain a more robust database, namely the Unified Global Landslide Database (UGLD), with 161 countries, 37,946 landslides, and 185,753 fatalities registered between 1903 and 2020. The merging process among the databases resulted in a small number of repeated landslides, indicating that the databases collect very different landslide information and complement each other. Finally, an update of the spatial and temporal analysis of landslides in the world was performed with the new database, in which patterns, trends, and the main triggers were presented and analysed. The results obtained from the analysis of the UGLD database show the American and Asian continents as the continents with the highest number of landslides and associated fatalities, showing a bimodal and unimodal annual temporal pattern, respectively. Regarding the most frequent triggers of landslides, rainfall, anthropogenic intervention, and earthquakes stand out."
Databases (cs.DB),2023,6,Human Ageing Genomic Resources: updates on key databases in ageing research,68,N/A,https://www.semanticscholar.org/paper/a0be87cae8171cd1f5d5bb71490468cb3f8c4a07,"J. de Magalhães, Zoya Abidi, Gabriel Arantes dos Santos et al.","Ageing is a complex and multifactorial process. For two decades, the Human Ageing Genomic Resources (HAGR) have aided researchers in the study of various aspects of ageing and its manipulation. Here we present the key features and recent enhancements of these resources, focusing on its six main databases. One database, GenAge, focuses on genes related to ageing, featuring 307 genes linked to human ageing and 2205 genes associated with longevity and ageing in model organisms. AnAge focuses on ageing, longevity, and life-history across animal species, containing data on 4645 species. DrugAge includes information about 1097 longevity drugs and compounds in model organisms such as mice, rats, flies, worms, and yeast. GenDR provides a list of 214 genes associated with the life-extending benefits of dietary restriction in model organisms. CellAge contains a catalogue of 866 genes associated with cellular senescence. The LongevityMap serves as a repository for genetic variants associated with human longevity, encompassing 3144 variants pertaining to 884 genes. Additionally, HAGR provides various tools as well as gene expression signatures of ageing, dietary restriction, and replicative senescence based on meta-analyses. Our databases are integrated, regularly updated, and manually curated by experts. HAGR is freely available online (https://genomics.senescence.info/)."
Databases (cs.DB),2023,3,Efficient Approximate Nearest Neighbor Search in Multi-dimensional Databases,67,N/A,https://www.semanticscholar.org/paper/dbcfa8a6fec5a12dc3a35b3587f7a3956a65c0e5,"Yun Peng, Byron Choi, Tsz Nam Chan et al.",No Abstract
Databases (cs.DB),2023,13,CavityPlus 2022 Update: An Integrated Platform for Comprehensive Protein Cavity Detection and Property Analyses with User-friendly Tools and Cavity Databases.,67,N/A,https://www.semanticscholar.org/paper/5a0e6f5dca2112445690407f3aa45cb51b24d045,"Shiwei Wang, Juan Xie, Jianfeng Pei et al.",No Abstract
Databases (cs.DB),2023,17,The accuracy of race & ethnicity data in US based healthcare databases: A systematic review.,59,N/A,https://www.semanticscholar.org/paper/5fba82d941bf1d04f6657903eaa978d251c11e37,"Joshlyn Johnson, Brandon Moore, Eun Kyeong Hwang et al.",No Abstract
Databases (cs.DB),2023,7,Relational Deep Learning: Graph Representation Learning on Relational Databases,48,2312.04615,https://www.semanticscholar.org/paper/17a6213e30895fb7e5d0b368236ea8beeb94ee86,"Matthias Fey, Weihua Hu, Kexin Huang et al.","Much of the world's most valued data is stored in relational databases and data warehouses, where the data is organized into many tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming. The core problem is that no machine learning method is capable of learning on multiple tables interconnected by primary-foreign key relations. Current methods can only learn from a single table, so the data must first be manually joined and aggregated into a single training table, the process known as feature engineering. Feature engineering is slow, error prone and leads to suboptimal models. Here we introduce an end-to-end deep representation learning approach to directly learn on data laid out across multiple tables. We name our approach Relational Deep Learning (RDL). The core idea is to view relational databases as a temporal, heterogeneous graph, with a node for each row in each table, and edges specified by primary-foreign key links. Message Passing Graph Neural Networks can then automatically learn across the graph to extract representations that leverage all input data, without any manual feature engineering. Relational Deep Learning leads to more accurate models that can be built much faster. To facilitate research in this area, we develop RelBench, a set of benchmark datasets and an implementation of Relational Deep Learning. The data covers a wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon Product Catalog. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability to a wide set of AI use cases."
Databases (cs.DB),2023,8,CLOOME: contrastive learning unlocks bioimaging databases for queries with chemical structures,48,N/A,https://www.semanticscholar.org/paper/2b6e24ba475529244cdb917a619126287b8b68b2,"Ana Sánchez-Fernández, Elisabeth Rumetshofer, Sepp Hochreiter et al.","Currently, bioimaging databases cannot be queried by chemical structures that induce the phenotypic effects captured by an image. Through the advent of the contrastive learning paradigm, images and text could be embedded into the same space. We build on this contrastive learning paradigm, to present a novel retrieval system that is able to identify the correct bioimage given a chemical structure out of a database of ∼2,000 candidate images with a top-1 accuracy >70 times higher than a random baseline. Additionally, the learned embeddings of our method are highly transferable to various relevant downstream tasks in drug discovery, including activity prediction, microscopy image classification and mechanism of action identification."
Databases (cs.DB),2023,9,A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases,45,2311.07509,https://www.semanticscholar.org/paper/b66c5d17424b37c46980d50bd2796c568e1e926f,"Juan Sequeda, D. Allemang, Bryon Jacob","Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems."
Databases (cs.DB),2023,10,Neural Graph Reasoning: Complex Logical Query Answering Meets Graph Databases,44,2303.14617,https://www.semanticscholar.org/paper/033275ccc2c7c5c38592ae893da0b5923cf90717,"Hongyu Ren, Mikhail Galkin, Michael Cochez et al.","Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves a far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs in a latent space. The task received a significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications. Refining the CLQA task, we introduce the concept of Neural Graph Databases (NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we design a graph store, a feature store, and further embed information in a latent embedding store using an encoder. Given a query, Neural Query Engine learns how to perform query planning and execution in order to efficiently retrieve the correct results by interacting with the Neural Graph Storage. Compared with traditional graph DBs, NGDBs allow for a flexible and unified modeling of features in diverse modalities using the embedding store. Moreover, when the graph is incomplete, they can provide robust retrieval of answers which a normal graph DB cannot recover. Finally, we point out promising directions, unsolved problems and applications of NGDB for future research."
Databases (cs.DB),2023,19,Domain Adaptive Code Completion via Language Models and Decoupled Domain Databases,43,2308.09313,https://www.semanticscholar.org/paper/8e460e470cdd6c9ee3263aa877ff94e851f10762,"Ze Tang, Jidong Ge, Shangqing Liu et al.","Large Language Models (LLMs) have demonstrated remarkable performance in code completion. However, due to the lack of domain-specific knowledge, they may not be optimal in completing code that requires intensive domain knowledge for example completing the library names. Although there are several works that have confirmed the effectiveness of fine-tuning techniques to adapt language models for code completion in specific domains. They are limited by the need for constant fine-tuning of the model when the project is in constant iteration. To address this limitation, in this paper, we propose $k$ NM-LM, a retrieval-augmented language model (R-LM), that integrates domain knowledge into language models without fine-tuning. Different from previous techniques, our approach is able to automatically adapt to different language models and domains. Specifically, it utilizes the in-domain code to build the retrieval-based database decoupled from LM, and then combines it with LM through Bayesian inference to complete the code. The extensive experiments on the completion of intra-project and intra-scenario have confirmed that $k$ NM-LM brings about appreciable enhancements when compared to CodeGPT and UnixCoder. A deep analysis of our tool including the responding speed, storage usage, specific type code completion, and API invocation completion has confirmed that $k$ NM-LM provides satisfactory performance, which renders it highly appropriate for domain adaptive code completion. Furthermore, our approach operates without the requirement for direct access to the language model's parameters. As a result, it can seamlessly integrate with black-box code completion models, making it easy to integrate our approach as a plugin to further enhance the performance of these models."
Databases (cs.DB),2023,15,"Drug–drug interaction prediction: databases, web servers and computational models",42,N/A,https://www.semanticscholar.org/paper/63ad3c36eb728ae281120e84eed208cbefe77c6c,"Yan Zhao, Jun Yin, Li Zhang et al.","Abstract In clinical treatment, two or more drugs (i.e. drug combination) are simultaneously or successively used for therapy with the purpose of primarily enhancing the therapeutic efficacy or reducing drug side effects. However, inappropriate drug combination may not only fail to improve efficacy, but even lead to adverse reactions. Therefore, according to the basic principle of improving the efficacy and/or reducing adverse reactions, we should study drug–drug interactions (DDIs) comprehensively and thoroughly so as to reasonably use drug combination. In this review, we first introduced the basic conception and classification of DDIs. Further, some important publicly available databases and web servers about experimentally verified or predicted DDIs were briefly described. As an effective auxiliary tool, computational models for predicting DDIs can not only save the cost of biological experiments, but also provide relevant guidance for combination therapy to some extent. Therefore, we summarized three types of prediction models (including traditional machine learning-based models, deep learning-based models and score function-based models) proposed during recent years and discussed the advantages as well as limitations of them. Besides, we pointed out the problems that need to be solved in the future research of DDIs prediction and provided corresponding suggestions."
Databases (cs.DB),2023,16,Automatic measurements of left ventricular volumes and ejection fraction by artificial intelligence: clinical validation in real time and large databases,38,N/A,https://www.semanticscholar.org/paper/4c701674abe054585dc1e7ec042451cd86977657,"S. Olaisen, E. Smistad, T. Espeland et al.","Abstract Aims Echocardiography is a cornerstone in cardiac imaging, and left ventricular (LV) ejection fraction (EF) is a key parameter for patient management. Recent advances in artificial intelligence (AI) have enabled fully automatic measurements of LV volumes and EF both during scanning and in stored recordings. The aim of this study was to evaluate the impact of implementing AI measurements on acquisition and processing time and test–retest reproducibility compared with standard clinical workflow, as well as to study the agreement with reference in large internal and external databases. Methods and results Fully automatic measurements of LV volumes and EF by a novel AI software were compared with manual measurements in the following clinical scenarios: (i) in real time use during scanning of 50 consecutive patients, (ii) in 40 subjects with repeated echocardiographic examinations and manual measurements by 4 readers, and (iii) in large internal and external research databases of 1881 and 849 subjects, respectively. Real-time AI measurements significantly reduced the total acquisition and processing time by 77% (median 5.3 min, P < 0.001) compared with standard clinical workflow. Test–retest reproducibility of AI measurements was superior in inter-observer scenarios and non-inferior in intra-observer scenarios. AI measurements showed good agreement with reference measurements both in real time and in large research databases. Conclusion The software reduced the time taken to perform and volumetrically analyse routine echocardiograms without a decrease in accuracy compared with experts."
Databases (cs.DB),2023,20,Chatbots and ChatGPT: A Bibliometric Analysis and Systematic Review of Publications in Web of Science and Scopus Databases,34,2304.05436,https://www.semanticscholar.org/paper/c2a66aecd6fe33190f77bad8e1bd3a8c841a20a2,"H. Khosravi, M. Shafie, Morteza Hajiabadi et al.","This paper presents a bibliometric analysis of the scientific literature related to chatbots, focusing specifically on ChatGPT. Chatbots have gained increasing attention recently, with an annual growth rate of 19.16% and 27.19% on the Web of Sciences (WoS) and Scopus, respectively. In this study, we have explored the structure, conceptual evolution, and trends in this field by analyzing data from both Scopus and WoS databases. The research consists of two study phases: (i) an analysis of chatbot literature and (ii) a comprehensive review of scientific documents on ChatGPT. In the first phase, a bibliometric analysis is conducted on all published literature, including articles, book chapters, conference papers, and reviews on chatbots from both Scopus (5839) and WoS (2531) databases covering the period from 1998 to 2023. An in-depth analysis focusing on sources, countries, authors' impact, and keywords has revealed that ChatGPT is the latest trend in the chatbot field. Consequently, in the second phase, bibliometric analysis has been carried out on ChatGPT publications, and 45 published studies have been analyzed thoroughly based on their methods, novelty, and conclusions. The key areas of interest identified from the study can be classified into three groups: artificial intelligence and related technologies, design and evaluation of conversational agents, and digital technologies and mental health. Overall, the study aims to provide guidelines for researchers to conduct their research more effectively in the field of chatbots and specifically highlight significant areas for future investigation into ChatGPT."
Databases (cs.DB),2023,14,Don't be Dense: Efficient Keyword PIR for Sparse Databases,33,N/A,https://www.semanticscholar.org/paper/3d1fff6e566ffe50399c38017fb19747ab3c3253,"Sarvar Patel, Joon Young Seo, Kevin Yeo",No Abstract
Databases (cs.DB),2023,18,Review of databases for experimentally validated human microRNA–mRNA interactions,26,N/A,https://www.semanticscholar.org/paper/8e6d40cdad17afea784b7ad9a3c88e44b4371bad,"Dorian Kariuki, K. Asam, B. Aouizerat et al.","Abstract MicroRNAs (miRs) may contribute to disease etiology by influencing gene expression. Numerous databases are available for miR target prediction and validation, but their functionality is varied, and outputs are not standardized. The purpose of this review is to identify and describe databases for cataloging validated miR targets. Using Tools4miRs and PubMed, we identified databases with experimentally validated targets, human data, and a focus on miR–messenger RNA (mRNA) interactions. Data were extracted about the number of times each database was cited, the number of miRs, the target genes, the interactions per database, experimental methodology and key features of each database. The search yielded 10 databases, which in order of most cited to least were: miRTarBase, starBase/The Encyclopedia of RNA Interactomes, DIANA-TarBase, miRWalk, miRecords, miRGator, miRSystem, miRGate, miRSel and targetHub. Findings from this review suggest that the information presented within miR target validation databases can be enhanced by adding features such as flexibility in performing queries in multiple ways, downloadable data, ongoing updates and integrating tools for further miR–mRNA target interaction analysis. This review is designed to aid researchers, especially those new to miR bioinformatics tools, in database selection and to offer considerations for future development and upkeep of validation tools. Database URL http://mirtarbase.cuhk.edu.cn/"
Databases (cs.DB),2024,1,When Large Language Models Meet Vector Databases: A Survey,68,2402.01763,https://www.semanticscholar.org/paper/16c816201eb629a758676a3c1fa4cead50e5f412,"Zhi Jing, Yongye Su, Yikun Han et al.","This survey explores the synergistic potential of Large Language Models (LLMs) and Vector Databases (VecDBs), a burgeoning but rapidly evolving research area. With the proliferation of LLMs comes a host of challenges, including hallucinations, outdated knowledge, prohibitive commercial application costs, and memory issues. VecDBs emerge as a compelling solution to these issues by offering an efficient means to store, retrieve, and manage the high-dimensional vector representations intrinsic to LLM operations. Through this nuanced review, we delineate the foundational principles of LLMs and VecDBs and critically analyze their integration’s impact on enhancing LLM functionalities. This discourse extends into a discussion on the speculative future developments in this domain, aiming to catalyze further research into optimizing the confluence of LLMs and VecDBs for advanced data handling and knowledge extraction capabilities."
Databases (cs.DB),2024,3,"Beyond Google Scholar, Scopus, and Web of Science: An evaluation of the backward and forward citation coverage of 59 databases' citation indices",62,N/A,https://www.semanticscholar.org/paper/67a84df356ef514aa8f85d6e2cf23e6ee09c1b69,Michael Gusenbauer,"Citation indices providing information on backward citation (BWC) and forward citation (FWC) links are essential for literature discovery, bibliographic analysis, and knowledge synthesis, especially when language barriers impede document identification. However, the suitability of citation indices varies. While some have been analyzed, the majority, whether new or established, lack comprehensive evaluation. Therefore, this study evaluates the citation coverage of the citation indices of 59 databases, encompassing the widely used Google Scholar, Scopus, and Web of Science alongside many others never previously analyzed, such as the emerging Lens, Scite, Dimensions, and OpenAlex or the subject‐specific PubMed and JSTOR. Through a comprehensive analysis using 259 journal articles from across disciplines, this research aims to guide scholars in selecting indices with broader document coverage and more accurate and comprehensive backward and forward citation links. Key findings highlight Google Scholar, ResearchGate, Semantic Scholar, and Lens as leading options for FWC searching, with Lens providing superior download capabilities. For BWC searching, the Web of Science Core Collection can be recommended over Scopus for accuracy. BWC information from publisher databases such as IEEE Xplore or ScienceDirect was generally found to be the most accurate, yet only available for a limited number of articles. The findings will help scholars conducting systematic reviews, meta‐analyses, and bibliometric analyses to select the most suitable databases for citation searching."
Databases (cs.DB),2024,12,Probable extinction of influenza B/Yamagata and its public health implications: a systematic literature review and assessment of global surveillance databases.,50,N/A,https://www.semanticscholar.org/paper/4ffc8571b9d6803fdd77dc3af30d40759d1b58f9,"S. Caini, Adam Meijer, Marta C Nunes et al.",No Abstract
Databases (cs.DB),2024,2,"Use of GLP1 receptor agonists in early pregnancy and reproductive safety: a multicentre, observational, prospective cohort study based on the databases of six Teratology Information Services",48,N/A,https://www.semanticscholar.org/paper/f87561c39e2543eb842aa17b2b4b6a3905506f4d,"K. Dao, S. Shechtman, C. Weber-Schoendorfer et al.","Objectives Glucagon-like peptide 1 receptor agonists (GLP1-RA) are indicated for the treatment of type 2 diabetes and more recently for weight loss. The aim of this study was to assess the risks associated with GLP1-RA exposure during early pregnancy. Design This multicentre, observational prospective cohort study compared pregnancy outcomes in women exposed to GLP1-RA in early pregnancy either for diabetes or obesity treatment with those in two reference groups: (1) women with diabetes exposed to at least one non-GLP1-RA antidiabetic drug during the first trimester and (2) a reference group of overweight/obese women without diabetes, between 2009 and 2022. Setting Data were collected from the databases of six Teratology Information Services. Participants This study included 168 pregnancies of women exposed to GLP1-RA during the first trimester, alongside a reference group of 156 pregnancies of women with diabetes and 163 pregnancies of overweight/obese women. Results Exposure to GLP1-RA in the first trimester was not associated with a risk of major birth defects when compared with diabetes (2.6% vs 2.3%; adjusted OR, 0.98 (95% CI, 0.16 to 5.82)) or to overweight/obese (2.6% vs 3.9%; adjusted OR 0.54 (0.11 to 2.75)). For the GLP1-RA group, cumulative incidence for live births, pregnancy losses and pregnancy terminations was 59%, 23% and 18%, respectively. In the diabetes reference group, corresponding estimates were 69%, 26% and 6%, while in the overweight/obese reference group, they were 63%, 29% and 8%, respectively. Cox proportional cause-specific hazard models indicated no increased risk of pregnancy losses in the GLP1-RA versus the diabetes and the overweight/obese reference groups, in both crude and adjusted analyses. Conclusions This study offers reassurance in cases of inadvertent exposure to GLP1-RA during the first trimester of pregnancy. Due to the limited sample size, larger studies are required to validate these findings."
Databases (cs.DB),2024,10,Ten common issues with reference sequence databases and how to mitigate them,41,N/A,https://www.semanticscholar.org/paper/94c4aef1178ebbd332222f158ba33389f68bd8e5,S. Chorlton,"Metagenomic sequencing has revolutionized our understanding of microbiology. While metagenomic tools and approaches have been extensively evaluated and benchmarked, far less attention has been given to the reference sequence database used in metagenomic classification. Issues with reference sequence databases are pervasive. Database contamination is the most recognized issue in the literature; however, it remains relatively unmitigated in most analyses. Other common issues with reference sequence databases include taxonomic errors, inappropriate inclusion and exclusion criteria, and sequence content errors. This review covers ten common issues with reference sequence databases and the potential downstream consequences of these issues. Mitigation measures are discussed for each issue, including bioinformatic tools and database curation strategies. Together, these strategies present a path towards more accurate, reproducible and translatable metagenomic sequencing."
Databases (cs.DB),2024,5,CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases,39,2408.03910,https://www.semanticscholar.org/paper/514e4e91e0fbddaa85857760d4f206a18228d614,"Xiangyan Liu, Bo Lan, Zhiyuan Hu et al.","Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval and MBPP, but struggle with handling entire code repositories. This challenge has prompted research on enhancing LLM-codebase interaction at a repository scale. Current solutions rely on similarity-based retrieval or manual tools and APIs, each with notable drawbacks. Similarity-based retrieval often has low recall in complex tasks, while manual tools and APIs are typically task-specific and require expert knowledge, reducing their generalizability across diverse code tasks and real-world applications. To mitigate these limitations, we introduce CodexGraph, a system that integrates LLM agents with graph database interfaces extracted from code repositories. By leveraging the structural properties of graph databases and the flexibility of the graph query language, CodexGraph enables the LLM agent to construct and execute queries, allowing for precise, code structure-aware context retrieval and code navigation. We assess CodexGraph using three benchmarks: CrossCodeEval, SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding applications. With a unified graph database schema, CodexGraph demonstrates competitive performance and potential in both academic and real-world environments, showcasing its versatility and efficacy in software engineering. Our application demo: https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent."
Databases (cs.DB),2024,7,"A Comprehensive Resource for Exploring Antiphage Defense: DefenseFinder Webservice, Wiki and Databases",39,N/A,https://www.semanticscholar.org/paper/d93078eb93805f0efb90bfc375ce20a7d6c9aac6,"F. Tesson, R. Planel, A. Egorov et al.","In recent years, a vast number of novel antiphage defense mechanisms were uncovered. To facilitate the exploration of mechanistic, ecological, and evolutionary aspects related to antiphage defense systems, we released DefenseFinder in 2021 (Tesson et al., 2022). DefenseFinder is a bioinformatic program designed for the systematic identification of known antiphage defense mechanisms. The initial release of DefenseFinder v1.0.0 included 60 systems. Over the past three years, the number of antiphage systems incorporated into DefenseFinder has grown to 152. The increasing number of known systems makes it a challenge to enter the field and makes the interpretation of detections of antiphage systems difficult. Moreover, the rapid development of sequence-based predictions of structures offers novel possibilities of analysis and should be easily available. To overcome these challenges, we present a hub of resources on defense systems, including: 1) an updated version of DefenseFinder with a web-service search function, 2) a community-curated repository of knowledge on the systems, and 3) precomputed databases, which include annotations done on RefSeq genomes and structure predictions generated by AlphaFold. These pages can be freely accessed for users as a starting point on their journey to better understand a given system. We anticipate that these resources will foster the use of bioinformatics in the study of antiphage systems and will serve the community of researchers who study antiphage systems. This resource is available at: https://defensefinder.mdmlab.fr."
Databases (cs.DB),2024,11,Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases,39,2403.09675,https://www.semanticscholar.org/paper/6768fd3a63ade98b09c83e18939c19abb6573575,"Rio Aguina-Kang, Maxim Gumin, Do Heon Han et al.","We present a system for generating indoor scenes in response to text prompts. The prompts are not limited to a fixed vocabulary of scene descriptions, and the objects in generated scenes are not restricted to a fixed set of object categories -- we call this setting indoor scene generation. Unlike most prior work on indoor scene generation, our system does not require a large training dataset of existing 3D scenes. Instead, it leverages the world knowledge encoded in pre-trained large language models (LLMs) to synthesize programs in a domain-specific layout language that describe objects and spatial relations between them. Executing such a program produces a specification of a constraint satisfaction problem, which the system solves using a gradient-based optimization scheme to produce object positions and orientations. To produce object geometry, the system retrieves 3D meshes from a database. Unlike prior work which uses databases of category-annotated, mutually-aligned meshes, we develop a pipeline using vision-language models (VLMs) to retrieve meshes from massive databases of un-annotated, inconsistently-aligned meshes. Experimental evaluations show that our system outperforms generative models trained on 3D data for traditional, closed-universe scene generation tasks; it also outperforms a recent LLM-based layout generation method on open-universe scene generation."
Databases (cs.DB),2024,4,Text2SQL is Not Enough: Unifying AI and Databases with TAG,38,2408.14717,https://www.semanticscholar.org/paper/0b8a12065f4f5da0165c82e2a21261c1793b65c3,"Asim Biswal, Liana Patel, Siddarth Jha et al.","AI systems that serve natural language questions over databases promise to unlock tremendous value. Such systems would allow users to leverage the powerful reasoning and knowledge capabilities of language models (LMs) alongside the scalable computational power of data management systems. These combined capabilities would empower users to ask arbitrary natural language questions over custom data sources. However, existing methods and benchmarks insufficiently explore this setting. Text2SQL methods focus solely on natural language questions that can be expressed in relational algebra, representing a small subset of the questions real users wish to ask. Likewise, Retrieval-Augmented Generation (RAG) considers the limited subset of queries that can be answered with point lookups to one or a few data records within the database. We propose Table-Augmented Generation (TAG), a unified and general-purpose paradigm for answering natural language questions over databases. The TAG model represents a wide range of interactions between the LM and database that have been previously unexplored and creates exciting research opportunities for leveraging the world knowledge and reasoning capabilities of LMs over data. We systematically develop benchmarks to study the TAG problem and find that standard methods answer no more than 20% of queries correctly, confirming the need for further research in this area. We release code for the benchmark at https://github.com/TAG-Research/TAG-Bench."
Databases (cs.DB),2024,15,Characterization of second primary malignancies post CAR T-cell therapy: real-world insights from the two global pharmacovigilance databases of FAERS and VigiBase,38,N/A,https://www.semanticscholar.org/paper/708975bbad73d17d0f8371cb2798919e63c7af90,"Junyi Shen, Rong Hu, Anqi Lin et al.",No Abstract
Databases (cs.DB),2024,19,Transfer learning for collapse warning in TBM tunneling using databases in China,36,N/A,https://www.semanticscholar.org/paper/db9758482b807a024c5e661c07658177717d2573,"Jinhui Li, Dong Guo, Zuyu Chen et al.",No Abstract
Databases (cs.DB),2024,6,RelBench: A Benchmark for Deep Learning on Relational Databases,35,2407.20060,https://www.semanticscholar.org/paper/f61e5d651061070dec0c40eb3513f0dfb62b4de4,"Joshua Robinson, Rishabh Ranjan, Weihua Hu et al.","We present RelBench, a public benchmark for solving predictive tasks over relational databases with graph neural networks. RelBench provides databases and tasks spanning diverse domains and scales, and is intended to be a foundational infrastructure for future research. We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables. End-to-end learned RDL models fully exploit the predictive signal encoded in primary-foreign key links, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular models. To thoroughly evaluate RDL against this prior gold-standard, we conduct an in-depth user study where an experienced data scientist manually engineers features for each task. In this study, RDL learns better models whilst reducing human work needed by more than an order of magnitude. This demonstrates the power of deep learning for solving predictive tasks over relational databases, opening up many new research opportunities enabled by RelBench."
Databases (cs.DB),2024,20,Thompson Sampling—An Efficient Method for Searching Ultralarge Synthesis on Demand Databases,35,N/A,https://www.semanticscholar.org/paper/022e4c98a2efcb6be883a3dfc229c376d87a7f61,"Kathryn Klarich, Brian B. Goldman, Trevor Kramer et al.","Over the last five years, virtual screening of ultralarge synthesis on-demand libraries has emerged as a powerful tool for hit identification in drug discovery programs. As these libraries have grown to tens of billions of molecules, we have reached a point where it is no longer cost-effective to screen every molecule virtually. To address these challenges, several groups have developed heuristic search methods to rapidly identify the best molecules on a virtual screen. This article describes the application of Thompson sampling (TS), an active learning approach that streamlines the virtual screening of large combinatorial libraries by performing a probabilistic search in the reagent space, thereby never requiring the full enumeration of the library. TS is a general technique that can be applied to various virtual screening modalities, including 2D and 3D similarity search, docking, and application of machine-learning models. In an illustrative example, we show that TS can identify more than half of the top 100 molecules from a docking-based virtual screen of 335 million molecules by evaluating 1% of the data set."
Databases (cs.DB),2024,13,"Chat2Data: An Interactive Data Analysis System with RAG, Vector Databases and LLMs",33,N/A,https://www.semanticscholar.org/paper/e970d243e9fb56100a0371733466ad887a038938,"Xinyang Zhao, Xuanhe Zhou, Guoliang Li","  Traditional data analysis methods require users to write programming codes or issue SQL queries to analyze the data, which are inconvenient for ordinary users. Large language models (LLMs) can alleviate these limitations by enabling users to interact with the data with natural language (NL), e.g., result retrieval and summarization for unstructured data and transforming the NL text to SQL queries or codes for structured data. However, existing LLMs have three limitations: hallucination (due to lacking domain knowledge for vertical domains), high cost for LLM reasoning, and low accuracy for complicated tasks. To address these problems, we propose a prototype, Chat2Data, to interactively analyze the data with natural language. Chat2Data adopts a three-layer method, where the first layer uses Retrieval-Augmented Generation (RAG) to embed domain knowledge in order to address the hallucination problem, the second layer utilizes vector databases to reduce the number of interactions with LLMs so as to improve the performance, and the third layer designs a pipeline agent to decompose a complex task to multiple subtasks and use multiple round reasoning to generate the results in order to improve the accuracy of LLMs. We demonstrate Chat2Data with two real scenarios, unstructured data retrieval and summarization, and natural language-based structured data analysis. The online demo is available at  http://vdemo.dbmind.cn. "
Databases (cs.DB),2024,14,Completeness degree of publication metadata in eight free-access scholarly databases,32,N/A,https://www.semanticscholar.org/paper/e500dadc9fe181bf2659707b94aef95a8e1c159e,"Lorena Delgado-Quirós, José Luis Ortega","Abstract The main objective of this study is to compare the amount of metadata and the completeness degree of research publications in new academic databases. Using a quantitative approach, we selected a random Crossref sample of more than 115,000 records, which was then searched in seven databases (Dimensions, Google Scholar, Microsoft Academic, OpenAlex, Scilit, Semantic Scholar, and The Lens). Seven characteristics were analyzed (abstract, access, bibliographic info, document type, publication date, language, and identifiers), to observe fields that describe this information, the completeness rate of these fields, and the agreement among databases. The results show that academic search engines (Google Scholar, Microsoft Academic, and Semantic Scholar) gather less information and have a low degree of completeness. Conversely, third-party databases (Dimensions, OpenAlex, Scilit, and The Lens) have more metadata quality and a higher completeness rate. We conclude that academic search engines lack the ability to retrieve reliable descriptive data by crawling the web, and the main problem of third-party databases is the loss of information derived from integrating different sources."
Databases (cs.DB),2024,16,Mining Sequential Patterns in Uncertain Databases Using Hierarchical Index Structure,30,2404.01347,https://www.semanticscholar.org/paper/c86c5a8098701fe226c77a5419001b55e2e4dc6e,"Kashob Kumar Roy, Md Hasibul Haque Moon, Md Mahmudur Rahman et al.","In this uncertain world, data uncertainty is inherent in many applications and its importance is growing drastically due to the rapid development of modern technologies. Nowadays, researchers have paid more attention to mine patterns in uncertain databases. A few recent works attempt to mine frequent uncertain sequential patterns. Despite their success, they are incompetent to reduce the number of false-positive pattern generation in their mining process and maintain the patterns efficiently. In this paper, we propose multiple theoretically tightened pruning upper bounds that remarkably reduce the mining space. A novel hierarchical structure is introduced to maintain the patterns in a space-efficient way. Afterward, we develop a versatile framework for mining uncertain sequential patterns that can effectively handle weight constraints as well. Besides, with the advent of incremental uncertain databases, existing works are not scalable. There exist several incremental sequential pattern mining algorithms, but they are limited to mine in precise databases. Therefore, we propose a new technique to adapt our framework to mine patterns when the database is incremental. Finally, we conduct extensive experiments on several real-life datasets and show the efficacy of our framework in different applications."
Databases (cs.DB),2024,8,Position: Relational Deep Learning - Graph Representation Learning on Relational Databases,27,N/A,https://www.semanticscholar.org/paper/1181c36f7b932384defbc97c9b5d792618fda1a5,"Matthias Fey, Weihua Hu, Kexin Huang et al.",No Abstract
Databases (cs.DB),2024,9,Potential for Agricultural Expansion in Degraded Pasture Lands in Brazil Based on Geospatial Databases,27,N/A,https://www.semanticscholar.org/paper/e31a252967cde43b16e7d6279645a5654486b737,"É. L. Bolfe, Daniel de Castro Victoria, Edson Eyji Sano et al.","Important public and private initiatives to map agricultural lands and natural resources have been carried out in Brazil to support land use planning. Some studies indicate that Brazil still has up to 109.7 million hectares of cultivated pastures with some level of degradation, representing around 60% of the total pasturelands, estimated at 177 million hectares. This study aimed to gather, process, and analyze publicly available databases to generate quantitative and spatial information about the potential of Brazilian degraded pastures for agricultural expansion. We considered data related to the natural agricultural potential, restrictions imposed by special areas (indigenous lands and Afro-Brazilian “quilombola” settlements), areas with high biodiversity conservation priorities, infrastructure such as distance between major highways and availability of warehouses, current agricultural areas, and the information made available by Agricultural Climate Risk Zoning. The results indicated the existence of approximately 28 million hectares of planted pastures with intermediate and severe levels of degradation that show high potential for agricultural crops. These areas could increase the planted areas with grains in Brazil by approximately 35% in relation to the total area used in the 2022/23 crop season."
Databases (cs.DB),2024,17,NANO: Cryptographic Enforcement of Readability and Editability Governance in Blockchain Databases,27,N/A,https://www.semanticscholar.org/paper/588a313887d7b65311f7e598f1769ca88fa8ab46,"Chuan Zhang, Mingyang Zhao, Jinwen Liang et al.","Recently, increasing personal data has been stored in blockchain databases, ensuring data integrity by consensus. Although transparent and immutable blockchains are mainly adopted, the need to deploy preferences on which users can read and edit the data is growing in importance. Based on chameleon hashes, recent blockchains support editability governance but can hardly prevent data breaches because the data is readable to all participants in plaintexts. This motivates us to propose NANO, the first permissioned blockchain database that provides downward compatible readability and editability governance (i.e., users who can edit the data can also read the data). Two challenges are protecting policy privacy and efficiently revoking malicious users (e.g., users who abuse their editability privileges). The punchline is leveraging Newton's interpolation formula-based secret sharing to hide policies into polynomial parameters and govern the distribution of data decryption keys and chameleon hash trapdoors. Inspired by proxy re-encryption, NANO integrates unique user symbols into user keys, achieving linear user revocation overhead. Security analysis proves that NANO provides comprehensive privacy preservation under the chosen-ciphertext attack. Experiments on the FISCO blockchain platform demonstrate that compared with state-of-the-art related solutions, NANO achieves a 7× improvement on average regarding computational costs, gas consumption, and communication overhead."
Databases (cs.DB),2024,18,Generative artificial intelligence in higher education learning: A review based on academic databases,26,N/A,https://www.semanticscholar.org/paper/7e0b228695280f5a022c8583fc6eb76931db8dd3,"D. Andrade-Girón, W. Marín-Rodriguez, Juana Sandivar-Rosas et al.","Objective. The rapid integration of Generative Artificial Intelligence (AI), especially tools like ChatGPT, into educational sectors has spurred significant academic interest. This review article provides a systematic examination of the current scholarly landscape concerning the use of ChatGPT within higher education.  Design/Methodology/Approach. Drawing from a range of academic databases between 2022 and 2024, we meticulously adhere to PRISMA guidelines, evaluating a final set of 28 out of 1740 initial articles based on predetermined inclusion and exclusion criteria.  Results/Discussion. Our analysis reveals diverse global contributions predominantly from Asia and identifies a prevalent quantitative research approach among the studies. We delve into the selected articles' geographical distribution, methodologies, and thematic outcomes, highlighting a notable lack of research from Latin America. The review critically assesses the validity, utility, and time optimization aspects of ChatGPT in educational settings, uncovering a positive impact on student learning and time management. However, we pinpoint a significant gap in rigorous experimental research, underscoring the need for studies with random sampling and controlled settings to enhance the external validity of findings. Additionally, we call attention to the ethical considerations and the necessity for higher education institutions to adapt teaching methodologies to incorporate AI effectively.  Conclusion. The article concludes with recommendations for future research to address the identified gaps and optimize the educational use of generative AI technologies like ChatGPT."
Machine Learning (cs.LG),2019,1,A Survey on Bias and Fairness in Machine Learning,5155,1908.09635,https://www.semanticscholar.org/paper/0090023afc66cd2741568599057f4e82b566137c,"Ninareh Mehrabi, Fred Morstatter, N. Saxena et al.","With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields."
Machine Learning (cs.LG),2019,2,Interpretable Machine Learning,2898,N/A,https://www.semanticscholar.org/paper/b0c34618ffd1154f35863e2ce7250ac6b6f2c424,"Bradley C. Boehmke, Brandon M. Greenwell","Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners."
Machine Learning (cs.LG),2019,5,Federated Machine Learning,2653,1902.04885,https://www.semanticscholar.org/paper/62ccd99a65bfc7c735ae1f33b75b107665de95df,"Qiang Yang, Yang Liu, Tianjian Chen et al.","Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy."
Machine Learning (cs.LG),2019,3,ilastik: interactive machine learning for (bio)image analysis,2589,N/A,https://www.semanticscholar.org/paper/5d433da6d0f143f20936379910104d2bb139d4ae,"S. Berg, D. Kutra, Thorben Kroeger et al.",No Abstract
Machine Learning (cs.LG),2019,4,Machine Learning for Fluid Mechanics,2416,1905.11075,https://www.semanticscholar.org/paper/4087e84fc695bb6433d0104ee94f9d7e9f4b7da5,"S. Brunton, B. R. Noack, P. Koumoutsakos","The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications."
Machine Learning (cs.LG),2019,6,Machine Learning With Python,2153,N/A,https://www.semanticscholar.org/paper/eb9e0da8b7170e3ca4364f2f9010599c2d2556f1,Ajit Singh,No Abstract
Machine Learning (cs.LG),2019,7,Applications of machine learning in drug discovery and development,2069,N/A,https://www.semanticscholar.org/paper/b5904cd5dbf73b8d5ff13517de490c292d877ee0,"J. Vamathevan, Dominic Clark, P. Czodrowski et al.",No Abstract
Machine Learning (cs.LG),2019,16,Recent advances and applications of machine learning in solid-state materials science,1871,N/A,https://www.semanticscholar.org/paper/0273507eb05f1135f3a05f9c7adc9a56f12c7c5c,"Jonathan Schmidt, Mário R. G. Marques, S. Botti et al.","One of the most exciting tools that have entered the material science toolbox in recent years is machine learning. This collection of statistical methods has already proved to be capable of considerably speeding up both fundamental and applied research. At present, we are witnessing an explosion of works that develop and apply machine learning to solid-state systems. We provide a comprehensive overview and analysis of the most recent research in this topic. As a starting point, we introduce machine learning principles, algorithms, descriptors, and databases in materials science. We continue with the description of different machine learning approaches for the discovery of stable materials and the prediction of their crystal structure. Then we discuss research in numerous quantitative structure–property relationships and various approaches for the replacement of first-principle methods by machine learning. We review how active learning and surrogate-based optimization can be applied to improve the rational design process and related examples of applications. Two major questions are always the interpretability of and the physical understanding gained from machine learning models. We consider therefore the different facets of interpretability and their importance in materials science. Finally, we propose solutions and future research paths for various challenges in computational materials science."
Machine Learning (cs.LG),2019,14,Machine learning and the physical sciences,1721,1903.10563,https://www.semanticscholar.org/paper/a9cbbef8f4426329d0687025b34287c35bdd8b38,"Giuseppe Carleo, I. Cirac, Kyle Cranmer et al.","Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges."
Machine Learning (cs.LG),2019,8,Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods,1711,1910.09457,https://www.semanticscholar.org/paper/b631ba962b4403a9c0fd9cce446ef3b1e21ea059,"Eyke Hüllermeier, W. Waegeman","The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as aleatoric and epistemic. In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular."
Machine Learning (cs.LG),2019,11,"Definitions, methods, and applications in interpretable machine learning",1599,1901.04592,https://www.semanticscholar.org/paper/b9518627db25f05930e931f56497602363a75491,"W. James Murdoch, Chandan Singh, Karl Kumbier et al.","Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods."
Machine Learning (cs.LG),2019,13,Adversarial machine learning,1509,N/A,https://www.semanticscholar.org/paper/e24b8a9531573d284647239affc6c855505b0de4,"Ling Huang, A. Joseph, B. Nelson et al.","In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning---the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques."
Machine Learning (cs.LG),2019,12,Machine Learning Interpretability: A Survey on Methods and Metrics,1505,N/A,https://www.semanticscholar.org/paper/46c266b3d1274dacd7fce27ee8cb4d587f087a58,"D. V. Carvalho, E. M. Pereira, Jaime S. Cardoso","Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field."
Machine Learning (cs.LG),2019,15,Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization,1477,N/A,https://www.semanticscholar.org/paper/ec6200bdcc23b79a71555962cde50306c4029f1a,"Jia Wu, Xiuyun Chen, H. Zhang et al.",No Abstract
Machine Learning (cs.LG),2019,19,Machine Learning in Medicine,1362,N/A,https://www.semanticscholar.org/paper/21dfbc88b21b27fe8a245ab1df98edd45f655ae7,"A. Rajkomar, Jeffrey Dean, I. Kohane","Machine Learning in Medicine In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. The..."
Machine Learning (cs.LG),2019,17,"Automated Machine Learning - Methods, Systems, Challenges",1352,N/A,https://www.semanticscholar.org/paper/b55e490637babd50dab3cdaaa3a60a2be6eb1cbb,Unknown,No Abstract
Machine Learning (cs.LG),2019,18,Comparing different supervised machine learning algorithms for disease prediction,1234,N/A,https://www.semanticscholar.org/paper/c8ac6060d34179871b81ecd19621c63360347f8e,"S. Uddin, Arif Khan, Md Ekramul Hossain et al.","BackgroundSupervised machine learning algorithms have been a dominant method in the data mining field. Disease prediction using health data has recently shown a potential application area for these methods. This study ai7ms to identify the key trends among different types of supervised machine learning algorithms, and their performance and usage for disease risk prediction.MethodsIn this study, extensive research efforts were made to identify those studies that applied more than one supervised machine learning algorithm on single disease prediction. Two databases (i.e., Scopus and PubMed) were searched for different types of search items. Thus, we selected 48 articles in total for the comparison among variants supervised machine learning algorithms for disease prediction.ResultsWe found that the Support Vector Machine (SVM) algorithm is applied most frequently (in 29 studies) followed by the Naïve Bayes algorithm (in 23 studies). However, the Random Forest (RF) algorithm showed superior accuracy comparatively. Of the 17 studies where it was applied, RF showed the highest accuracy in 9 of them, i.e., 53%. This was followed by SVM which topped in 41% of the studies it was considered.ConclusionThis study provides a wide overview of the relative performance of different variants of supervised machine learning algorithms for disease prediction. This important information of relative performance can be used to aid researchers in the selection of an appropriate supervised machine learning algorithm for their studies."
Machine Learning (cs.LG),2019,9,Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques,1230,N/A,https://www.semanticscholar.org/paper/2bc3644ce4de7fce5812c1455e056649a47c1bbf,"Senthilkumar Mohan, Chandrasegar Thirumalai, Gautam Srivastava","Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM)."
Machine Learning (cs.LG),2019,20,Machine learning algorithm validation with a limited sample size,1203,N/A,https://www.semanticscholar.org/paper/fbf9812f29156024ec693b4633a21303eead309d,"A. Vabalas, E. Gowen, E. Poliakoff et al.","Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used."
Machine Learning (cs.LG),2019,10,Explaining machine learning classifiers through diverse counterfactual explanations,1172,1905.07697,https://www.semanticscholar.org/paper/c2413fa296543159b32d16350d9e29f7db528790,"Ramaravind Kommiya Mothilal, Amit Sharma, Chenhao Tan","Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE."
Machine Learning (cs.LG),2022,1,Machine Learning Algorithms: A Review,1897,N/A,https://www.semanticscholar.org/paper/56e8863838b4dcc4790108cd1e7e680a104a7c30,Ayon Dey,.
Machine Learning (cs.LG),2022,2,Scientific Machine Learning Through Physics–Informed Neural Networks: Where we are and What’s Next,1776,2201.05624,https://www.semanticscholar.org/paper/e916f69e70a4321f21356f7ce360e380dd976a43,"S. Cuomo, Vincenzo Schiano Di Cola, F. Giampaolo et al.","Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved."
Machine Learning (cs.LG),2022,3,"CARD 2023: expanded curation, support for machine learning, and resistome prediction at the Comprehensive Antibiotic Resistance Database",1241,N/A,https://www.semanticscholar.org/paper/bae4f1a8fdc5f3aefe69db3c0e7c57018e35cede,"Brian P. Alcock, William Huynh, Romeo Chalil et al.","Abstract The Comprehensive Antibiotic Resistance Database (CARD; card.mcmaster.ca) combines the Antibiotic Resistance Ontology (ARO) with curated AMR gene (ARG) sequences and resistance-conferring mutations to provide an informatics framework for annotation and interpretation of resistomes. As of version 3.2.4, CARD encompasses 6627 ontology terms, 5010 reference sequences, 1933 mutations, 3004 publications, and 5057 AMR detection models that can be used by the accompanying Resistance Gene Identifier (RGI) software to annotate genomic or metagenomic sequences. Focused curation enhancements since 2020 include expanded β-lactamase curation, incorporation of likelihood-based AMR mutations for Mycobacterium tuberculosis, addition of disinfectants and antiseptics plus their associated ARGs, and systematic curation of resistance-modifying agents. This expanded curation includes 180 new AMR gene families, 15 new drug classes, 1 new resistance mechanism, and two new ontological relationships: evolutionary_variant_of and is_small_molecule_inhibitor. In silico prediction of resistomes and prevalence statistics of ARGs has been expanded to 377 pathogens, 21,079 chromosomes, 2,662 genomic islands, 41,828 plasmids and 155,606 whole-genome shotgun assemblies, resulting in collation of 322,710 unique ARG allele sequences. New features include the CARD:Live collection of community submitted isolate resistome data and the introduction of standardized 15 character CARD Short Names for ARGs to support machine learning efforts."
Machine Learning (cs.LG),2022,8,Machine learning-aided engineering of hydrolases for PET depolymerization,768,N/A,https://www.semanticscholar.org/paper/8fedd23c1604dfeed02b75f8d38c1d7e33beee3a,"Hongyuan Lu, Daniel J. Diaz, Natalie J. Czarnecki et al.",No Abstract
Machine Learning (cs.LG),2022,9,"Federated Learning: Collaborative Machine Learning without
Centralized Training Data",746,N/A,https://www.semanticscholar.org/paper/6a6ad9eb495739f4c80e7c09598720c3d5c5dff7,"Abhishek V A, Binny S, Johan T R et al.","Federated learning (also known as collaborative learning) is a machine learning technique that trains an algorithm without transferring data samples across numerous decentralized edge devices or servers. This strategy differs from standard centralized machine learning techniques in which all local datasets are uploaded to a single server, as well as more traditional decentralized alternatives, which frequently presume that local data samples are uniformly distributed. Federated learning allows several actors to collaborate on the development of a single, robust machine learning model without sharing data, allowing crucial issues such as data privacy, data security, data access rights, and access to heterogeneous data to be addressed. Defence, telecommunications, internet of things, and pharmaceutical industries are just a few of the sectors where it has applications."
Machine Learning (cs.LG),2022,4,"CheckM2: a rapid, scalable and accurate tool for assessing microbial genome quality using machine learning",713,N/A,https://www.semanticscholar.org/paper/78cfbe4203ede2d1f3437fbd91266823ac18cf07,"Alex Chklovski, Donovan H. Parks, B. Woodcroft et al.",No Abstract
Machine Learning (cs.LG),2022,13,Challenges and opportunities in quantum machine learning,594,2303.09491,https://www.semanticscholar.org/paper/ab06951251e0abfdb866694f9a23a79c72784317,"M. Cerezo, Guillaume Verdon, Hsin-Yuan Huang et al.","At the intersection of machine learning and quantum computing, quantum machine learning has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry and high-energy physics. Nevertheless, challenges remain regarding the trainability of quantum machine learning models. Here we review current methods and applications for quantum machine learning. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with quantum machine learning. Quantum machine learning has become an essential tool to process and analyze the increased amount of quantum data. Despite recent progress, there are still many challenges to be addressed and myriad future avenues of research."
Machine Learning (cs.LG),2022,10,A Review on Fairness in Machine Learning,583,N/A,https://www.semanticscholar.org/paper/f64670a5f54fcce339a916497a001cbf02a9a04f,"Dana Pessach, E. Shmueli","An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop ML algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision making may be inherently prone to unfairness, even when there is no intention for it. This article presents an overview of the main concepts of identifying, measuring, and improving algorithmic fairness when using ML algorithms, focusing primarily on classification tasks. The article begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process, and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, toward a better understanding of which mechanisms should be used in different scenarios. The article ends by reviewing several emerging research sub-fields of algorithmic fairness, beyond classification."
Machine Learning (cs.LG),2022,18,Human-in-the-loop machine learning: a state of the art,582,N/A,https://www.semanticscholar.org/paper/62cadbc4fcc73204a72847300cb2214f4401efad,"E. Mosqueira-Rey, Elena Hernández-Pereira, David Alonso-Ríos et al.","Researchers are defining new types of interactions between humans and machine learning algorithms generically called human-in-the-loop machine learning. Depending on who is in control of the learning process, we can identify: active learning, in which the system remains in control; interactive machine learning, in which there is a closer interaction between users and learning systems; and machine teaching, where human domain experts have control over the learning process. Aside from control, humans can also be involved in the learning process in other ways. In curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning; in explainable AI the focus is on the ability of the model to explain to humans why a given solution was chosen. This collaboration between AI models and humans should not be limited only to the learning process; if we go further, we can see other terms that arise such as Usable and Useful AI. In this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ML algorithms. Our contribution is not merely listing the different approaches, but to provide definitions clarifying confusing, varied and sometimes contradictory terms; to elucidate and determine the boundaries between the different methods; and to correlate all the techniques searching for the connections and influences between them."
Machine Learning (cs.LG),2022,15,A Review of Feature Selection Methods for Machine Learning-Based Disease Risk Prediction,559,N/A,https://www.semanticscholar.org/paper/911fbaec109f72130815e05e2633ec879590382c,"N. Pudjihartono, T. Fadason, Andreas W. Kempa-Liehr et al.","Machine learning has shown utility in detecting patterns within large, unstructured, and complex datasets. One of the promising applications of machine learning is in precision medicine, where disease risk is predicted using patient genetic data. However, creating an accurate prediction model based on genotype data remains challenging due to the so-called “curse of dimensionality” (i.e., extensively larger number of features compared to the number of samples). Therefore, the generalizability of machine learning models benefits from feature selection, which aims to extract only the most “informative” features and remove noisy “non-informative,” irrelevant and redundant features. In this article, we provide a general overview of the different feature selection methods, their advantages, disadvantages, and use cases, focusing on the detection of relevant features (i.e., SNPs) for disease risk prediction."
Machine Learning (cs.LG),2022,16,Machine learning-based integration develops an immune-derived lncRNA signature for improving outcomes in colorectal cancer,556,N/A,https://www.semanticscholar.org/paper/84e7b5a6477033e8ca58e8f015c7027556e664f6,"Zaoqu Liu, Long Liu, Siyuan Weng et al.","Long noncoding RNAs (lncRNAs) are recently implicated in modifying immunology in colorectal cancer (CRC). Nevertheless, the clinical significance of immune-related lncRNAs remains largely unexplored. In this study, we develope a machine learning-based integrative procedure for constructing a consensus immune-related lncRNA signature (IRLS). IRLS is an independent risk factor for overall survival and displays stable and powerful performance, but only demonstrates limited predictive value for relapse-free survival. Additionally, IRLS possesses distinctly superior accuracy than traditional clinical variables, molecular features, and 109 published signatures. Besides, the high-risk group is sensitive to fluorouracil-based adjuvant chemotherapy, while the low-risk group benefits more from bevacizumab. Notably, the low-risk group displays abundant lymphocyte infiltration, high expression of CD8A and PD-L1, and a response to pembrolizumab. Taken together, IRLS could serve as a robust and promising tool to improve clinical outcomes for individual CRC patients. Identification of long non-coding RNA (lncRNA) signatures could be used to improve cancer clinical outcome. Here the authors developed a machine learning-based integrative procedure to construct a consensus immune-related lncRNA signature to predict prognosis, recurrence and treatment benefits in colorectal cancer."
Machine Learning (cs.LG),2022,14,Educational data mining: prediction of students' academic performance using machine learning algorithms,483,N/A,https://www.semanticscholar.org/paper/0ad4189bdddfa32ecf7b1c9122eba57c8d8bbc7f,M. Yağcı,"Educational data mining has become an effective tool for exploring the hidden relationships in educational data and predicting students' academic achievements. This study proposes a new model based on machine learning algorithms to predict the final exam grades of undergraduate students, taking their midterm exam grades as the source data. The performances of the random forests, nearest neighbour, support vector machines, logistic regression, Naïve Bayes, and k-nearest neighbour algorithms, which are among the machine learning algorithms, were calculated and compared to predict the final exam grades of the students. The dataset consisted of the academic achievement grades of 1854 students who took the Turkish Language-I course in a state University in Turkey during the fall semester of 2019–2020. The results show that the proposed model achieved a classification accuracy of 70–75%. The predictions were made using only three types of parameters; midterm exam grades, Department data and Faculty data. Such data-driven studies are very important in terms of establishing a learning analysis framework in higher education and contributing to the decision-making processes. Finally, this study presents a contribution to the early prediction of students at high risk of failure and determines the most effective machine learning methods."
Machine Learning (cs.LG),2022,6,"Machine Learning Operations (MLOps): Overview, Definition, and Architecture",466,2205.02302,https://www.semanticscholar.org/paper/aba92bb029e81cb6c4c1b90a5adec57c738ea9bd,"Dominik Kreuzberger, Niklas Kühl, Sebastian Hirschl","The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies."
Machine Learning (cs.LG),2022,17,Mitigating the Multicollinearity Problem and Its Machine Learning Approach: A Review,410,N/A,https://www.semanticscholar.org/paper/4b9077c1c062b18ccdc91d595b2a617792195405,"Jireh Yi-Le Chan, Steven Mun Hong Leow, Khean Thye Bea et al.","Technologies have driven big data collection across many fields, such as genomics and business intelligence. This results in a significant increase in variables and data points (observations) collected and stored. Although this presents opportunities to better model the relationship between predictors and the response variables, this also causes serious problems during data analysis, one of which is the multicollinearity problem. The two main approaches used to mitigate multicollinearity are variable selection methods and modified estimator methods. However, variable selection methods may negate efforts to collect more data as new data may eventually be dropped from modeling, while recent studies suggest that optimization approaches via machine learning handle data with multicollinearity better than statistical estimators. Therefore, this study details the chronological developments to mitigate the effects of multicollinearity and up-to-date recommendations to better mitigate multicollinearity."
Machine Learning (cs.LG),2022,19,Multimodal machine learning in precision health: A scoping review,352,N/A,https://www.semanticscholar.org/paper/ab8fa3a8de5440c3a6d1043c83028314197c7803,"Adrienne S. Kline, Hanyin Wang, Yikuan Li et al.","Machine learning is frequently being leveraged to tackle problems in the health sector including utilization for clinical decision-support. Its use has historically been focused on single modal data. Attempts to improve prediction and mimic the multimodal nature of clinical expert decision-making has been met in the biomedical field of machine learning by fusing disparate data. This review was conducted to summarize the current studies in this field and identify topics ripe for future research. We conducted this review in accordance with the PRISMA extension for Scoping Reviews to characterize multi-modal data fusion in health. Search strings were established and used in databases: PubMed, Google Scholar, and IEEEXplore from 2011 to 2021. A final set of 128 articles were included in the analysis. The most common health areas utilizing multi-modal methods were neurology and oncology. Early fusion was the most common data merging strategy. Notably, there was an improvement in predictive performance when using data fusion. Lacking from the papers were clear clinical deployment strategies, FDA-approval, and analysis of how using multimodal approaches from diverse sub-populations may improve biases and healthcare disparities. These findings provide a summary on multimodal data fusion as applied to health diagnosis/prognosis problems. Few papers compared the outputs of a multimodal approach with a unimodal prediction. However, those that did achieved an average increase of 6.4% in predictive accuracy. Multi-modal machine learning, while more robust in its estimations over unimodal methods, has drawbacks in its scalability and the time-consuming nature of information concatenation."
Machine Learning (cs.LG),2022,20,Compute Trends Across Three Eras of Machine Learning,351,2202.05924,https://www.semanticscholar.org/paper/927a5203363fc9c8ba48599dc749cf0cc647444b,"J. Sevilla, Lennart Heim, A. Ho et al.","Compute, data, and algorithmic advances are the three fundamental factors that drive progress in modern Machine Learning (ML). In this paper we study trends in the most readily quantified factor - compute. We make three novel contributions: (1) we curate a dataset with the training compute of 123 milestone ML systems, 3× larger than previous such datasets. (2) We frame the trends in compute in in three eras - the Pre Deep Learning Era, the Deep Learning Era, and the Large-Scale Era, based on our identification of a novel trend emerging around 2015. (3) We find a Deep Learning Era compute doubling time of around 6 months, significantly longer than previous findings. Overall, our work highlights the fast-growing compute requirements for training advanced ML systems."
Machine Learning (cs.LG),2022,7,"The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink",334,2204.05149,https://www.semanticscholar.org/paper/76cb108e37d9d2a06f5a49df04e993f5fb123c26,"David A. Patterson, Joseph Gonzalez, Urs Holzle et al.","Machine learning (ML) workloads have rapidly grown, raising concerns about their carbon footprint. We show four best practices to reduce ML training energy and carbon dioxide emissions. If the whole ML field adopts best practices, we predict that by 2030, total carbon emissions from training will decline."
Machine Learning (cs.LG),2022,5,PDEBENCH: An Extensive Benchmark for Scientific Machine Learning,322,2210.07182,https://www.semanticscholar.org/paper/b05f97e84e0867b63f6271cf5d42eacaa0d9e68e,"M. Takamoto, T. Praditia, Raphael Leiteritz et al.","Machine learning-based modeling of physical systems has experienced increased interest in recent years. Despite some impressive progress, there is still a lack of benchmarks for Scientific ML that are easy to use but still challenging and representative of a wide range of problems. We introduce PDEBench, a benchmark suite of time-dependent simulation tasks based on Partial Differential Equations (PDEs). PDEBench comprises both code and data to benchmark the performance of novel machine learning models against both classical numerical simulations and machine learning baselines. Our proposed set of benchmark problems contribute the following unique features: (1) A much wider range of PDEs compared to existing benchmarks, ranging from relatively common examples to more realistic and difficult problems; (2) much larger ready-to-use datasets compared to prior work, comprising multiple simulation runs across a larger number of initial and boundary conditions and PDE parameters; (3) more extensible source codes with user-friendly APIs for data generation and baseline results with popular machine learning models (FNO, U-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers to extend the benchmark freely for their own purposes using a standardized API and to compare the performance of new models to existing baseline methods. We also propose new evaluation metrics with the aim to provide a more holistic understanding of learning methods in the context of Scientific ML. With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community. The code is available at https://github.com/pdebench/PDEBench."
Machine Learning (cs.LG),2022,11,The Disagreement Problem in Explainable Machine Learning: A Practitioner's Perspective,238,2202.01602,https://www.semanticscholar.org/paper/e0f12956ccfc1ed005b54cb876d9173c4a18dc75,"Satyapriya Krishna, Tessa Han, Alex Gu et al.","As various post hoc explanation methods are increasingly being leveraged to explain complex models in high-stakes settings, it becomes critical to develop a deeper understanding of whether and when the explanations output by these methods disagree with each other, and how such disagreements are resolved in practice. However, there is little to no research that provides answers to these critical questions. In this work, we formalize and study the disagreement problem in explainable machine learning. More specifically, we define the notion of disagreement between explanations, analyze how often such disagreements occur in practice, and how practitioners resolve these disagreements. We first conduct interviews with data scientists to understand what constitutes disagreement between explanations generated by different methods for the same model prediction, and introduce a novel quantitative framework to formalize this understanding. We then leverage this framework to carry out a rigorous empirical analysis with four real-world datasets, six state-of-the-art post hoc explanation methods, and six different predictive models, to measure the extent of disagreement between the explanations generated by various popular explanation methods. In addition, we carry out an online user study with data scientists to understand how they resolve the aforementioned disagreements. Our results indicate that (1) state-of-the-art explanation methods often disagree in terms of the explanations they output, and (2) machine learning practitioners often employ ad hoc heuristics when resolving such disagreements. These findings suggest that practitioners may be relying on misleading explanations when making consequential decisions. They also underscore the importance of developing principled frameworks for effectively evaluating and comparing explanations output by various explanation techniques."
Machine Learning (cs.LG),2022,12,The Vendi Score: A Diversity Evaluation Metric for Machine Learning,190,2210.02410,https://www.semanticscholar.org/paper/b03c078303326ff022f525fccdf028b73ccb1cb4,"Dan Friedman, A. B. Dieng","Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper, we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ML. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labeled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation."
NLP (cs.CL),2020,1,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing,2111,2007.15779,https://www.semanticscholar.org/paper/a2f38d03fd363e920494ad65a5f0ad8bd18cd60b,"Yu Gu, Robert Tinn, Hao Cheng et al.","Pretraining large neural language models, such as BERT, has led to impressive gains on many natural language processing (NLP) tasks. However, most pretraining efforts focus on general domain corpora, such as newswire and Web. A prevailing assumption is that even domain-specific pretraining can benefit by starting from general-domain language models. In this article, we challenge this assumption by showing that for domains with abundant unlabeled text, such as biomedicine, pretraining language models from scratch results in substantial gains over continual pretraining of general-domain language models. To facilitate this investigation, we compile a comprehensive biomedical NLP benchmark from publicly available datasets. Our experiments show that domain-specific pretraining serves as a solid foundation for a wide range of biomedical NLP tasks, leading to new state-of-the-art results across the board. Further, in conducting a thorough evaluation of modeling choices, both for pretraining and task-specific fine-tuning, we discover that some common practices are unnecessary with BERT models, such as using complex tagging schemes in named entity recognition. To help accelerate research in biomedical NLP, we have released our state-of-the-art pretrained and task-specific models for the community, and created a leaderboard featuring our BLURB benchmark (short for Biomedical Language Understanding & Reasoning Benchmark) at https://aka.ms/BLURB."
NLP (cs.CL),2020,2,Stanza: A Python Natural Language Processing Toolkit for Many Human Languages,1875,2003.07082,https://www.semanticscholar.org/paper/641a9749fe546a02bbab9a86bfc91492db1c3bc5,"Peng Qi, Yuhao Zhang, Yuhui Zhang et al.","We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza/."
NLP (cs.CL),2020,3,Pre-trained models for natural language processing: A survey,1603,2003.08271,https://www.semanticscholar.org/paper/3bcb17559ce96eb20fa79af8194f4af0380d194a,"Xipeng Qiu, Tianxiang Sun, Yige Xu et al.","Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy from four different perspectives. Next, we describe how to adapt the knowledge of PTMs to downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks."
NLP (cs.CL),2020,4,A Survey of the Usages of Deep Learning for Natural Language Processing,1510,N/A,https://www.semanticscholar.org/paper/7b9b756ab509cb9f52dbac95e3e901d571f0784f,"Dan Otter, Julian R. Medina, J. Kalita","Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This article provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to many applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field."
NLP (cs.CL),2020,5,Revisiting Pre-Trained Models for Chinese Natural Language Processing,780,2004.13922,https://www.semanticscholar.org/paper/d16ab5c19ed33a263b6412ac41a4ea1f068d254a,"Yiming Cui, Wanxiang Che, Ting Liu et al.","Bidirectional Encoder Representations from Transformers (BERT) has shown marvelous improvements across various NLP tasks, and consecutive variants have been proposed to further improve the performance of the pre-trained language models. In this paper, we target on revisiting Chinese pre-trained language models to examine their effectiveness in a non-English language and release the Chinese pre-trained language model series to the community. We also propose a simple but effective model called MacBERT, which improves upon RoBERTa in several ways, especially the masking strategy that adopts MLM as correction (Mac). We carried out extensive experiments on eight Chinese NLP tasks to revisit the existing pre-trained language models as well as the proposed MacBERT. Experimental results show that MacBERT could achieve state-of-the-art performances on many NLP tasks, and we also ablate details with several findings that may help future research. https://github.com/ymcui/MacBERT"
NLP (cs.CL),2020,8,A Survey of the State of Explainable AI for Natural Language Processing,426,2010.00711,https://www.semanticscholar.org/paper/829e36b23f7b42e109f84b5b761052498b291962,"Marina Danilevsky, Kun Qian, R. Aharonov et al.","Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area."
NLP (cs.CL),2020,6,COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter,391,2005.07503,https://www.semanticscholar.org/paper/126fb7df6bcab2b70000dfe5b940ada63ae1ba6a,"Martin Müller, M. Salathé, P. Kummervold","Introduction This study presents COVID-Twitter-BERT (CT-BERT), a transformer-based model that is pre-trained on a large corpus of COVID-19 related Twitter messages. CT-BERT is specifically designed to be used on COVID-19 content, particularly from social media, and can be utilized for various natural language processing tasks such as classification, question-answering, and chatbots. This paper aims to evaluate the performance of CT-BERT on different classification datasets and compare it with BERT-LARGE, its base model. Methods The study utilizes CT-BERT, which is pre-trained on a large corpus of COVID-19 related Twitter messages. The authors evaluated the performance of CT-BERT on five different classification datasets, including one in the target domain. The model's performance is compared to its base model, BERT-LARGE, to measure the marginal improvement. The authors also provide detailed information on the training process and the technical specifications of the model. Results The results indicate that CT-BERT outperforms BERT-LARGE with a marginal improvement of 10-30% on all five classification datasets. The largest improvements are observed in the target domain. The authors provide detailed performance metrics and discuss the significance of these results. Discussion The study demonstrates the potential of pre-trained transformer models, such as CT-BERT, for COVID-19 related natural language processing tasks. The results indicate that CT-BERT can improve the classification performance on COVID-19 related content, especially on social media. These findings have important implications for various applications, such as monitoring public sentiment and developing chatbots to provide COVID-19 related information. The study also highlights the importance of using domain-specific pre-trained models for specific natural language processing tasks. Overall, this work provides a valuable contribution to the development of COVID-19 related NLP models."
NLP (cs.CL),2020,10,Natural language processing (NLP) in management research: A literature review,390,N/A,https://www.semanticscholar.org/paper/db528269ef800727245c0fcb35b692d29c1ccdc9,"Yue Kang, Zhao Cai, Chee‐Wee Tan et al.","Natural language processing (NLP) is gaining momentum in management research for its ability to automatically analyze and comprehend human language. Yet, despite its extensive application in manage..."
NLP (cs.CL),2020,9,A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios,341,2010.12309,https://www.semanticscholar.org/paper/455cdafd55a5b5ddefa029bf97801327e142646d,"Michael A. Hedderich, Lukas Lange, Heike Adel et al.","Deep neural networks and huge language models are becoming omnipresent in natural language applications. As they are known for requiring large amounts of training data, there is a growing body of work to improve the performance in low-resource settings. Motivated by the recent fundamental changes towards neural models and the popular pre-train and fine-tune paradigm, we survey promising approaches for low-resource natural language processing. After a discussion about the different dimensions of data availability, we give a structured overview of methods that enable learning when training data is sparse. This includes mechanisms to create additional labeled data like data augmentation and distant supervision as well as transfer learning settings that reduce the need for target supervision. A goal of our survey is to explain how these methods differ in their requirements as understanding them is essential for choosing a technique suited for a specific low-resource setting. Further key aspects of this work are to highlight open issues and to outline promising directions for future research."
NLP (cs.CL),2020,11,Natural Language Processing Reveals Vulnerable Mental Health Support Groups and Heightened Health Anxiety on Reddit During COVID-19: Observational Study,276,N/A,https://www.semanticscholar.org/paper/d619e3534b12a12269483336273a47b5b5a538df,"D. Low, Laurie Rumker, Tanya Talkar et al.","Background The COVID-19 pandemic is impacting mental health, but it is not clear how people with different types of mental health problems were differentially impacted as the initial wave of cases hit. Objective The aim of this study is to leverage natural language processing (NLP) with the goal of characterizing changes in 15 of the world’s largest mental health support groups (eg, r/schizophrenia, r/SuicideWatch, r/Depression) found on the website Reddit, along with 11 non–mental health groups (eg, r/PersonalFinance, r/conspiracy) during the initial stage of the pandemic. Methods We created and released the Reddit Mental Health Dataset including posts from 826,961 unique users from 2018 to 2020. Using regression, we analyzed trends from 90 text-derived features such as sentiment analysis, personal pronouns, and semantic categories. Using supervised machine learning, we classified posts into their respective support groups and interpreted important features to understand how different problems manifest in language. We applied unsupervised methods such as topic modeling and unsupervised clustering to uncover concerns throughout Reddit before and during the pandemic. Results We found that the r/HealthAnxiety forum showed spikes in posts about COVID-19 early on in January, approximately 2 months before other support groups started posting about the pandemic. There were many features that significantly increased during COVID-19 for specific groups including the categories “economic stress,” “isolation,” and “home,” while others such as “motion” significantly decreased. We found that support groups related to attention-deficit/hyperactivity disorder, eating disorders, and anxiety showed the most negative semantic change during the pandemic out of all mental health groups. Health anxiety emerged as a general theme across Reddit through independent supervised and unsupervised machine learning analyses. For instance, we provide evidence that the concerns of a diverse set of individuals are converging in this unique moment of history; we discovered that the more users posted about COVID-19, the more linguistically similar (less distant) the mental health support groups became to r/HealthAnxiety (ρ=–0.96, P<.001). Using unsupervised clustering, we found the suicidality and loneliness clusters more than doubled in the number of posts during the pandemic. Specifically, the support groups for borderline personality disorder and posttraumatic stress disorder became significantly associated with the suicidality cluster. Furthermore, clusters surrounding self-harm and entertainment emerged. Conclusions By using a broad set of NLP techniques and analyzing a baseline of prepandemic posts, we uncovered patterns of how specific mental health problems manifest in language, identified at-risk users, and revealed the distribution of concerns across Reddit, which could help provide better resources to its millions of users. We then demonstrated that textual analysis is sensitive to uncover mental health complaints as they appear in real time, identifying vulnerable groups and alarming themes during COVID-19, and thus may have utility during the ongoing pandemic and other world-changing events such as elections and protests."
NLP (cs.CL),2020,7,HAT: Hardware-Aware Transformers for Efficient Natural Language Processing,275,2005.14187,https://www.semanticscholar.org/paper/ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7,"Hanrui Wang, Zhanghao Wu, Zhijian Liu et al.","Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but they are difficult to be deployed on hardware due to the intensive computation. To enable low-latency inference on resource-constrained hardware platforms, we propose to design Hardware-Aware Transformers (HAT) with neural architecture search. We first construct a large design space with arbitrary encoder-decoder attention and heterogeneous layers. Then we train a SuperTransformer that covers all candidates in the design space, and efficiently produces many SubTransformers with weight sharing. Finally, we perform an evolutionary search with a hardware latency constraint to find a specialized SubTransformer dedicated to run fast on the target hardware. Extensive experiments on four machine translation tasks demonstrate that HAT can discover efficient models for different hardware (CPU, GPU, IoT device). When running WMT’14 translation task on Raspberry Pi-4, HAT can achieve 3× speedup, 3.7× smaller size over baseline Transformer; 2.7× speedup, 3.6× smaller size over Evolved Transformer with 12,041× less search cost and no performance loss. HAT is open-sourced at https://github.com/mit-han-lab/hardware-aware-transformers."
NLP (cs.CL),2020,13,Adversarial Attacks on Deep-learning Models in Natural Language Processing,263,N/A,https://www.semanticscholar.org/paper/88338c58701f34503c7af77e34f19d9a5cd66313,"W. Zhang, Quan Z. Sheng, A. Alhazmi et al.","With the development of high computational devices, deep neural networks (DNNs), in recent years, have gained significant popularity in many Artificial Intelligence (AI) applications. However, previous efforts have shown that DNNs are vulnerable to strategically modified samples, named adversarial examples. These samples are generated with some imperceptible perturbations, but can fool the DNNs to give false predictions. Inspired by the popularity of generating adversarial examples against DNNs in Computer Vision (CV), research efforts on attacking DNNs for Natural Language Processing (NLP) applications have emerged in recent years. However, the intrinsic difference between image (CV) and text (NLP) renders challenges to directly apply attacking methods in CV to NLP. Various methods are proposed addressing this difference and attack a wide range of NLP applications. In this article, we present a systematic survey on these works. We collect all related academic works since the first appearance in 2017. We then select, summarize, discuss, and analyze 40 representative works in a comprehensive way. To make the article self-contained, we cover preliminary knowledge of NLP and discuss related seminal works in computer vision. We conclude our survey with a discussion on open issues to bridge the gap between the existing progress and more robust adversarial attacks on NLP DNNs."
NLP (cs.CL),2020,14,Data-driven materials research enabled by natural language processing and information extraction,258,N/A,https://www.semanticscholar.org/paper/0578dfb2a28b77abde19b32de777e0365df3020e,"E. Olivetti, J. Cole, Edward Kim et al.","Given the emergence of data science and machine learning throughout all aspects of society, but particularly in the scientific domain, there is increased importance placed on obtaining data. Data in materials science are particularly heterogeneous, based on the significant range in materials classes that are explored and the variety of materials properties that are of interest. This leads to data that range many orders of magnitude, and these data may manifest as numerical text or image-based information, which requires quantitative interpretation. The ability to automatically consume and codify the scientific literature across domains—enabled by techniques adapted from the field of natural language processing—therefore has immense potential to unlock and generate the rich datasets necessary for data science and machine learning. This review focuses on the progress and practices of natural language processing and text mining of materials science literature and highlights opportunities for extracting additional information beyond text contained in figures and tables in articles. We discuss and provide examples for several reasons for the pursuit of natural language processing for materials, including data compilation, hypothesis development, and understanding the trends within and across fields. Current and emerging natural language processing methods along with their applications to materials science are detailed. We, then, discuss natural language processing and data challenges within the materials science domain where future directions may prove valuable."
NLP (cs.CL),2020,16,Natural Language Processing Advancements By Deep Learning: A Survey,247,2003.01200,https://www.semanticscholar.org/paper/77b91d7607518994d04f75119db4138b23e2eb87,"A. Torfi, Rouzbeh A. Shirvani, Yaser Keneshloo et al.","Natural Language Processing (NLP) helps empower intelligent machines by enhancing a better understanding of the human language for linguistic-based human-computer communication. Recent developments in computational power and the advent of large amounts of linguistic data have heightened the need and demand for automating semantic analysis using data-driven approaches. The utilization of data-driven strategies is pervasive now due to the significant improvements demonstrated through the usage of deep learning methods in areas such as Computer Vision, Automatic Speech Recognition, and in particular, NLP. This survey categorizes and addresses the different aspects and applications of NLP that have benefited from deep learning. It covers core NLP tasks and applications and describes how deep learning methods and models advance these areas. We further analyze and compare different approaches and state-of-the-art models."
NLP (cs.CL),2020,12,CAMeL Tools: An Open Source Python Toolkit for Arabic Natural Language Processing,223,N/A,https://www.semanticscholar.org/paper/995ec006ac98a697ea38bd4eea8c1f3170a8adb4,"Ossama Obeid, Nasser Zalmout, Salam Khalifa et al.",No Abstract
NLP (cs.CL),2020,15,Natural Language Processing for Requirements Engineering: A Systematic Mapping Study,177,N/A,https://www.semanticscholar.org/paper/543abfa0999008690c095810ceba065ee074e810,"Liping Zhao, Waad Alhoshan, †. AlessioFerrari et al.",No Abstract
NLP (cs.CL),2020,18,NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language Processing,125,2006.07116,https://www.semanticscholar.org/paper/48167fbde4ef8d5caa69e1c0c9d6e2ac7fd48c3b,"Nikita Klyuchnikov, I. Trofimov, E. Artemova et al.","Neural Architecture Search (NAS) is a promising and rapidly evolving research area. Training a large number of neural networks requires an exceptional amount of computational power, which makes NAS unreachable for those researchers who have limited or no access to high-performance clusters and supercomputers. A few benchmarks with precomputed neural architectures performances have been recently introduced to overcome this problem and ensure reproducible experiments. However, these benchmarks are only for the computer vision domain and, thus, are built from the image datasets and convolution-derived architectures. In this work, we step outside the computer vision domain by leveraging the language modeling task, which is the core of natural language processing (NLP). Our main contribution is as follows: we have provided search space of recurrent neural networks on the text datasets and trained 14k architectures within it; we have conducted both intrinsic and extrinsic evaluation of the trained models using datasets for semantic relatedness and language understanding evaluation; finally, we have tested several NAS algorithms to demonstrate how the precomputed results can be utilized. We consider that the benchmark will provide more reliable empirical findings in the community and stimulate progress in developing new NAS methods well suited for recurrent architectures."
NLP (cs.CL),2020,19,EVALITA 2020: Overview of the 7th Evaluation Campaign of Natural Language Processing and Speech Tools for Italian,98,N/A,https://www.semanticscholar.org/paper/57fa70fc300b702b9eea24a86556782a9e1f3bad,"Valerio Basile, D. Croce, Maria Di Maro et al.","The Evaluation Campaign of Natural Language Processing and Speech Tools for Italian (EVALITA) is the biennial initiative aimed at promoting the development of language and speech technologies for the Italian language. EVALITA is promoted by the Italian Association of Computational Linguistics (AILC)1 and it is endorsed by the Italian Association for Artificial Intelligence (AIxIA)2 and the Italian Association for Speech Sciences (AISV)3. EVALITA provides a shared framework where different systems and approaches can be scientifically evaluated and compared with each other with respect to a large variety of tasks, suggested and organized by the Italian research community. The proposed tasks represent scientific challenges where methods, resources, and systems can be tested against shared benchmarks representing linguistic open issues or real world applications, possibly in a multilingual and/or multi-modal perspective. The collected data sets provide big opportunities for scientists to explore old and new problems concerning NLP in Italian as well as to develop solutions and to discuss the NLP-related issues within the community. Some tasks are traditionally present in the evaluation campaign, while others are completely new. This paper introduces the tasks proposed at EVALITA 2020 and provides an overview to the participants and systems whose descriptions and obtained results are reported in these Proceedings4. The EVALITA 2020 edition, held online on December 17th due to the COVID-19 pandemic, counts 14 different tasks. In particular, the selected tasks are grouped in five research areas (tracks) according to their objective and characteristics, namely (i) Affect, Hate, and Stance, (ii) Creativity and Style, (iii) New Challenges in Long-standing Tasks, (iv) Semantics and Multimodality, (v) Time and Diachrony. This edition was highly participated, with 51 groups whose participants have affiliation in 14 countries. Although EVALITA is generally promoted and targeted to the Italian research community, this edition saw an international participation, also thanks to the fact that several Italian researchers working in different countries contributed to the organization of the tasks or participated in them as authors. This overview is organized as follows: in Section 2 a brief description of the tasks belonging to the various areas is reported. Section 3 discusses the participation to the workshop referred to several aspects, from the research area, to the affiliation of authors. Section 4 describes the criteria used to assign the best system across tasks award, made by an ad-hoc committee starting from the suggestions of task organizers and reviewers. Finally, section 5 points out on both the obtained results and on the future of the workshop."
NLP (cs.CL),2020,20,"Content Analysis of Textbooks via Natural Language Processing: Findings on Gender, Race, and Ethnicity in Texas U.S. History Textbooks",94,N/A,https://www.semanticscholar.org/paper/ad113aa8aedb6a352720a54bcd3018ef2364b69c,"Li Lucy, Dorottya Demszky, Patricia Bromley et al.","Cutting-edge data science techniques can shed new light on fundamental questions in educational research. We apply techniques from natural language processing (lexicons, word embeddings, topic models) to 15 U.S. history textbooks widely used in Texas between 2015 and 2017, studying their depiction of historically marginalized groups. We find that Latinx people are rarely discussed, and the most common famous figures are nearly all White men. Lexicon-based approaches show that Black people are described as performing actions associated with low agency and power. Word embeddings reveal that women tend to be discussed in the contexts of work and the home. Topic modeling highlights the higher prominence of political topics compared with social ones. We also find that more conservative counties tend to purchase textbooks with less representation of women and Black people. Building on a rich tradition of textbook analysis, we release our computational toolkit to support new research directions."
NLP (cs.CL),2020,17,Unnatural Language Processing: Bridging the Gap Between Synthetic and Natural Language Data,33,2004.13645,https://www.semanticscholar.org/paper/4f4202aac8c900efc79ec534f5f3b10b07bb45f5,"Alana Marzoev, S. Madden, M. Kaashoek et al.","Large, human-annotated datasets are central to the development of natural language processing models. Collecting these datasets can be the most challenging part of the development process. We address this problem by introducing a general purpose technique for ``simulation-to-real'' transfer in language understanding problems with a delimited set of target behaviors, making it possible to develop models that can interpret natural utterances without natural training data. We begin with a synthetic data generation procedure, and train a model that can accurately interpret utterances produced by the data generator. To generalize to natural utterances, we automatically find projections of natural language utterances onto the support of the synthetic language, using learned sentence embeddings to define a distance metric. With only synthetic training data, our approach matches or outperforms state-of-the-art models trained on natural language data in several domains. These results suggest that simulation-to-real transfer is a practical framework for developing NLP applications, and that improved models for transfer might provide wide-ranging improvements in downstream tasks."
NLP (cs.CL),2021,1,"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",4757,2107.13586,https://www.semanticscholar.org/paper/28692beece311a90f5fa1ca2ec9d0c2ce293d069,"Pengfei Liu, Weizhe Yuan, Jinlan Fu et al.","This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website NLPedia–Pretrain including constantly updated survey and paperlist."
NLP (cs.CL),2021,2,Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey,1333,2111.01243,https://www.semanticscholar.org/paper/c23d9d44e8bc68408cea9f305d1f24d915bc0d0d,"Bonan Min, Hayley Ross, Elior Sulem et al.","Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research."
NLP (cs.CL),2021,3,Datasets: A Community Library for Natural Language Processing,698,2109.02846,https://www.semanticscholar.org/paper/cddf40e579a596d0110b260313adf43470617c4c,"Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite et al.","The scale, variety, and quantity of publicly-available NLP datasets has grown rapidly as researchers propose new tasks, larger models, and novel benchmarks. Datasets is a community library for contemporary NLP designed to support this ecosystem. Datasets aims to standardize end-user interfaces, versioning, and documentation, while providing a lightweight front-end that behaves similarly for small datasets as for internet-scale corpora. The design of the library incorporates a distributed, community-driven approach to adding datasets and documenting usage. After a year of development, the library now includes more than 650 unique datasets, has more than 250 contributors, and has helped support a variety of novel cross-dataset research projects and shared tasks. The library is available at https://github.com/huggingface/datasets."
NLP (cs.CL),2021,16,"An introduction to Deep Learning in Natural Language Processing: Models, techniques, and tools",503,N/A,https://www.semanticscholar.org/paper/106176d796eda5efcd8a4d84ce98267350d679b9,"Ivano Lauriola, A. Lavelli, F. Aiolli",No Abstract
NLP (cs.CL),2021,7,BERT: A Review of Applications in Natural Language Processing and Understanding,362,2103.11943,https://www.semanticscholar.org/paper/879eaab2275a364549809560b42f0fef357ebbce,M. V. Koroteev,"Koroteev M.V., Financial University under the government of the Russian Federation, Moscow, Russia mvkoroteev@fa.ru Abstract: In this review, we describe the application of one of the most popular deep learning-based language models BERT. The paper describes the mechanism of operation of this model, the main areas of its application to the tasks of text analytics, comparisons with similar models in each task, as well as a description of some proprietary models. In preparing this review, the data of several dozen original scientific articles published over the past few years, which attracted the most attention in the scientific community, were systematized. This survey will be useful to all students and researchers who want to get acquainted with the latest advances in the field of natural language text analysis."
NLP (cs.CL),2021,14,AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing,308,2108.05542,https://www.semanticscholar.org/paper/6c761cfdb031701072582e434d8f64d436255da6,"Katikapalli Subramanyam Kalyan, A. Rajasekharan, S. Sangeetha","Transformer-based pretrained language models (T-PTLMs) have achieved great success in almost every NLP task. The evolution of these models started with GPT and BERT. These models are built on the top of transformers, self-supervised learning and transfer learning. Transformed-based PTLMs learn universal language representations from large volumes of text data using self-supervised learning and transfer this knowledge to downstream tasks. These models provide good background knowledge to downstream tasks which avoids training of downstream models from scratch. In this comprehensive survey paper, we initially give a brief overview of self-supervised learning. Next, we explain various core concepts like pretraining, pretraining methods, pretraining tasks, embeddings and downstream adaptation methods. Next, we present a new taxonomy of T-PTLMs and then give brief overview of various benchmarks including both intrinsic and extrinsic. We present a summary of various useful libraries to work with T-PTLMs. Finally, we highlight some of the future research directions which will further improve these models. We strongly believe that this comprehensive survey paper will serve as a good reference to learn the core concepts as well as to stay updated with the recent happenings in T-PTLMs."
NLP (cs.CL),2021,5,Five sources of bias in natural language processing,297,N/A,https://www.semanticscholar.org/paper/8b430ae5af9d7991cb3e698b2b30296fdf43dd15,"E. Hovy, Shrimai Prabhumoye","Abstract Recently, there has been an increased interest in demographically grounded bias in natural language processing (NLP) applications. Much of the recent work has focused on describing bias and providing an overview of bias in a larger context. Here, we provide a simple, actionable summary of this recent work. We outline five sources where bias can occur in NLP systems: (1) the data, (2) the annotation process, (3) the input representations, (4) the models, and finally (5) the research design (or how we conceptualize our research). We explore each of the bias sources in detail in this article, including examples and links to related work, as well as potential counter‐measures."
NLP (cs.CL),2021,6,"Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond",287,2109.00725,https://www.semanticscholar.org/paper/130d432ccbc836380a212bea618f84ff094a6a52,"Amir Feder, Katherine A. Keith, Emaad A. Manzoor et al.","Abstract A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the challenges and opportunities in the application of causal inference to the textual domain, with its unique properties. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects with text, encompassing settings where text is used as an outcome, treatment, or to address confounding. In addition, we explore potential uses of causal inference to improve the robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the NLP community.1"
NLP (cs.CL),2021,9,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),252,N/A,https://www.semanticscholar.org/paper/f5dfed82b0c8747e41a1206f52a6d0ea3dce4a5c,Unknown,No Abstract
NLP (cs.CL),2021,8,Extracting social determinants of health from electronic health records using natural language processing: a systematic review,184,N/A,https://www.semanticscholar.org/paper/7b3963d9ba52bfccd40ac1dba060e7a46a8f581c,"Braja Gopal Patra, M. Sharma, Veer Vekaria et al.","Abstract Objective Social determinants of health (SDoH) are nonclinical dispositions that impact patient health risks and clinical outcomes. Leveraging SDoH in clinical decision-making can potentially improve diagnosis, treatment planning, and patient outcomes. Despite increased interest in capturing SDoH in electronic health records (EHRs), such information is typically locked in unstructured clinical notes. Natural language processing (NLP) is the key technology to extract SDoH information from clinical text and expand its utility in patient care and research. This article presents a systematic review of the state-of-the-art NLP approaches and tools that focus on identifying and extracting SDoH data from unstructured clinical text in EHRs. Materials and Methods A broad literature search was conducted in February 2021 using 3 scholarly databases (ACL Anthology, PubMed, and Scopus) following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A total of 6402 publications were initially identified, and after applying the study inclusion criteria, 82 publications were selected for the final review. Results Smoking status (n = 27), substance use (n = 21), homelessness (n = 20), and alcohol use (n = 15) are the most frequently studied SDoH categories. Homelessness (n = 7) and other less-studied SDoH (eg, education, financial problems, social isolation and support, family problems) are mostly identified using rule-based approaches. In contrast, machine learning approaches are popular for identifying smoking status (n = 13), substance use (n = 9), and alcohol use (n = 9). Conclusion NLP offers significant potential to extract SDoH data from narrative clinical notes, which in turn can aid in the development of screening tools, risk prediction models, and clinical decision support systems."
NLP (cs.CL),2021,12,Natural Language Processing for Requirements Engineering,155,N/A,https://www.semanticscholar.org/paper/8bd130a5531622d58f819db4cab743a83eae90e6,"Liping Zhao, Waad Alhoshan, Alessio Ferrari et al.","Natural Language Processing for Requirements Engineering (NLP4RE) is an area of research and development that seeks to apply natural language processing (NLP) techniques, tools, and resources to the requirements engineering (RE) process, to support human analysts to carry out various linguistic analysis tasks on textual requirements documents, such as detecting language issues, identifying key domain concepts, and establishing requirements traceability links. This article reports on a mapping study that surveys the landscape of NLP4RE research to provide a holistic understanding of the field. Following the guidance of systematic review, the mapping study is directed by five research questions, cutting across five aspects of NLP4RE research, concerning the state of the literature, the state of empirical research, the research focus, the state of tool development, and the usage of NLP technologies. Our main results are as follows: (i) we identify a total of 404 primary studies relevant to NLP4RE, which were published over the past 36 years and from 170 different venues; (ii) most of these studies (67.08%) are solution proposals, assessed by a laboratory experiment or an example application, while only a small percentage (7%) are assessed in industrial settings; (iii) a large proportion of the studies (42.70%) focus on the requirements analysis phase, with quality defect detection as their central task and requirements specification as their commonly processed document type; (iv) 130 NLP4RE tools (i.e., RE specific NLP tools) are extracted from these studies, but only 17 of them (13.08%) are available for download; (v) 231 different NLP technologies are also identified, comprising 140 NLP techniques, 66 NLP tools, and 25 NLP resources, but most of them—particularly those novel NLP techniques and specialized tools—are used infrequently; by contrast, commonly used NLP technologies are traditional analysis techniques (e.g., POS tagging and tokenization), general-purpose tools (e.g., Stanford CoreNLP and GATE) and generic language lexicons (WordNet and British National Corpus). The mapping study not only provides a collection of the literature in NLP4RE but also, more importantly, establishes a structure to frame the existing literature through categorization, synthesis and conceptualization of the main theoretical concepts and relationships that encompass both RE and NLP aspects. Our work thus produces a conceptual framework of NLP4RE. The framework is used to identify research gaps and directions, highlight technology transfer needs, and encourage more synergies between the RE community, the NLP one, and the software and systems practitioners. Our results can be used as a starting point to frame future studies according to a well-defined terminology and can be expanded as new technologies and novel solutions emerge."
NLP (cs.CL),2021,11,Multi-Task Learning in Natural Language Processing: An Overview,154,2109.09138,https://www.semanticscholar.org/paper/760f807406272b5ede591f19241824f2d17c319a,"Shijie Chen, Yu Zhang, Qiang Yang","Deep learning approaches have achieved great success in the field of Natural Language Processing (NLP). However, directly training deep neural models often suffer from overfitting and data scarcity problems that are pervasive in NLP tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful information of related tasks to achieve simultaneous performance improvement on these tasks, has been used to handle these problems. In this article, we give an overview of the use of MTL in NLP tasks. We first review MTL architectures used in NLP tasks and categorize them into four classes, including parallel architecture, hierarchical architecture, modular architecture, and generative adversarial architecture. Then we present optimization techniques on loss construction, gradient regularization, data sampling, and task scheduling to properly train a multi-task model. After presenting applications of MTL in a variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a conclusion and discuss several possible research directions in this field."
NLP (cs.CL),2021,13,A State of Art for Semantic Analysis of Natural Language Processing,154,N/A,https://www.semanticscholar.org/paper/23c140ed32108d2d49106a305a940b8838f3d17f,"st Dastan, Hussen Maulud, Subhi R. M. Zeebaree et al.",No Abstract
NLP (cs.CL),2021,4,Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing,152,2101.03289,https://www.semanticscholar.org/paper/b53c386b7c65af80905dc05a9b27e98e03324739,"Minh Nguyen, Viet Dac Lai, Amir Pouran Ben Veyseh et al.","We introduce Trankit, a light-weight Transformer-based Toolkit for multilingual Natural Language Processing (NLP). It provides a trainable pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained pipelines for 56 languages. Built on a state-of-the-art pretrained language model, Trankit significantly outperforms prior multilingual NLP pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsing while maintaining competitive performance for tokenization, multi-word token expansion, and lemmatization over 90 Universal Dependencies treebanks. Despite the use of a large pretrained transformer, our toolkit is still efficient in memory usage and speed. This is achieved by our novel plug-and-play mechanism with Adapters where a multilingual pretrained transformer is shared across pipelines for different languages. Our toolkit along with pretrained models and code are publicly available at: https://github.com/nlp-uoregon/trankit. A demo website for our toolkit is also available at: http://nlp.uoregon.edu/trankit. Finally, we create a demo video for Trankit at: https://youtu.be/q0KGP3zGjGc."
NLP (cs.CL),2021,15,A Survey on Gender Bias in Natural Language Processing,141,2112.14168,https://www.semanticscholar.org/paper/04ec406caebff60e226695c921f0af1b29162c5f,"Karolina Stańczak, Isabelle Augenstein","Language can be used as a means of reproducing and enforcing harmful stereotypes and biases and has been analysed as such in numerous research. In this paper, we present a survey of 304 papers on gender bias in natural language processing. We analyse definitions of gender and its categories within social sciences and connect them to formal definitions of gender bias in NLP research. We survey lexica and datasets applied in research on gender bias and then compare and contrast approaches to detecting and mitigating gender bias. We find that research on gender bias suffers from four core limitations. 1) Most research treats gender as a binary variable neglecting its fluidity and continuity. 2) Most of the work has been conducted in monolingual setups for English or other high-resource languages. 3) Despite a myriad of papers on gender bias in NLP methods, we find that most of the newly developed algorithms do not test their models for bias and disregard possible ethical considerations of their work. 4) Finally, methodologies developed in this line of research are fundamentally flawed covering very limited definitions of gender bias and lacking evaluation baselines and pipelines. We suggest recommendations towards overcoming these limitations as a guide for future research."
NLP (cs.CL),2021,10,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,140,2104.08815,https://www.semanticscholar.org/paper/a55c399bbb0382650459da59fc545f2dd275012b,"Bill Yuchen Lin, Chaoyang He, ZiHang Zeng et al.","Increasing concerns and regulations about data privacy and sparsity necessitate the study of privacy-preserving, decentralized learning methods for natural language processing (NLP) tasks. Federated learning (FL) provides promising approaches for a large number of clients (e.g., personal devices or organizations) to collaboratively learn a shared global model to benefit all clients while allowing users to keep their data locally. Despite interest in studying FL methods for NLP tasks, a systematic comparison and analysis is lacking in the literature. Herein, we present the FedNLP, a benchmarking framework for evaluating federated learning methods on four different task formulations: text classification, sequence tagging, question answering, and seq2seq. We propose a universal interface between Transformer-based language models (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under various non-IID partitioning strategies. Our extensive experiments with FedNLP provide empirical comparisons between FL methods and helps us better understand the inherent challenges of this direction. The comprehensive analysis points to intriguing and exciting future research aimed at developing FL methods for NLP tasks."
NLP (cs.CL),2021,19,Including Signed Languages in Natural Language Processing,129,2105.05222,https://www.semanticscholar.org/paper/c4358134954d8e62939c3a8b9ba8e953d951f73b,"Kayo Yin, Amit Moryossef, J. Hochgesang et al.","Signed languages are the primary means of communication for many deaf and hard of hearing individuals. Since signed languages exhibit all the fundamental linguistic properties of natural language, we believe that tools and theories of Natural Language Processing (NLP) are crucial towards its modeling. However, existing research in Sign Language Processing (SLP) seldom attempt to explore and leverage the linguistic organization of signed languages. This position paper calls on the NLP community to include signed languages as a research area with high social and scientific impact. We first discuss the linguistic properties of signed languages to consider during their modeling. Then, we review the limitations of current SLP models and identify the open challenges to extend NLP to signed languages. Finally, we urge (1) the adoption of an efficient tokenization method; (2) the development of linguistically-informed models; (3) the collection of real-world signed language data; (4) the inclusion of local signed language communities as an active and leading voice in the direction of research."
NLP (cs.CL),2021,20,Machine learning in medicine: a practical introduction to natural language processing,116,N/A,https://www.semanticscholar.org/paper/c279034daae43af856178e7fb60ce196ff2b534b,"C. Harrison, Chris J. Sidey-Gibbons","Background Unstructured text, including medical records, patient feedback, and social media comments, can be a rich source of data for clinical research. Natural language processing (NLP) describes a set of techniques used to convert passages of written text into interpretable datasets that can be analysed by statistical and machine learning (ML) models. The purpose of this paper is to provide a practical introduction to contemporary techniques for the analysis of text-data, using freely-available software. Methods We performed three NLP experiments using publicly-available data obtained from medicine review websites. First, we conducted lexicon-based sentiment analysis on open-text patient reviews of four drugs: Levothyroxine, Viagra, Oseltamivir and Apixaban. Next, we used unsupervised ML (latent Dirichlet allocation, LDA) to identify similar drugs in the dataset, based solely on their reviews. Finally, we developed three supervised ML algorithms to predict whether a drug review was associated with a positive or negative rating. These algorithms were: a regularised logistic regression, a support vector machine (SVM), and an artificial neural network (ANN). We compared the performance of these algorithms in terms of classification accuracy, area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results Levothyroxine and Viagra were reviewed with a higher proportion of positive sentiments than Oseltamivir and Apixaban. One of the three LDA clusters clearly represented drugs used to treat mental health problems. A common theme suggested by this cluster was drugs taking weeks or months to work. Another cluster clearly represented drugs used as contraceptives. Supervised machine learning algorithms predicted positive or negative drug ratings with classification accuracies ranging from 0.664, 95% CI [0.608, 0.716] for the regularised regression to 0.720, 95% CI [0.664,0.776] for the SVM. Conclusions In this paper, we present a conceptual overview of common techniques used to analyse large volumes of text, and provide reproducible code that can be readily applied to other research studies using open-source software."
NLP (cs.CL),2021,17,Applying natural language processing and machine learning techniques to patient experience feedback: a systematic review,112,N/A,https://www.semanticscholar.org/paper/cc375e2130cae2bc1f390a6c84a0258bbf9971a8,"M. Khanbhai, P. Anyadi, Joshua Symons et al.","Objectives Unstructured free-text patient feedback contains rich information, and analysing these data manually would require a lot of personnel resources which are not available in most healthcare organisations.To undertake a systematic review of the literature on the use of natural language processing (NLP) and machine learning (ML) to process and analyse free-text patient experience data. Methods Databases were systematically searched to identify articles published between January 2000 and December 2019 examining NLP to analyse free-text patient feedback. Due to the heterogeneous nature of the studies, a narrative synthesis was deemed most appropriate. Data related to the study purpose, corpus, methodology, performance metrics and indicators of quality were recorded. Results Nineteen articles were included. The majority (80%) of studies applied language analysis techniques on patient feedback from social media sites (unsolicited) followed by structured surveys (solicited). Supervised learning was frequently used (n=9), followed by unsupervised (n=6) and semisupervised (n=3). Comments extracted from social media were analysed using an unsupervised approach, and free-text comments held within structured surveys were analysed using a supervised approach. Reported performance metrics included the precision, recall and F-measure, with support vector machine and Naïve Bayes being the best performing ML classifiers. Conclusion NLP and ML have emerged as an important tool for processing unstructured free text. Both supervised and unsupervised approaches have their role depending on the data source. With the advancement of data analysis tools, these techniques may be useful to healthcare organisations to generate insight from the volumes of unstructured free-text data."
NLP (cs.CL),2021,18,NPE: An FPGA-based Overlay Processor for Natural Language Processing,84,2104.06535,https://www.semanticscholar.org/paper/9f840be023309cc957dc741dce85dfc6b1a3b486,"H. Khan, Asma Khan, Zainab F. Khan et al.","In recent years, transformer-based models have shown state-of-the-art results for Natural Language Processing (NLP). In particular, the introduction of the BERT language model brought with it breakthroughs in tasks such as question answering and natural language inference, advancing applications that allow humans to interact naturally with embedded devices. FPGA-based overlay processors have been shown as effective solutions for edge image and video processing applications, which mostly rely on low precision linear matrix operations. In contrast, transformer-based NLP techniques employ a variety of higher precision nonlinear operations with significantly higher frequency. We present NPE, an FPGA-based overlay processor that can efficiently execute a variety of NLP models. NPE offers software-like programmability to the end user and, unlike FPGA designs that implement specialized accelerators for each nonlinear function, can be upgraded for future NLP models without requiring reconfiguration. NPE can meet real-time conversational AI latency targets for the BERT language model with 4x lower power than CPUs and 6x lower power than GPUs. We also show NPE uses 3x fewer FPGA resources relative to comparable BERT network-specific accelerators in the literature. NPE provides a cost-effective and power-efficient FPGA-based solution for Natural Language Processing at the edge."
NLP (cs.CL),2023,1,Is ChatGPT a General-Purpose Natural Language Processing Task Solver?,784,2302.06476,https://www.semanticscholar.org/paper/873a581320d928249609d3c07229d5af182a379c,"Chengwei Qin, Aston Zhang, Zhuosheng Zhang et al.","Spurred by advancements in scale, large language models (LLMs) have demonstrated the ability to perform a variety of natural language processing (NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently, the debut of ChatGPT has drawn a great deal of attention from the natural language processing (NLP) community due to the fact that it can generate high-quality responses to human input and self-correct previous mistakes based on subsequent conversations. However, it is not yet known whether ChatGPT can serve as a generalist model that can perform many NLP tasks zero-shot. In this work, we empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on 20 popular NLP datasets covering 7 representative task categories. With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT. We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging. We additionally provide in-depth analysis through qualitative case studies."
NLP (cs.CL),2023,2,A Scoping Literature Review of Natural Language Processing Application to Safety Occurrence Reports,599,N/A,https://www.semanticscholar.org/paper/f402971f33a07333bb81394aa3d0c0e93ca2b960,"John W. Ricketts, David Barry, Weisi Guo et al.","Safety occurrence reports can contain valuable information on how incidents occur, revealing knowledge that can assist safety practitioners. This paper presents and discusses a literature review exploring how Natural Language Processing (NLP) has been applied to occurrence reports within safety-critical industries, informing further research on the topic and highlighting common challenges. Some of the uses of NLP include the ability for occurrence reports to be automatically classified against categories, and entities such as causes and consequences to be extracted from the text as well as the semantic searching of occurrence databases. The review revealed that machine learning models form the dominant method when applying NLP, although rule-based algorithms still provide a viable option for some entity extraction tasks. Recent advances in deep learning models such as Bidirectional Transformers for Language Understanding are now achieving a high accuracy while eliminating the need to substantially pre-process text. The construction of safety-themed datasets would be of benefit for the application of NLP to occurrence reporting, as this would allow the fine-tuning of current language models to safety tasks. An interesting approach is the use of topic modelling, which represents a shift away from the prescriptive classification taxonomies, splitting data into “topics”. Where many papers focus on the computational accuracy of models, they would also benefit from real-world trials to further inform usefulness. It is anticipated that NLP will soon become a mainstream tool used by safety practitioners to efficiently process and gain knowledge from safety-related text."
NLP (cs.CL),2023,9,Graph Neural Networks for Natural Language Processing: A Survey,347,N/A,https://www.semanticscholar.org/paper/da923d1ccfd4927fae7c2a835c7979e3a4dec159,"Lingfei Wu, Yu Chen, Kai Shen et al.",No Abstract
NLP (cs.CL),2023,11,Natural Language Processing in Electronic Health Records in relation to healthcare decision-making: A systematic review,272,2306.12834,https://www.semanticscholar.org/paper/65d0e006452d980830108d8c80960e4f37a8440f,"Elias Hossain, R. Rana, N. Higgins et al.",No Abstract
NLP (cs.CL),2023,3,A Review of the Trends and Challenges in Adopting Natural Language Processing Methods for Education Feedback Analysis,160,2301.08826,https://www.semanticscholar.org/paper/efbe2903ce921d6aa7ad6055c53511e0e6f25fa1,"T. Shaik, Xiaohui Tao, Y. Li et al.","Artificial Intelligence (AI) is a fast-growing area of study that stretching its presence to many business and research domains. Machine learning, deep learning, and natural language processing (NLP) are subsets of AI to tackle different areas of data processing and modelling. This review article presents an overview of AI’s impact on education outlining with current opportunities. In the education domain, student feedback data is crucial to uncover the merits and demerits of existing services provided to students. AI can assist in identifying the areas of improvement in educational infrastructure, learning management systems, teaching practices and study environment. NLP techniques play a vital role in analyzing student feedback in textual format. This research focuses on existing NLP methodologies and applications that could be adapted to educational domain applications like sentiment annotations, entity annotations, text summarization, and topic modelling. Trends and challenges in adopting NLP in education were reviewed and explored. Context-based challenges in NLP like sarcasm, domain-specific language, ambiguity, and aspect-based sentiment analysis are explained with existing methodologies to overcome them. Research community approaches to extract the semantic meaning of emoticons and special characters in feedback which conveys user opinion and challenges in adopting NLP in education are explored."
NLP (cs.CL),2023,10,Exploring the frontiers of deep learning and natural language processing: A comprehensive overview of key challenges and emerging trends,150,N/A,https://www.semanticscholar.org/paper/2baa3d2699e680bd6b16bce603f1df6827ff98d8,"Wahab Khan, Ali Daud, Khairullah Khan et al.",No Abstract
NLP (cs.CL),2023,4,"A Comprehensive Study of ChatGPT: Advancements, Limitations, and Ethical Considerations in Natural Language Processing and Cybersecurity",129,N/A,https://www.semanticscholar.org/paper/0302438b3656971ea3741b71d0da6e4c417c74cf,"Moatsum Alawida, S. Mejri, Abid Mehmood et al.","This paper presents an in-depth study of ChatGPT, a state-of-the-art language model that is revolutionizing generative text. We provide a comprehensive analysis of its architecture, training data, and evaluation metrics and explore its advancements and enhancements over time. Additionally, we examine the capabilities and limitations of ChatGPT in natural language processing (NLP) tasks, including language translation, text summarization, and dialogue generation. Furthermore, we compare ChatGPT to other language generation models and discuss its applicability in various tasks. Our study also addresses the ethical and privacy considerations associated with ChatGPT and provides insights into mitigation strategies. Moreover, we investigate the role of ChatGPT in cyberattacks, highlighting potential security risks. Lastly, we showcase the diverse applications of ChatGPT in different industries and evaluate its performance across languages and domains. This paper offers a comprehensive exploration of ChatGPT’s impact on the NLP field."
NLP (cs.CL),2023,5,"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing",117,2304.02017,https://www.semanticscholar.org/paper/9e93ab728e3e174ec1492009055885a9123d434f,Walid Hariri,"Large language models, pivotal in artificial intelligence, find diverse applications. ChatGPT (Chat Generative Pre-trained Transformer), an OpenAI creation, stands out as a widely adopted, powerful tool. It excels in chatbots, content generation, language translation, recommendations, and medical applications, due to its ability to generate human-like responses, comprehend natural language, and adapt contextually. Its versatility and accuracy make it a potent force in natural language processing (NLP). Despite successes, ChatGPT has limitations, including biased responses and potential reinforcement of harmful language patterns. This article offers a comprehensive overview of ChatGPT, detailing its applications, advantages, and limitations. It also describes the main advancements from GPT-3 to GPT-4 Omni, comparing them with other LLMs like LLaMA 3, Gemini and Deepseek. The paper underscores the ethical imperative when utilizing this robust tool in practical settings. Furthermore, it contributes to ongoing discussions on artificial intelligence's impact on vision and NLP domains, providing insights into prompt engineering techniques."
NLP (cs.CL),2023,7,Benchmarking large language models for biomedical natural language processing applications and recommendations,114,2305.16326,https://www.semanticscholar.org/paper/ef9b84a57a654888729ce73a3f2400d56e12a300,"Qingyu Chen, Jingcheng Du, Yan Hu et al.","The rapid growth of biomedical literature poses challenges for manual knowledge curation and synthesis. Biomedical Natural Language Processing (BioNLP) automates the process. While Large Language Models (LLMs) have shown promise in general domains, their effectiveness in BioNLP tasks remains unclear due to limited benchmarks and practical guidelines. We perform a systematic evaluation of four LLMs—GPT and LLaMA representatives—on 12 BioNLP benchmarks across six applications. We compare their zero-shot, few-shot, and fine-tuning performance with the traditional fine-tuning of BERT or BART models. We examine inconsistencies, missing information, hallucinations, and perform cost analysis. Here, we show that traditional fine-tuning outperforms zero- or few-shot LLMs in most tasks. However, closed-source LLMs like GPT-4 excel in reasoning-related tasks such as medical question answering. Open-source LLMs still require fine-tuning to close performance gaps. We find issues like missing information and hallucinations in LLM outputs. These results offer practical insights for applying LLMs in BioNLP. Baseline performance, benchmarks, and guidance for LLMs in biomedicine are limited. The authors assess four LLMs on 12 tasks, establish baselines, examine hallucinations, and provide recommendations for optimal LLM use."
NLP (cs.CL),2023,6,PyThaiNLP: Thai Natural Language Processing in Python,110,2312.04649,https://www.semanticscholar.org/paper/17fd7b820b0879734a2c08c20a890ddc526cd83d,"Wannaphong Phatthiyaphaibun, Korakot Chaovavanich, Charin Polpanumas et al.","We present PyThaiNLP, a free and open-source natural language processing (NLP) library for Thai language implemented in Python. It provides a wide range of software, models, and datasets for Thai language. We first provide a brief historical context of tools for Thai language prior to the development of PyThaiNLP. We then outline the functionalities it provided as well as datasets and pre-trained language models. We later summarize its development milestones and discuss our experience during its development. We conclude by demonstrating how industrial and research communities utilize PyThaiNLP in their work. The library is freely available at https://github.com/pythainlp/pythainlp."
NLP (cs.CL),2023,8,Natural language processing for mental health interventions: a systematic review and research framework,102,N/A,https://www.semanticscholar.org/paper/894e8cf18cbec9251d7c911b9433cc85f7150d51,"M. Malgaroli, Thomas D. Hull, Jamie M. Zech et al.","Neuropsychiatric disorders pose a high societal cost, but their treatment is hindered by lack of objective outcomes and fidelity metrics. AI technologies and specifically Natural Language Processing (NLP) have emerged as tools to study mental health interventions (MHI) at the level of their constituent conversations. However, NLP’s potential to address clinical and research challenges remains unclear. We therefore conducted a pre-registered systematic review of NLP-MHI studies using PRISMA guidelines (osf.io/s52jh) to evaluate their models, clinical applications, and to identify biases and gaps. Candidate studies (n = 19,756), including peer-reviewed AI conference manuscripts, were collected up to January 2023 through PubMed, PsycINFO, Scopus, Google Scholar, and ArXiv. A total of 102 articles were included to investigate their computational characteristics (NLP algorithms, audio features, machine learning pipelines, outcome metrics), clinical characteristics (clinical ground truths, study samples, clinical focus), and limitations. Results indicate a rapid growth of NLP MHI studies since 2019, characterized by increased sample sizes and use of large language models. Digital health platforms were the largest providers of MHI data. Ground truth for supervised learning models was based on clinician ratings ( n  = 31), patient self-report ( n  = 29) and annotations by raters ( n  = 26). Text-based features contributed more to model accuracy than audio markers. Patients’ clinical presentation ( n  = 34), response to intervention ( n  = 11), intervention monitoring ( n  = 20), providers’ characteristics ( n  = 12), relational dynamics ( n  = 14), and data preparation ( n  = 4) were commonly investigated clinical categories. Limitations of reviewed studies included lack of linguistic diversity, limited reproducibility, and population bias. A research framework is developed and validated (NLPxMHI) to assist computational and clinical researchers in addressing the remaining gaps in applying NLP to MHI, with the goal of improving clinical utility, data access, and fairness."
NLP (cs.CL),2023,16,Gpt-4: A Review on Advancements and Opportunities in Natural Language Processing,70,2305.03195,https://www.semanticscholar.org/paper/89dd10444b733478452f5700184ac9e398b6764d,"J. Baktash, Mursal Dawodi","Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation language model in the GPT series, developed by OpenAI, which promises significant advancements in the field of natural language processing (NLP). In this research article, we have discussed the features of GPT-4, its potential applications, and the challenges that it might face. We have also compared GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one trillion), better multilingual capabilities, improved contextual understanding, and reasoning capabilities than GPT-3. Some of the potential applications of GPT-4 include chatbots, personal assistants, language translation, text summarization, and question-answering. However, GPT-4 poses several challenges and limitations such as computational requirements, data requirements, and ethical concerns."
NLP (cs.CL),2023,19,Literature Review of Qualitative Data with Natural Language Processing,69,N/A,https://www.semanticscholar.org/paper/eb764d87d4d8c25a290fbbe83f922cda122ae1ef,Bukuroshe Elira Epoka,"Qualitative research techniques are frequently employed by scholars in the field of social sciences when investigating communities and their communication media. The proliferation of computer-mediated communications has resulted in a substantial volume of textual content. However, the process of coding this vast amount of information necessitates significant time and effort. This article examines the potential for automating specific elements of content analysis through the utilization of natural language processing (NLP) systems, which analyze text in human languages, with a focus on extracting theoretical evidence. In this study, we present a case analysis utilizing NLP to examine the effectiveness of NLP rules in qualitative analysis. Our findings indicate that the NLP rules demonstrated strong performance across multiple codes. The utilization of a NLP system in its current developmental stage has the potential to significantly minimize the text volume, which has to be evaluated using the human coder. This reduction could potentially result in a substantial increase in coding speed, potentially by a factor of ten or more. The research is considered groundbreaking as it pioneers the application of advanced NLP approach to evaluate qualitative data, making it one of the earliest studies in this domain."
NLP (cs.CL),2023,20,"Uncertainty in Natural Language Processing: Sources, Quantification, and Applications",52,2306.04459,https://www.semanticscholar.org/paper/ec7a6d3d930dad2c36088478f2490830f102bd97,"Mengting Hu, Zhen Zhang, Shiwan Zhao et al.","As a main field of artificial intelligence, natural language processing (NLP) has achieved remarkable success via deep neural networks. Plenty of NLP tasks have been addressed in a unified manner, with various tasks being associated with each other through sharing the same paradigm. However, neural networks are black boxes and rely on probability computation. Making mistakes is inevitable. Therefore, estimating the reliability and trustworthiness (in other words, uncertainty) of neural networks becomes a key research direction, which plays a crucial role in reducing models' risks and making better decisions. Therefore, in this survey, we provide a comprehensive review of uncertainty-relevant works in the NLP field. Considering the data and paradigms characteristics, we first categorize the sources of uncertainty in natural language into three types, including input, system, and output. Then, we systemically review uncertainty quantification approaches and the main applications. Finally, we discuss the challenges of uncertainty estimation in NLP and discuss potential future directions, taking into account recent trends in the field. Though there have been a few surveys about uncertainty estimation, our work is the first to review uncertainty from the NLP perspective."
NLP (cs.CL),2023,12,Assessment of Natural Language Processing of Electronic Health Records to Measure Goals-of-Care Discussions as a Clinical Trial Outcome,50,N/A,https://www.semanticscholar.org/paper/57c14d250f231bf56b3c68441aaa36d389281b0d,"R. Lee, Erin K Kross, J. Torrence et al.","This diagnostic study evaluates the performance, feasibility, and power implications of using natural language processing to measure outcomes in a randomized clinical trial of a communication intervention among adults with serious illness."
NLP (cs.CL),2023,13,Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review,44,2309.06055,https://www.semanticscholar.org/paper/aa83437007d3fd6b79f11180f0c5b640d0c48cb3,"Pengzhou Cheng, Zongru Wu, Wei Du et al.","Language models (LMs) are becoming increasingly popular in real-world applications. Outsourcing model training and data hosting to third-party platforms has become a standard method for reducing costs. In such a situation, the attacker can manipulate the training process or data to inject a backdoor into models. Backdoor attacks are a serious threat where malicious behavior is activated when triggers are present; otherwise, the model operates normally. However, there is still no systematic and comprehensive review of LMs from the attacker’s capabilities and purposes on different backdoor attack surfaces. Moreover, there is a shortage of analysis and comparison of the diverse emerging backdoor countermeasures. Therefore, this work aims to provide the natural language processing (NLP) community with a timely review of backdoor attacks and countermeasures. According to the attackers’ capability and affected stage of the LMs, the attack surfaces are formalized into four categorizations: attacking the pretrained model with fine-tuning (APMF) or parameter-efficient fine-tuning (PEFT), attacking the final model with training (AFMT), and attacking large language model (ALLM). Thus, attacks under each categorization are combed. The countermeasures are categorized into two general classes: sample inspection and model inspection. Thus, we review countermeasures and analyze their advantages and disadvantages. Also, we summarize the benchmark datasets and provide comparable evaluations for representative attacks and defenses. Drawing the insights from the review, we point out the crucial areas for future research on the backdoor, especially soliciting more efficient and practical countermeasures."
NLP (cs.CL),2023,14,Machine Learning Driven Mental Stress Detection on Reddit Posts Using Natural Language Processing,43,N/A,https://www.semanticscholar.org/paper/66d8440202c799e89e95d0abb468789b85d8dd94,"Shaunak Inamdar, Rishikesh Chapekar, Shilpa Gite et al.","People’s mental conditions are often reflected in their social media activity due to the internet's anonymity. Psychiatric issues are often detected through such activities and can be addressed in their early stages, potentially preventing the consequences of unattended mental disorders like depression and anxiety. In this paper, the authors have implemented machine learning models and used various embedding techniques to classify posts from the famous social media blog site Reddit as stressful and non-stressful. The dataset used contains user posts that can be analyzed to detect patterns in the social media activity of those diagnosed with mental disorders. This paper uses different NLP (Natural Language Processing) tools such as ELMo (Embeddings from Language Models) word embeddings, BERT (Bidirectional Encoder Representations from Transformers) tokenizers, and BoW (Bag of Words) approach to create word/sentence data that can be fed to machine learning models. The results of each method have been discussed. The results achieved a top F1 score of 0.76, a Precision score of 0.71, and a Recall of 0.74 using only the preprocessed texts and machine learning algorithms to classify the posts. The results achieved by this paper are significant and have the potential to be applied in real-world scenarios to analyze mental stress among social media users. Although this paper focuses on data from Reddit, the techniques used can be transferred to similar social media platforms and could help solve the growing mental health crisis."
NLP (cs.CL),2023,15,Interactive Natural Language Processing,42,2305.13246,https://www.semanticscholar.org/paper/3ec625fabd8c43a05381d601b4e15dead0ae2317,"Zekun Wang, Ge Zhang, Kexin Yang et al.","Interactive Natural Language Processing (iNLP) has emerged as a novel paradigm within the field of NLP, aimed at addressing limitations in existing frameworks while aligning with the ultimate goals of artificial intelligence. This paradigm considers language models as agents capable of observing, acting, and receiving feedback iteratively from external entities. Specifically, language models in this context can: (1) interact with humans for better understanding and addressing user needs, personalizing responses, aligning with human values, and improving the overall user experience; (2) interact with knowledge bases for enriching language representations with factual knowledge, enhancing the contextual relevance of responses, and dynamically leveraging external information to generate more accurate and informed responses; (3) interact with models and tools for effectively decomposing and addressing complex tasks, leveraging specialized expertise for specific subtasks, and fostering the simulation of social behaviors; and (4) interact with environments for learning grounded representations of language, and effectively tackling embodied tasks such as reasoning, planning, and decision-making in response to environmental observations. This paper offers a comprehensive survey of iNLP, starting by proposing a unified definition and framework of the concept. We then provide a systematic classification of iNLP, dissecting its various components, including interactive objects, interaction interfaces, and interaction methods. We proceed to delve into the evaluation methodologies used in the field, explore its diverse applications, scrutinize its ethical and safety issues, and discuss prospective research directions. This survey serves as an entry point for researchers who are interested in this rapidly evolving area and offers a broad view of the current landscape and future trajectory of iNLP."
NLP (cs.CL),2023,17,Fraud detection with natural language processing,38,N/A,https://www.semanticscholar.org/paper/a26ebf06c55b80cdb5be79d35031dcc0633e967a,"Petros Boulieris, John Pavlopoulos, Alexandros Xenos et al.","Automated fraud detection can assist organisations to safeguard user accounts, a task that is very challenging due to the great sparsity of known fraud transactions. Many approaches in the literature focus on credit card fraud and ignore the growing field of online banking. However, there is a lack of publicly available data for both. The lack of publicly available data hinders the progress of the field and limits the investigation of potential solutions. With this work, we: (a) introduce FraudNLP, the first anonymised, publicly available dataset for online fraud detection, (b) benchmark machine and deep learning methods with multiple evaluation measures, (c) argue that online actions do follow rules similar to natural language and hence can be approached successfully by natural language processing methods."
NLP (cs.CL),2023,18,The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research,36,2305.02797,https://www.semanticscholar.org/paper/587ffdfd7229e8e0dbc5250b44df5fad6251f6ad,"Mohamed Abdalla, Jan Philip Wahle, Terry Ruas et al.","Recent advances in deep learning methods for natural language processing (NLP) have created new business opportunities and made NLP research critical for industry development. As one of the big players in the field of NLP, together with governments and universities, it is important to track the influence of industry on research. In this study, we seek to quantify and characterize industry presence in the NLP community over time. Using a corpus with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP publication authors, we explore the industry presence in the field since the early 90s. We find that industry presence among NLP authors has been steady before a steep increase over the past five years (180% growth from 2017 to 2022). A few companies account for most of the publications and provide funding to academic researchers through grants and internships. Our study shows that the presence and impact of the industry on natural language processing research are significant and fast-growing. This work calls for increased transparency of industry influence in the field."
NLP (cs.CL),2024,3,Text mining and natural language processing in construction,110,N/A,https://www.semanticscholar.org/paper/d297f36939026502a88587740401a070160094be,"Alireza Shamshiri, K. Ryu, June Young Park",No Abstract
NLP (cs.CL),2024,2,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,100,N/A,https://www.semanticscholar.org/paper/d33a14592d68da068953cdf37f8bf562740c0085,"Sonish Sivarajkumar, Mark Kelley, Alyssa Samolyk-Mazzanti et al.","Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area."
NLP (cs.CL),2024,5,Retrieval-Augmented Generation for Natural Language Processing: A Survey,85,2407.13193,https://www.semanticscholar.org/paper/d4a5c2ab2b459426869e1a3ab1550897b005303e,"Shangyu Wu, Ying Xiong, Yufei Cui et al.","Large language models (LLMs) have demonstrated great success in various fields, benefiting from their huge amount of parameters that store knowledge. However, LLMs still suffer from several key issues, such as hallucination problems, knowledge update issues, and lacking domain-specific expertise. The appearance of retrieval-augmented generation (RAG), which leverages an external knowledge database to augment LLMs, makes up those drawbacks of LLMs. This paper reviews all significant techniques of RAG, especially in the retriever and the retrieval fusions. Besides, tutorial codes are provided for implementing the representative techniques in RAG. This paper further discusses the RAG update, including RAG with/without knowledge update. Then, we introduce RAG evaluation and benchmarking, as well as the application of RAG in representative NLP tasks and industrial scenarios. Finally, this paper discusses RAG's future directions and challenges for promoting this field's development."
NLP (cs.CL),2024,6,Overview of IberLEF 2024: Natural Language Processing Challenges for Spanish and other Iberian Languages,78,N/A,https://www.semanticscholar.org/paper/e97e149b916d970dca3b108dfd27420685901c21,"Luis Chiruzzo, Salud María Jiménez-Zafra, Francisco Rangel",No Abstract
NLP (cs.CL),2024,7,Survey of transformers and towards ensemble learning using transformers for natural language processing,64,N/A,https://www.semanticscholar.org/paper/a95f97e4b51eeab38e94b088034ced7c6e31a4c1,"Hongzhi Zhang, M. O. Shafiq","The transformer model is a famous natural language processing model proposed by Google in 2017. Now, with the extensive development of deep learning, many natural language processing tasks can be solved by deep learning methods. After the BERT model was proposed, many pre-trained models such as the XLNet model, the RoBERTa model, and the ALBERT model were also proposed in the research community. These models perform very well in various natural language processing tasks. In this paper, we describe and compare these well-known models. In addition, we also apply several types of existing and well-known models which are the BERT model, the XLNet model, the RoBERTa model, the GPT2 model, and the ALBERT model to different existing and well-known natural language processing tasks, and analyze each model based on their performance. There are a few papers that comprehensively compare various transformer models. In our paper, we use six types of well-known tasks, such as sentiment analysis, question answering, text generation, text summarization, name entity recognition, and topic modeling tasks to compare the performance of various transformer models. In addition, using the existing models, we also propose ensemble learning models for the different natural language processing tasks. The results show that our ensemble learning models  perform better than a single classifier on specific tasks. Graphical Abstract"
NLP (cs.CL),2024,8,Natural Language Processing for Dialects of a Language: A Survey,60,2401.05632,https://www.semanticscholar.org/paper/d70fe318d5fa97dab6ceaa3a5f14869f45b384dd,"Aditya Joshi, Raj Dabre, Diptesh Kanojia et al.","State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectal datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German, among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and extends to several NLU and NLG tasks. For these tasks, we describe classical machine learning using statistical models, along with the recent deep learning-based approaches based on pre-trained language models. We expect that this survey will be useful to NLP researchers interested in building equitable language technologies by rethinking LLM benchmarks and model architectures."
NLP (cs.CL),2024,9,A Comparative Analysis of Generative Artificial Intelligence Tools for Natural Language Processing,49,N/A,https://www.semanticscholar.org/paper/aaa971c619766f9445c223a22783dab303b7d526,"A. Iorliam, Joseph Abunimye Ingio","Generative artificial intelligence tools have recently attracted a great deal of attention. This is because of their huge advantages, which include ease of usage, quick generation of answers to requests, and the human-like intelligence they possess. This paper presents a vivid comparative analysis of the top 9 generative artificial intelligence (AI) tools, namely ChatGPT, Perplexity AI, YouChat, ChatSonic, Google's Bard, Microsoft Bing Assistant, HuggingChat, Jasper AI, and Quora's Poe, paying attention to the Pros and Cons each of the AI tools presents. This comparative analysis shows that the generative AI tools have several Pros that outweigh the Cons. Further, we explore the transformative impact of generative AI in Natural Language Processing (NLP), focusing on its integration with search engines, privacy concerns, and ethical implications. A comparative analysis categorizes generative AI tools based on popularity and evaluates challenges in development, including data limitations and computational costs. The study highlights ethical considerations such as technology misuse and regulatory challenges. Additionally, we delved into AI Planning techniques in NLP, covering classical planning, probabilistic planning, hierarchical planning, temporal planning, knowledge-driven planning, and neural planning models. These planning approaches are vital in achieving specific goals in NLP tasks. In conclusion, we provide a concise overview of the current state of generative AI, including its challenges, ethical considerations, and potential applications, contributing to the academic discourse on human-computer interaction.  "
NLP (cs.CL),2024,17,"The impact of AI-enhanced natural language processing tools on writing proficiency: an analysis of language precision, content summarization, and creative writing facilitation",43,N/A,https://www.semanticscholar.org/paper/e3128f9b52ecfa52f167d5a0b4a28dd9860e4558,Dan Zhao,No Abstract
NLP (cs.CL),2024,18,"Artificial Intelligence-Driven Corporate Finance: Enhancing Efficiency and Decision-Making Through Machine Learning, Natural Language Processing, and Robotic Process Automation in Corporate Governance and Sustainability",41,N/A,https://www.semanticscholar.org/paper/f8db0326341c6f40149072f3549546407ac914dc,"N. Rane, Saurabh P. Choudhary, Jayesh Rane","This research paper delves into the transformative possibilities of Artificial Intelligence (AI) within corporate finance, specifically focusing on its role in improving efficiency and decision-making processes. Through the utilization of machine learning, natural language processing (NLP), and robotic process automation (RPA), AI introduces innovative methods for enhancing corporate governance and sustainability practices. In the contemporary business landscape, corporations encounter mounting pressure to streamline operations while simultaneously addressing concerns regarding environmental, social, and governance (ESG) issues. Conventional finance methodologies often struggle to efficiently handle large volumes of data and extract actionable insights promptly. However, AI presents a shift in paradigm by enabling automated data analysis, recognizing patterns, and conducting predictive modeling, thus enabling finance professionals to make data-informed decisions swiftly and accurately. Machine learning algorithms play a pivotal role in detecting patterns and correlations within financial data, facilitating proactive risk management and strategic planning. Additionally, NLP technologies facilitate the extraction of valuable insights from unstructured data sources like regulatory filings, news articles, and social media, thereby enabling informed decision-making in corporate governance and sustainability endeavors. Moreover, RPA simplifies repetitive tasks and workflows, thereby reducing operational expenses and freeing up human resources for more strategic pursuits. Through the automation of routine processes such as data entry, reconciliation, and reporting, RPA enhances operational efficiency and ensures adherence to regulatory standards. Through the adoption of AI technologies, corporations can unlock novel avenues for innovation, optimize resource allocation, and promote sustainable growth within today's dynamic business milieu."
NLP (cs.CL),2024,14,Improving triage performance in emergency departments using machine learning and natural language processing: a systematic review,38,N/A,https://www.semanticscholar.org/paper/fbb7a8a84bfefb0e805004afddbd21417e8bd813,Bruno Matos Porto,"In Emergency Departments (EDs), triage is crucial for determining patient severity and prioritizing care, typically using the Manchester Triage Scale (MTS). Traditional triage systems, reliant on human judgment, are prone to under-triage and over-triage, resulting in variability, bias, and incorrect patient classification. Studies suggest that Machine Learning (ML) and Natural Language Processing (NLP) could enhance triage accuracy and consistency. This review analyzes studies on ML and/or NLP algorithms for ED patient triage. Following Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) guidelines, we conducted a systematic review across five databases: Web of Science, PubMed, Scopus, IEEE Xplore, and ACM Digital Library, from their inception of each database to October 2023. The risk of bias was assessed using the Prediction model Risk of Bias Assessment Tool (PROBAST). Only articles employing at least one ML and/or NLP method for patient triage classification were included. Sixty studies covering 57 ML algorithms were included. Logistic Regression (LR) was the most used model, while eXtreme Gradient Boosting (XGBoost), decision tree-based algorithms with Gradient Boosting (GB), and Deep Neural Networks (DNNs) showed superior performance. Frequent predictive variables included demographics and vital signs, with oxygen saturation, chief complaints, systolic blood pressure, age, and mode of arrival being the most retained. The ML algorithms showed significant bias risk due to critical bias assessment in classification models. NLP methods improved ML algorithms' classification capability using triage nursing and medical notes and structured clinical data compared to algorithms using only structured data. Feature engineering (FE) and class imbalance correction methods enhanced ML workflows' performance, but FE and eXplainable Artificial Intelligence (XAI) were underexplored in this field. Registration and funding. This systematic review has been registered (registration number: CRD42024604529) in the International Prospective Register of Systematic Reviews (PROSPERO) and can be accessed online at the following URL: https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=604529. Funding for this work was provided by the National Council for Scientific and Technological Development (CNPq), Brazil."
NLP (cs.CL),2024,12,Medication Recommendation System Based on Natural Language Processing for Patient Emotion Analysis,37,N/A,https://www.semanticscholar.org/paper/85f96bb62e65b01b653f8e1b1f8f2eb4f0233165,"Haotian Zheng, Kangming Xu, Huiming Zhou et al.","Natural Language Processing (NLP) is an interdisciplinary field of computer science, artificial intelligence, and linguistics that focuses on the ability of computers to understand, process, generate, and simulate human language in order to achieve the ability to have natural conversations with humans. The underlying principles of natural language processing are at multiple levels, including linguistics, computer science, and statistics. It involves the study of language structure, semantics, grammar and pragmatics, as well as the statistical analysis and modeling of large-scale corpora. In the process of concrete implementation, it is necessary to process natural language at multiple levels. Based on this, this paper combined deep learning and natural language processing technology to conduct sentiment analysis on patients' comments, so as to recommend drugs that are more suitable for patients, thus achieving accurate drug prescribing and personalized recommendation."
NLP (cs.CL),2024,4,Conformal Prediction for Natural Language Processing: A Survey,36,2405.01976,https://www.semanticscholar.org/paper/346fdbda3ecf4775819fced0cfed78357bee8128,"Margarida M. Campos, António Farinhas, Chrysoula Zerva et al.","Abstract The rapid proliferation of large language models and natural language processing (NLP) applications creates a crucial need for uncertainty quantification to mitigate risks such as Hallucinations and to enhance decision-making reliability in critical applications. Conformal prediction is emerging as a theoretically sound and practically useful framework, combining flexibility with strong statistical guarantees. Its model-agnostic and distribution-free nature makes it particularly promising to address the current shortcomings of NLP systems that stem from the absence of uncertainty quantification. This paper provides a comprehensive survey of conformal prediction techniques, their guarantees, and existing applications in NLP, pointing to directions for future research and open challenges."
NLP (cs.CL),2024,19,Perspectivist approaches to natural language processing: a survey,36,N/A,https://www.semanticscholar.org/paper/bde66085379b50ae4a8f61ef965cbe0d7f50f7fa,"Simona Frenda, Gavin Abercrombie, Valerio Basile et al.",No Abstract
NLP (cs.CL),2024,10,Application of Deep Learning-Based Natural Language Processing in Multilingual Sentiment Analysis,35,N/A,https://www.semanticscholar.org/paper/dc22186c72f07ea3809ecfd839d85d4d758e2568,"Jiabei Liu, Keqin Li, Armando Zhu et al.","This study explores the application of deep learning-based natural language processing technologies in multilingual sentiment analysis. By examining the performance of deep learning models such as BERT and LSTM in multilingual settings, the research demonstrates the effectiveness of these models in cross-linguistic sentiment classification tasks. Despite progress, major challenges in multilingual sentiment analysis include language and cultural differences, insufficient complex context processing, and data imbalance. Future research directions include optimizing the models' contextual understanding abilities, leveraging multilingual data resources, exploring novel neural network architectures, and improving assessment metrics. With these measures, the accuracy and efficiency of multilingual sentiment analysis are expected to be significantly enhanced, further advancing the global application of natural language processing technologies."
NLP (cs.CL),2024,16,Automating financial reporting with natural language processing: A review and case analysis,35,N/A,https://www.semanticscholar.org/paper/008fcac1e149299aee23a25180eb51afc67919a7,"A. Oyewole, Omotayo Bukola, Wilhelmina Afua Addy et al.","In the evolving landscape of financial reporting, the integration of Natural Language Processing (NLP) emerges as a beacon of innovation, promising to redefine the paradigms of accuracy, efficiency, and compliance. This paper embarks on a scholarly expedition to explore the transformative potential of NLP within the realm of financial disclosures, navigating through the intricate interplay of technological advancements and regulatory frameworks. The study meticulously analyzes the application of NLP techniques in automating financial reporting, unraveling the complexities of implementation and the multifaceted challenges therein through a qualitative research design. Through a comprehensive review of the literature and empirical data, the paper illuminates the efficacy of NLP in enhancing the precision and reliability of financial reports while also delving into stakeholders' perceptions regarding its adoption. The findings reveal a significant improvement in reporting efficiency and accuracy, underscored by the strategic importance of addressing implementation hurdles and regulatory considerations. The study culminates in a set of cogent recommendations, advocating for the development of a robust framework for NLP applications in financial reporting, alongside a clarion call for ongoing research into sophisticated NLP models and scalable solutions. In essence, this paper not only charts a course for the future integration of NLP in financial reporting but also stands as a testament to the indelible impact of technological innovation on the financial industry. It beckons the academic and professional communities to forge a collaborative path towards realizing the full potential of NLP, thereby ushering in a new era of transparency and insight in financial disclosures."
NLP (cs.CL),2024,20,Taking adaptive learning in educational settings to the next level: leveraging natural language processing for improved personalization,35,N/A,https://www.semanticscholar.org/paper/e735e328bf8dc08c8a1e77a59ff8faafcd186b3e,"Mathias Mejeh, Martin Rehm",No Abstract
NLP (cs.CL),2024,11,Utilizing Natural Language Processing and Large Language Models in the Diagnosis and Prediction of Infectious Diseases: A Systematic Review,33,N/A,https://www.semanticscholar.org/paper/fb6260c1b072237724006bba9891d1aadf8e5746,"M. Omar, D. Brin, Benjamin S. Glicksberg et al.","Background: Natural Language Processing (NLP) and Large Language Models (LLMs) hold largely untapped potential in infectious disease management. This review explores their current use and uncovers areas needing more attention. Methods: This analysis followed systematic review procedures, registered with PROSPERO. We conducted a search across major databases including PubMed, Embase, Web of Science, and Scopus, up to December 2023, using keywords related to NLP, LLM, and infectious diseases. We also employed the QUADAS-2 tool for evaluating the quality and robustness of the included studies. Results: Our review identified 15 studies with diverse applications of NLP in infectious disease management. Notable examples include GPT-4's application in detecting urinary tract infections and BERTweet's use in Lyme Disease surveillance through social media analysis. These models demonstrated effective disease monitoring and public health tracking capabilities. However, the effectiveness varied across studies. For instance, while some NLP tools showed high accuracy in pneumonia detection and high sensitivity in identifying invasive mold diseases from medical reports, others fell short in areas like bloodstream infection management. Conclusion: This review highlights the yet-to-be-fully-realized promise of NLP and LLMs in infectious disease management. It calls for more exploration to fully harness AI's capabilities, particularly in the areas of diagnosis, surveillance, predicting disease courses, and tracking epidemiological trends."
NLP (cs.CL),2024,13,Autism Detection in Children: Integrating Machine Learning and Natural Language Processing in Narrative Analysis,31,N/A,https://www.semanticscholar.org/paper/3ea0e7905db5e13f38bd54a848b15287c7b3fcfb,"Charalambos Themistocleous, Maria Andreou, Eleni Peristeri","Despite the consensus that early identification leads to better outcomes for individuals with autism spectrum disorder (ASD), recent research reveals that the average age of diagnosis in the Greek population is approximately six years. However, this age of diagnosis is delayed by an additional two years for families from lower-income or minority backgrounds. These disparities result in adverse impacts on intervention outcomes, which are further burdened by the often time-consuming and labor-intensive language assessments for children with ASD. There is a crucial need for tools that increase access to early assessment and diagnosis that will be rigorous and objective. The current study leverages the capabilities of artificial intelligence to develop a reliable and practical model for distinguishing children with ASD from typically-developing peers based on their narrative and vocabulary skills. We applied natural language processing-based extraction techniques to automatically acquire language features (narrative and vocabulary skills) from storytelling in 68 children with ASD and 52 typically-developing children, and then trained machine learning models on the children’s combined narrative and expressive vocabulary data to generate behavioral targets that effectively differentiate ASD from typically-developing children. According to the findings, the model could distinguish ASD from typically-developing children, achieving an accuracy of 96%. Specifically, out of the models used, hist gradient boosting and XGBoost showed slightly superior performance compared to the decision trees and gradient boosting models, particularly regarding accuracy and F1 score. These results bode well for the deployment of machine learning technology for children with ASD, especially those with limited access to early identification services."
NLP (cs.CL),2024,15,RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing,31,2404.19543,https://www.semanticscholar.org/paper/1b7492a4b813052146300fa8c03325c4ad7a0a25,"Yucheng Hu, Yuxing Lu","Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge. To mitigate these, recent methodologies have integrated information retrieved from external resources with LLMs, substantially enhancing their performance across NLP tasks. This survey paper addresses the absence of a comprehensive overview on Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an in-depth examination of their paradigm, evolution, taxonomy, and applications. The paper discusses the essential components of RALMs, including Retrievers, Language Models, and Augmentations, and how their interactions lead to diverse model structures and applications. RALMs demonstrate utility in a spectrum of tasks, from translation and dialogue systems to knowledge-intensive applications. The survey includes several evaluation methods of RALMs, emphasizing the importance of robustness, accuracy, and relevance in their assessment. It also acknowledges the limitations of RALMs, particularly in retrieval quality and computational efficiency, offering directions for future research. In conclusion, this survey aims to offer a structured insight into RALMs, their potential, and the avenues for their future development in NLP. The paper is supplemented with a Github Repository containing the surveyed works and resources for further study: https://github.com/2471023025/RALM_Survey."
NLP (cs.CL),2024,1,Natural language acquisition and gestalt language processing: A critical analysis of their application to autism and speech language therapy,13,N/A,https://www.semanticscholar.org/paper/81efda0e68a253e1a70970fe8bed8e0444b21025,"Tiffany L Hutchins, Sophie E. Knox, E. C. Fletcher","Background and Aim Recently, there has been a lot of interest surrounding the term gestalt language processor (GLP) which is associated with Natural Language Acquisition (NLA): a protocol intended to support the language development of autistic people. In NLA, delayed echolalia is presumed raw source material that GLPs use to acquire language in a stage-like progression from delayed echolalia to spontaneous speech. The aim of this article is to evaluate NLA in light of relevant literatures to allow scrutiny of NLA claims. Main contributions First, we review the notion of gestalt language and situate it in the broader literature on language styles to update understanding of its significance. We then review the links from gestalt language processing to autism and identify definitional and conceptual problems and clarify the construct ‘episodic memory’. We discuss the ‘raw material view of delayed echolalia’ and identify theoretical and empirical shortcomings. Finally, we review Blanc’s language stages and their accompanying assessment and language support recommendations and challenge their validity. Conclusions & Implications The term ‘gestalt language processor’ is definitionally and conceptually troubled, the assertion that autistic people are GLPs is misleading and unhelpful, and evidence is lacking that GLP represents a legitimate clinical entity. The theoretical basis of NLA lacks empirical support. NLA stages are implausible and their accompanying assessment and support recommendations lack justification. We recommend the use of alternate, individualized, theoretically-sound, evidence-based, neurodiversity-affirming supports that are sensitive and responsive to the heterogeneity that defines autism."
Networking (cs.NI),2022,1,Effect of Balancing Data Using Synthetic Data on the Performance of Machine Learning Classifiers for Intrusion Detection in Computer Networks,80,2204.00144,https://www.semanticscholar.org/paper/f37ccad83af05f955b6df2158c5072561213a1ad,"Ayesha S. Dina, A. Siddique, D. Manivannan","Attacks on computer networks have increased significantly in recent days, due in part to the availability of sophisticated tools for launching such attacks as well as the thriving underground cyber-crime economy to support it. Over the past several years, researchers in academia and industry used machine learning (ML) techniques to design and implement Intrusion Detection Systems (IDSes) for computer networks. Many of these researchers used datasets collected by various organizations to train ML classifiers for detecting intrusions. In many of the datasets used in training ML classifiers in such systems, data are imbalanced (i.e., not all classes had equal number of samples). ML classifiers trained with such imbalanced datasets may produce unsatisfactory results. Traditionally, researchers used over-sampling and under-sampling for balancing data in datasets to overcome this problem. In this work, in addition to random over-sampling, we also used a synthetic data generation method, called Conditional Generative Adversarial Network (CTGAN), to balance data and study their effect on the performance of various widely used ML classifiers. To the best of our knowledge, no one else has used CTGAN to generate synthetic samples to balance intrusion detection datasets. Based on extensive experiments using widely used datasets NSL-KDD and UNSW-NB15, we found that training ML classifiers on datasets balanced with synthetic samples generated by CTGAN increased their prediction accuracy by up to 8% and improved their MCC score by up to 13%, compared to training the same ML classifiers over imbalanced datasets. We also show that this approach consistently performs better than some of the recently proposed state-of-the-art IDSes on both datasets. Our experiments also demonstrate that the accuracy of some ML classifiers trained over datasets balanced with random over-sampling decline compared to the same ML classifiers trained over original imbalanced dataset."
Networking (cs.NI),2022,11,A Novel Model Based on Window-Pass Preferences for Data Emergency Aware Scheduling in Computer Networks,27,N/A,https://www.semanticscholar.org/paper/2429714fc77cd6f71e85e9c87b12e7247d50ae12,"M. Jemmali, Mohsen Denden, Wadii Boulila et al.","The breakdown of vital communication infrastructures is one of the most common characteristics of all disasters. It can cause severe communication problems such as time delays and data loss, which cause deterioration in system performance. New techniques are needed to cope with such situations, many of which have been made possible due to the ongoing evolution of artificial intelligence technologies. In this study, we consider the case of a network consisting of several router allocation problems in situations of high priority and emergency data allocation. A novel network component called the scheduler is introduced and window constraints for routers are imposed. To solve the studied problem, four different algorithms are developed in this work. These algorithms were then applied in a particular scenario consisting of several routers and 2200 instances. In terms of the gap and running time, the proposed algorithms provide acceptable results. The best performances were achieved using the critical packet algorithm for 80% of instances with an average gap value of 0.009 and an average time of 0.209 s."
Networking (cs.NI),2022,2,Simulation-Based Learning via Cisco Packet Tracer to Enhance the Teaching of Computer Networks,23,N/A,https://www.semanticscholar.org/paper/4467d57c9c4629eeadcad1a8904d8c78f07543c7,J. Allison,"Teaching and learning computer networks is a crucial part of a computing undergraduates education. However, it is an abstract topic with theory that can be challenging for students to comprehend. Simulation-based learning can be used as a teaching tool to enhance networking-based lecture topics and help students more easily understand and visualise how it really works in a safe, user-friendly environment. One such simulation tool, Cisco Packet Tracer, can be used to good effect, and this paper reports on the practical implementation of the tool as identified in existing literature. Additionally, this paper discusses how Packet Tracer was utilised as part of a UK based first year undergraduate module 'Computers and Security', and details the content of nine practical sessions, whilst also identifying the main benefits and challenges of their implementation from a practitioner perspective. It was found that while Packet Tracer can be an additional benefit to augment the teaching of networking concepts, there are limitations and challenges which educators must be aware of if implementing the tool. The paper therefore concludes with providing recommendations which should help educators and curriculum designers in creating and delivering more effective and interactive networking sessions."
Networking (cs.NI),2022,3,Learning to Configure Computer Networks with Neural Algorithmic Reasoning,22,2211.01980,https://www.semanticscholar.org/paper/dcf3caaf797f4496241c7375c0e8ede8cc5616f1,"Luca Beurer-Kellner, Martin T. Vechev, Laurent Vanbever et al.","We present a new method for scaling automatic configuration of computer networks. The key idea is to relax the computationally hard search problem of finding a configuration that satisfies a given specification into an approximate objective amenable to learning-based techniques. Based on this idea, we train a neural algorithmic model which learns to generate configurations likely to (fully or partially) satisfy a given specification under existing routing protocols. By relaxing the rigid satisfaction guarantees, our approach (i) enables greater flexibility: it is protocol-agnostic, enables cross-protocol reasoning, and does not depend on hardcoded rules; and (ii) finds configurations for much larger computer networks than previously possible. Our learned synthesizer is up to 490x faster than state-of-the-art SMT-based methods, while producing configurations which on average satisfy more than 93% of the provided requirements."
Networking (cs.NI),2022,4,Analysis of Botnet Attack Communication Pattern Behavior on Computer Networks,21,N/A,https://www.semanticscholar.org/paper/4d020044e6c94377d8da10b273c5eee4901c4a35,Unknown,No Abstract
Networking (cs.NI),2022,7,A novel method for intrusion detection in computer networks by identifying multivariate outliers and ReliefF feature selection,18,N/A,https://www.semanticscholar.org/paper/e89b0ef5451dc756aa9a4b5edf94bb7e926c95d2,"Birnur Uzun, Serkan Balli",No Abstract
Networking (cs.NI),2022,8,Artificial intelligence in computer networks,18,N/A,https://www.semanticscholar.org/paper/91fba41373693e7dc2d8a91d07d1e91999f11eb8,T. A. Jaber,"Artificial Intelligence (AI) has been defined as a modern and intense scientific topic that enables computer-based systems or embedded systems to divide and solve problems by simulating complex biological procedures that are represented by specific algorithms along with (learning, reasoning, as well as self-correction). The present study provides a detailed assessment and review of applications of various artificial intelligence approaches for the purpose of improving the general efficiency of optical communication structures and networks and network systems in general. Using the AI-based approaches has been researched at first in the applications that are associated with the optic transmissions, beginning by characterizing and operating the additives of the network for the monitoring of the performance, estimation of transmission quality and nonlinearities mitigation. Ultimately, this study has provided as well a summary of advantages and issues in the optical networks in which artificial intelligence is expected to have an important impact on near future and which represent areas of research expected to be popular in this discipline."
Networking (cs.NI),2022,5,Employing Deep Ensemble Learning for Improving the Security of Computer Networks Against Adversarial Attacks,14,2209.12195,https://www.semanticscholar.org/paper/b32460311b391fd065337eae93ecf84508d9740f,"Ehsan Nowroozi, Mohammadreza Mohammadi, E. Savaş et al.","In the past few years, Convolutional Neural Networks (CNN) have demonstrated promising performance in various real-world cybersecurity applications, such as network and multimedia security. However, the underlying fragility of CNN structures poses major security problems, making them inappropriate for use in security-oriented applications, including computer networks. Protecting these architectures from adversarial attacks necessitates using security-wise architectures that are challenging to attack. In this study, we present a novel architecture based on an ensemble classifier that combines the enhanced security of 1-Class classification (known as 1C) with the high performance of conventional 2-Class classification (known as 2C) in the absence of attacks. Our architecture is referred to as the 1.5-Class (cmb-classifier) classifier and is constructed using a final dense classifier, one 2C classifier (i.e., CNNs), and two parallel 1C classifiers (i.e., auto-encoders). In our experiments, we evaluated the robustness of our proposed architecture by considering eight possible adversarial attacks in various scenarios. We performed these attacks on the 2C and cmb-classifier architectures separately. The experimental results of our study showed that the Attack Success Rate (ASR) of the I-FGSM attack against a 2C classifier trained with the N-BaIoT dataset is 0.9900. In contrast, the ASR is 0.0000 for the cmb-classifier."
Networking (cs.NI),2022,6,Intrusion Detection in Computer Networks using Optimized Machine Learning Algorithms,13,N/A,https://www.semanticscholar.org/paper/f2b2d0b5a1d92f8fb9c6286c81c5fd22a54c66b3,Abdullah Asım Yılmaz,"Intrusion detection systems (IDSs) are employed to maintain computer networks from cyber attacks. Here, the aim is to detect intrusions once the data is transmitted across the internet. Intrusion detection methods (IDMs) developed in the literature are commonly focused on data mining, statistical and machine learning-based analysis of anomaly situations. In this paper, we suggested machine learning based methodology to detect intrusions in computer networks. The proposed method comprises four main phases, namely, preprocessing, feature selection, parameter optimization and classification. Most significant features are selected by utilizing the Correlation Based Feature Selection. For classification Random Tree, AdaBoost, K-Nearest Neighbor (KNN), Support-vector machine (SVM) are used while for parameter optimization particle swarm optimization is employed. The proposed method was tested on two extensive datasets, namely NSL-KDD and CIC-DDOS2019. The experimental results reveal that the proposed method can effectively classify intrusions with a high detection rate and that it outperforms the other machine learning techniques."
Networking (cs.NI),2022,9,"Cloud Service for Protecting Computer Networks of Enterprises Using Intelligent Hardware and Software Devices, Based on Raspberry Pi Microcomputers",12,N/A,https://www.semanticscholar.org/paper/0d2a3d9c444c2b43315d1dd2f6ac9d8c781063b7,"A. Ospanova, A. Zharkimbekova, Lazzat Kussepova et al.",": This paper describes the development of a unified cloud service, for protecting and monitoring corporate computer networks and SOHO-class networks, with intelligent mobile software and hardware clients, based on the Raspberry Pi type microcomputer. It is planned to develop an intelligent algorithm, that performs automatic decision-making and provides recommendations, when threats are detected in the network, to finalize software and hardware, taking into account the requirements of mobility and integrability, within the cloud service. The intelligent data processing algorithm, implemented on these devices, will be based on the developed linguistic processor and the procedure of automatic assessment of network threats. Implementation of this idea consists in the development of a web service with a replenished database of threats, incidents at the nodes of a computer network and standard solutions, a system for quantitative and qualitative risk assessment, as well as, in the subsequent integration of the described intelligent mobile software and hardware device into this web application. Thus, the developed cloud service, for protecting and monitoring computer networks, will be a centralized toolkit for the joint fight against network attacks, identifying vulnerabilities in the configuration of enterprises’ networks, for using and building up a database of investigated incidents and solutions, taking into account the permissible degree of data disclosure. This work presents a developed sequential plan for the implementation of this task. Attempts have been made to substantiate, theoretically, the feasibility of implementing the described task. The authors describe the relevant tools that are currently available."
Networking (cs.NI),2022,10,The Impact of a Digital Escape Room focused on HTML and Computer Networks on Vocational High School Students,10,N/A,https://www.semanticscholar.org/paper/8cd20cca660dcadd768302cbcc0c873b966002cc,"L. Huraj, R. Hrmo, Marianna Sejutová Sejutová Hudáková","Today, students live in a world surrounded by technology and traditional education methods are no longer very attractive to them. Applying the concept of a digital educational escape room to teaching can help increase students’ interest in the subject. In an escape room, the players search for clues, complete tasks, and solve polymorphic puzzles, working together to escape the room within a certain time limit. This article presents the use of a digital escape room on third-year students in the field of computer network mechanics at a secondary vocational school. The aim of this study was to determine the effects of implementing an escape room focused on HTML and computer networks on third-year computer network mechanics students and to assess the students’ levels of perception of the game. Although the experiment did not confirm an increase in students’ cognitive abilities, the quantitative analysis confirms a significant increase in the motivation, engagement, and satisfaction of students in secondary vocational schools focusing on technical vocational subjects. Qualitative analysis provides a better understanding of these results and supports the conclusion that using a digital educational escape room is enjoyable for students, and leads to problem-solving skills and teamwork."
Networking (cs.NI),2022,12,Feature Ranking using Statistical Techniques for Computer Networks Intrusion Detection,7,N/A,https://www.semanticscholar.org/paper/7416e1e9d6e6f0775dfca6abc0aedb8574ea7f84,"Yash Sharma, Somya Sharma, Anshul Arora","Nowadays with the enlargement of the utility of computer networks, the danger of getting our personal information being misused has also grown rapidly. According to the [1] 2022 Cyber Threat Report released by SonicWall, the health care industry faced a 755% increase in the attacks worldwide and Governments witnessed a 1,885% hike in attacks in 2021. Moreover, the threats due to intrusions are becoming more and more complex and difficult to detect. This research study intends to observe and inspect the network traffic of normal as well as intrusions and to perceive the network traffic features that can distinguish normal traffic from intrusions traffic. In order to extract distinguishing features, the proposed research study utilizes the statistical techniques of ANOVA and the Chi-Square test to order and line up the network traffic features. The experimental results demonstrate that the feature Bytes Sent is ranked at the top when the ANOVA test is applied over the data. In the cases where Chi-Square test is applied over normal and malware data, the features bytes sent and bytes received are ranked at the top respectively. Such ranking can help build an effective intrusion detection system."
Networking (cs.NI),2022,13,Mathematical Modelling of Malware Intrusion in Computer Networks,7,N/A,https://www.semanticscholar.org/paper/0d67169d1d12ef481656fe7975da6c4831bc661a,Andon Lazarov,"Abstract Malware attacks cause great harms in the contemporary information systems and that requires analysis of computer networks reaction in case of malware impact. The focus of the present study is on the analysis of the computer network’s states and reactions in case of malware attacks defined by the susceptibility, exposition, infection and recoverability of computer nodes. Two scenarios are considered – equilibrium without secure software and not equilibrium with secure software in the computer network. The behavior of the computer network under a malware attack is described by a system of nonhomogeneous differential equations. The system of the nonhomogeneous differential equations is solved, and analytical expressions are derived to analyze network characteristics in case of susceptibility, exposition, infection and recoverability of computer nodes during malware attack. The analytical expressions derived are illustrated with results of numerical experiments. The conception developed in this work can be applied to control, prevent and protect computer networks from malware intrusions."
Networking (cs.NI),2022,14,Higher Order Thinking Skills (HOTs) based Assessment for Learning: A Model for Computer Networks Learning in Vocational School,7,N/A,https://www.semanticscholar.org/paper/9229c9ca9dad9d2f56e28eb29e40f5c24a865516,"Muhammad Yassir, Husain Syam, Hasanah Nur","Vocational High School is a kind of school that has a strategic role in fulfilling labors. One of the competencies that graduates of Vocational High School must have is the Higher Order Thinking Skills (HOTS). Many graduates of Vocational High School are not absorbed by industry because they do not have HOTS. This study aims to develop a HOTS-based Assessment for Learning (AFL) model that can be applied to learning computer networks for vocational students. This research is a development research using the modified model of Hopkins and Clark - Analysis, Design, Development, Implementation, and Evaluation (HC-ADDIE), which is a collaboration and modification of research, development, and diffusion model of the Hopkins and Clark - Instructional System Design - Analysis, Design, Development, Implementation, and Evaluation (HC-ISD ADDIE), and Classroom Action Research (CAR). The development stage includes designing a prototype model, validating the model, testing legibility, training teachers / observers, and implementing limited and expanded trials. The results showed that the HOTS-based AFL model of computer network learning for vocational students was successfully developed through the HC-ADDIE modified model."
Networking (cs.NI),2022,16,Machine Learning for Securing Traffic in Computer Networks,6,N/A,https://www.semanticscholar.org/paper/d20e3a56fd5b6683a66c14d073c8d436d923b1da,"Ahmed Banimustafa, M. Baklizi, Khalaf Khatatneh","—Computer network attacks are among the most significant and common threats against computer-wired and wireless communications. Intrusion detection technology is used to secure computer networks by monitoring network traffic and identifying attacks. In this paper, we investigate and evaluate the application of four machine learning classification algorithms for identifying attacks that target computer networks: DDoS, Brute Force Web, and SQL Injection attacks, in addition to Benign Traffic. A public dataset of 80 features was used to build four machine learning models using Random Forest, Logistic Regression, CN2, and Neural Networks. The constructed models were evaluated based on 10-fold cross-validation using Classification Accuracy (CA), Area under the Curve (AUC), F1, Recall, Specificity, and Sensitivity metrics in addition to Confusion Matrix, Calibration, Lift, and ROC plots. The Random Forest model achieved 98% in the CA score and 99% in the AUC score, while the Logistic regression achieved 90% in the CA score and 98% in the AUC score."
Networking (cs.NI),2022,17,Modelling Activity of a Malicious User in Computer Networks,5,N/A,https://www.semanticscholar.org/paper/71e94d19a5bdd6d3b0e1f15b09305c07500a07c7,"Andon Lazarov, P. Petrova","Abstract In the present study, an extended classification of Internet users penetrating in computer networks and a definition of the motivation as a psychological and emotional state and main prerequisites for modelling of network intruder’s activity are suggested. A mathematical model as a quadratic function of malicious individual’s behavior and impact on the computer network based on three quantified factors, motivation, satisfaction and system protection is developed. Numerical simulation experiments of the unauthorized access and its effect onto the computer network are carried out. The obtained results are graphically illustrated and discussed."
Networking (cs.NI),2022,20,Applying Project-based Learning to Improve Computer Networks Courses: An Experience Report,4,N/A,https://www.semanticscholar.org/paper/1cee98b55bd5b121bfdb7d45e8a0f84d3ebcd2dd,"Zheng Song, Nidhi Shah, Jinhua Guo et al.","Project-based learning (PjBL) has been increasingly adopted in computer science courses to improve students’ engagement and learning outcomes. Although a computer networks course is in great need of a PjBL course module, no such module is available due to the huge gap between PjBL’s design requirements and the current structure and content of the course. This paper introduces a novel PjBL module for a computer networks course, which challenges the students with a real world problem of developing the communication system for a smart lock. Following the PjBL design principles, we devise several scaffolding activities and assignments, which can be integrated into a semester-long computer networks course. We test ran the PjBL module in both undergraduate- and graduate-level computer networks courses. Our preliminary evaluation results show that the proposed PjBL module is well received by the students and helps improve their learning outcomes."
Networking (cs.NI),2022,15,Training on the Use of GNS3 in Computer Networks Learning for Vocational High School Teachers,3,N/A,https://www.semanticscholar.org/paper/bcdb3a7bbbb4f2929faf29b70b5a56911002db07,"Amrizal, Agus Nur Khomarudin, Jamaluddin et al.","The development of Science and Technology (IPTEK), especially information technology, has had a positive impact on all aspects of human life, including education aspect. The teaching and learning process is the core of the whole educational process. The quality of teaching and learning is determined by the teacher and the students themselves as subjects or actors in the process. Therefore, a teacher is required to always improve skills through learning activities/seminars/training related to their competence field. This Community Service Program (CSP) used mentoring methods in its implementation, while the approaches used were classical and individual approach. This CSP activity has succeeded in providing debriefing and training for teachers to install computer networks using the GNS3 software. The training participants in this CSP were teachers of SMKN 1 Suliki, Lima Puluh Kota Regency and SMKN 1 Ampek Angkek, Agam Regency, West Sumatra. To find out the effectiveness of this CSP activity, a questionnaire was used as an assessment instrument. Based on the tabulation results, it was found that this CSP activity obtained an average value of 82.71% in the good category. Even though this activity has obtained good results from CSP participants, consistent efforts are needed to increase the effectiveness of CSP implementation for the next period. Efforts to increase the effectiveness of CSP implementation are also based on several suggestions and input submitted by CSP participants through an effectiveness questionnaire. The suggestions and input submitted by several participants became evaluation material for the CSP implementation team of the Computer Engineering Study Program, Payakumbuh State Agricultural Polytechnic in the future."
Networking (cs.NI),2022,18,Detection of zero‐day attacks in computer networks using combined classification,3,N/A,https://www.semanticscholar.org/paper/2d0eb6abbe4df2a88aec52e3f82a58b923ba0839,"Hamid Gavari Bami, Elaheh Moharamkhani, Behrouz Zadmehr et al.","In today's world, many public and private services are provided virtually on the Internet. Due to the increasing dynamism and development of computer networks, intrusion detection systems, as one of the hottest topics in network security, has become an attractive area of research for researchers. The intrusion detection system tries to categorize the activity of the connections into two categories, normal and abnormal. In intrusion detection system, each connection is described based on a set of features, and decisions about whether that connection is normal or abnormal are made using those features. The act of determining the norm or abnormality of a connection is called classification. In this article, a method based on combined classification is proposed to detect zero‐day attacks. One of the most important innovations in this method is using a new version of the GRASP feature selection algorithm, which is used to diversify the base classifiers. In this method, an attempt is made to produce a subset of different features that have high accuracy; and variety to be used in the assembly stage. Experimental results showed that the method used to create feature subsets has high quality."
Networking (cs.NI),2022,19,ANALYSIS OF THE PROBLEM OF MULTIVALUED OF CLASS LABELS ON THE SECURITY OF COMPUTER NETWORKS,3,N/A,https://www.semanticscholar.org/paper/41844f778308002de82caa19851f9715447d1d6a,D. I. Rakovskiy,"Modern computer networks have a complex infrastructure that requires constant monitoring to detect anomalous conditions that can cause malfunctions, which is unacceptable for large-scale distributed networks. An important problem in the intelligent processing of syslog data is the existence of multilabel datasets. Among the Russian language scientific publications, the problem under consideration in the context of information security of computer networks is not presented. The purpose of the research work is to increase the security of computer networks through the use of multi-label learning methods in solving the problem of classifying system log class labels. In this paper, a comparative analysis of single-label and multi-label classifiers in a computational experiment on the Mean accuracy metric was carried out. According to the results of the analysis, 80% of single-label classifiers were inferior in classification accuracy according to the Mean accuracy multi-label metric to their counterparts, which may indicate a strong influence of multi-label class labels on the models under consideration. The considered structure of experimental data in a tabular form is influenced by the multi-label problem much more strongly than it can be estimated by a standard frequency check, which actualizes further research in this direction."
Networking (cs.NI),2023,2,Machine learning empowered computer networks,55,N/A,https://www.semanticscholar.org/paper/b7e88b9f348e15cc415fc13c3859df480394b98b,"T. Cerquitelli, M. Meo, M. Curado et al.",No Abstract
Networking (cs.NI),2023,1,The OSI Model: Overview of All Seven Layers of Computer Networks,27,N/A,https://www.semanticscholar.org/paper/383e150cc01e89005d285ff3cd5b81e104bd2a00,"Sushmita Biya, Renuka Uday Kotwal","The International Organization for Standardization, better known by its abbreviation OSI Model, is an organization that establishes the fundamental communication protocols for computer networks.  • We refer to the OSI Model in multiple places since the problems fall into one of its seven models.  • The highest level of abstraction in the OSI architecture is the OSI Reference Model.  • The primary building sections used to create the network model are initially described in the release."
Networking (cs.NI),2023,3,A Comprehensive Survey on Ensemble Learning-Based Intrusion Detection Approaches in Computer Networks,13,N/A,https://www.semanticscholar.org/paper/53255a1c1d6fac9e17acb271b73c47926c788314,"T. J. Lucas, Inaê Soares De Figueiredo, C. Tojeiro et al.","Machine learning algorithms present a robust alternative for building Intrusion Detection Systems due to their ability to recognize attacks in computer network traffic by recognizing patterns in large amounts of data. Typically, classifiers are trained for this task. Together, ensemble learning algorithms have increased the performance of these detectors, reducing classification errors and allowing computer networks to be more protected. This research presents a comprehensive Systematic Review of the Literature where works related to intrusion detection with ensemble learning were obtained from the most relevant scientific bases. We offer 188 works, several compilations of datasets, classifiers, and ensemble algorithms, and document the experiments that stood out in their performance. A characteristic of this research is its originality. We found two surveys in the literature specifically focusing on the relationship between ensemble techniques and intrusion detection. We present for the last eight years covered by this survey a timeline-based view of the works studied to highlight evolutions and trends. The results obtained by our survey show a growing area, with excellent results in detecting attacks but with needs for improvement in pruning for choosing classifiers, which makes this work unprecedented for this context."
Networking (cs.NI),2023,4,Real-Time Monitoring and Management of Hardware and Software Resources in Heterogeneous Computer Networks through an Integrated System Architecture,11,N/A,https://www.semanticscholar.org/paper/f23117a58f1ef1b1a71d108225561beb730696c9,"Costel Aldea, R. Bocu, R. Solca","The theoretical and practical progress that has occurred in the field of computer networks during the past fifteen years has enhanced the economical efficiency and social relevance of related real-world use cases. Nevertheless, this ubiquitous usage has also introduced numerous security risks. Therefore, monitoring hardware and software resources represents one of the main instruments used in order to prevent potential attacks and to ensure the security and reliability of a network. Various solutions have been reported in the related scientific literature. In essence, most of the existing approaches are not suitable to implement a real-time hardware monitoring and management solution, particularly in heterogeneous networks. Therefore, the main contribution of this paper is represented by an architectural and implementational model, which is effective in order to build an interconnected system that can help system and network administrators to secure a network. This requirement is met by considering symmetrical design and implementation features related to various operating systems. Thus, the existing symmetrical relationships among identified parameters allow for the data to be wrapped into the same custom network packages, which are transported over the communication medium or are stored using the same data structures or tables. The system has been thoroughly assessed considering several real-world use case scenarios, and the results demonstrate that the proposed model can be applied to software-defined networks, which can be protected by relevant intrusion detection systems (IDS)."
Networking (cs.NI),2023,5,Exploring The Effectiveness of Artificial Intelligence in Detecting Malware and Improving Cybersecurity in Computer Networks,7,N/A,https://www.semanticscholar.org/paper/10a6ca4be942e4ce9b923a50327c0082213e7fa9,"K. Komarudin, Isma Elan Maulani, Tedi Herdianto et al.","Malware, in particular, has been identified as a major cy-bersecurity challenge due to its ability to infiltrate computer networks, steal sensi-tive data, and cause major damage to computer systems. The purpose of this study was to explore the effectiveness of artificial in-telligence in detecting malware and improving cybersecurity in computer net-works. Success rate in detecting and preventing malware attacks on computer networks using AI-based methods. The time it takes to detect and prevent malware attacks on computer net-works using AI-based cyber protection methods. Furthermore, the selection of two types of malware that are often found on computer networks, namely Trojans and Worms, and data sampling was then test-ed on a simulation system. In this study, three different AI techniques were applied, namely Support Vector Machine, Neural Network , and Decision Tree to detect malware on computer networks."
Networking (cs.NI),2023,7,An Evaluation of Time-Series Anomaly Detection in Computer Networks,5,N/A,https://www.semanticscholar.org/paper/e61043b53bb9fbbb5fd975d2ad1639c544bcc5e5,"Hong Nguyen, Arash Hajisafi, Alireza Abdoli et al.","One critical issue in any network systems is failure detection. Failures not only impact the source network but also propagate through other communicating networks due to the butterfly effect, making root causing of failures even more challenging. Therefore, the necessity to detect failures and anomalies in computer networks is fundamental. Given the nature of computer networks, data is received in a time-series format where each time-point has temporal dependencies on others. As a result, time-series analysis stands out as a potential approach to deal with the task of network anomaly detection. In this paper, we conduct studies on multivariate time series anomaly detection, varying from traditional machine learning techniques to deep learning models. We show that the choice of models is not as important as the choice of pre-processing techniques. Interestingly, non-linear normalization can boost the performance of deep detectors by around 20% in terms of F1 score and balance the preference of deep detectors for specific types of anomalies. We also study the bias of anomaly types to deep detectors, time-performance trade-offs, shortage of data, and effects of weakly labeled data on both synthetic and realworld datasets to fill out the missing insights in the literature."
Networking (cs.NI),2023,6,Hamming Code: An Analysis of its Reliability and Efficiency in Computer Networks,4,N/A,https://www.semanticscholar.org/paper/272299c079d26874c914a9b0a627b5fd0c035971,"N. H. Sabbry, A. Levina","Hamming code and Extended Hamming code are linear error-correcting codes used for detecting and correcting errors in digital data transmission. They help in maintaining data integrity and reliability by detecting and correcting errors introduced during transmission in various communication systems, including computer networks, storage devices, digital communication channels and other applications. This paper aims to analyze the reliability and efficiency of using of these codes for the purpose of detecting and correcting errors within computer networks. The performance of these codes was tested by developing a program in two steps: one for Hamming Code, and the other for Extended Hamming Code. Both codes were designed to test their error detection and correction capabilities under different scenarios. This study offers a detailed analysis of the strengths and limitations of Hamming Code and Extended Hamming Code in relation to error detection and correction, which shed light on why communication systems extensively rely on this type of coding, and how it significantly improves their dependability and effectiveness."
Networking (cs.NI),2023,8,MODELING AND ANALYSIS OF THE CHARACTERISTICS OF MULTICHANNEL AND MULTI-NODE COMPUTER NETWORKS WITH PRIORITY SERVICE,3,N/A,https://www.semanticscholar.org/paper/f966d79eb0ff3a49a8d6880c516b8690a34e191a,"Z. Huseynov, Mahil Isa Mammadov, Togrul Ismayılov","The subject of the research is modeling and analysis of the characteristics of multichannel and multi-node computer networks with priority services. The work is devoted to the study of the qualitative indicators of the functioning of computer networks with priority service. In this work, mathematical models are developed that make it possible to assess the quality of functioning of modern computer networks, taking into account the number of channels, waiting places in network nodes and the number of network nodes. The proposed methods for calculating the probability of failures and the probability of timely delivery of a stream of requests make it possible to determine the real values of the qualitative indicators of the functioning of computer networks and are suitable for both designed and operating computer networks. The proposed technique makes it possible to determine the number of packets in the queue and the optimal amount of buffer memory in computer network nodes."
Networking (cs.NI),2023,9,Risk Assessment in Critical Infrastructure Computer Networks (short paper),3,N/A,https://www.semanticscholar.org/paper/6a146b5e4eae11a25473279c0441de355eaad99e,"I. Zhukov, Tetiana Okhrimenko, Sergii Balakin et al.",No Abstract
Networking (cs.NI),2023,10,Exploring the Vulnerabilities and Countermeasures of SSL/TLS Protocols in Secure Data Transmission Over Computer Networks,2,N/A,https://www.semanticscholar.org/paper/0ae9b20a3255ca1e67bf7d7f036c86197f13f2d9,"Fidan Bozkurt, Mustafa Kara, Muhammed Ali Aydın et al.","The expansion of computer networks and the increase in information sharing over the internet platform have raised the issue of data security during transmission. SSL (Secure Socket Layer) and its more secure and updated version, TLS (Transport Layer Security), are encryption and authentication protocols designed for secure communication over computer networks. Unfortunately, the SSL/TLS protocol structure established to ensure the security of the transmitted data has become a target for malicious attackers. This article will discuss the versions of the SSL/TLS protocols, their operational structure, weaknesses in the SSL/TLS protocol, the attacks carried out through these weaknesses, and the measures that can be taken against them."
Networking (cs.NI),2023,11,Influence of multi&label class problem of system logs on the security of computer networks,2,N/A,https://www.semanticscholar.org/paper/1e305b9448f4f00461928fbeb37da28e22b413f1,D. I. Rakovskiy,"The security of information circulating in a computer network is related to the security of the supporting infrastructure. An important problem in the intelligent processing of syslog data is the existence of multi-label datasets. Among the Russian-language scientific publications, the problem under consideration in the context of information security of computer networks is not presented. Purpose: increase the security of computer networks by using multi-label learning methods when solving the problem of classifying system logs class labels. Results: A comparative analysis of single-valued and multi-label classifiers was carried out in a computational experiment on the Mean accuracy metric. A non-linear relationship was found between the proportion of experimental data sections containing multi-label class labels and the overall accuracy of data classification. Despite the fact that multilabel plots in the studied experimental data are only 3%, the gain in accuracy reaches 23% according to the specified metric. According to the results of the analysis, 80% of unambiguous classifiers were inferior in classification accuracy according to the Mean accuracy multi-label metric to their analogues, which may signal a strong influence of multi-label class labels on the models under consideration. It is shown that the considered structure of experimental data in a tabular form is affected by the multi-label problem much more strongly than it can be estimated by a standard frequency check, which actualizes further research in this direction. Practical relevance: The practical significance of the results obtained lies in increasing the security of computer networks through the use of a multi-label approach in the classification problem. The tasks of information security solved by multi-label classification may include: the area of monitoring, detection or prevention of violations and computer attacks in computer networks. Discussion: Since the predictive power of frequency testing of the influence of multi-label class label results on the classification results of unambiguous classifiers is low, further research on this topic is planned. It is planned to expand the list of classification quality assessment metrics in future experiments."
Networking (cs.NI),2023,12,THE METHOD OF OPTIMIZING THE DISTRIBUTION OF RADIO SUPPRESSION MEANS AND DESTRUCTIVE SOFTWARE INFLUENCE ON COMPUTER NETWORKS,2,N/A,https://www.semanticscholar.org/paper/e1df8a63abcfb30ffb93f20d9e8674cc53f25214,"S. M. Sholokhov, P. M. Pavlenko, B. A. Nikolaienko et al.","Context. Currently, generalized methodical approaches to the development of scenarios of complex radio suppression and electromagnetic influence of typical special telecommunication systems have been developed. However, during the development of possible cases for the complex application of radio suppression and destructive software influence,the problem of optimizing the resource of these means and its distribution according to the goals of radio suppression and objects of destructive computer influence arose, which has not yet been fully resolved.Especially in the literature known to the authors, there is no method for optimizing the resource distribution of radio and computer influence, used for the development and practical implementation of optimal scenarios of destructive influence on computer networks of enemy military groups in military operations.  Therefore, it is necessary to formulate a problem and develop a method of optimizing the distribution of the resource of radio suppression and destructive software influence for the development of possible scenarios of the enemy’s violation of information exchange in a standart telecommunication network.  Objective. The purpose of the research is to develop a method for optimizing the distribution of the resource of radio suppression and destructive software influence for the development of scenarios of information exchange violations by the enemy in the telecommunications network.  Method.To achieve the purpose of the research, the methods of nonlinear optimization of heterogeneous resource distribution, mass service theory, and expert evaluation were comprehensively applied and developed in the field of modeling of information conflict.  To determine the coefficients of protection of objects from radio-electronic and destructive computer influence, expert evaluation methods are used, in particular, the method of frequencies of preferences of the decision-maker using the Thurstone method. This method requires only one expert (a decision-maker), minimal communication time with him, minimal expert information (full ordering of weighting factors) and can be applied with a small number of evaluated weighting factors.  To solve the problem of optimal distribution of a heterogeneous resource of means of destructive influence, to ensure the value of the multiplicative objective function of an arbitrary form is not less than the given one, the method of successive increments is applied.  To determine the efficiency indicator of information exchange violation, the methods of mass service theory are applied, which allows to formalize special telecommunication systems as a set of mass service systems – subsystems of digital communication and computer networks.  Results. The formulated problem and the entered indicators made it possible to solve the problem of determining the minimum resource of means of destructive influence and their optimal distribution according to the purposes of radio suppression on the objects of destructive program influence in order to achieve the required level of disruption of the efficiency of information exchange in special telecommunication systems.  Conclusions.According to the results of the article, a method for optimizing the distribution of the resource of radio suppression and destructive software influence has been developed for the development of possible scenarios of information exchange violations by the enemy in a typical telecommunications network.The verification of the proposed method was carried out by comparing the theoretical results with the results of simulated modeling of scenarios of violation of the information exchange in the telecommunications network by the enemy."
Networking (cs.NI),2023,13,"Analysis of Determination in Computer-Based Information Systems: The Role of Databases, Computer Networks, and Technological Innovation",2,N/A,https://www.semanticscholar.org/paper/22fcc4612044c7ab5bbf129af6aab70cce5d37b3,"Isnawati Isnawati, Hapzi Ali","Analysis of the Determinants of Computer-Based Information Systems: The Role of Databases, Computer Networks, and Technological Innovation is an analysis of the works that have been published in the subject of ESSB. In order to provide a basis for future research, this article aims to generate hypotheses about the correlation between variables. Academic databases such as Google Scholar, Mendeley, and others are part of the research object. This research utilizes a literature review strategy based on the use of publicly accessible electronic resources, such as e-books and journals. Descriptive qualitative analysis was used. The following are the findings of this analysis: 1) The Role of Database in Determination Analysis of Computer-Based Information System; 2) The Role of Computer Networks in the Determinacy Analysis of Computer-Based Information Systems; 3) The Role of Technological Innovation in the Determination Analysis of Computer-Based Information Systems."
Networking (cs.NI),2023,14,A Comparative Study of Simulated and Hands-on Experiments in Teaching Computer Networks Laboratory Course,2,N/A,https://www.semanticscholar.org/paper/6acf1a3cc2b93545395b11d3b560b62b7680c5c5,"R. C. Kizilirmak, Abylaikhan Kassayev, Ikechi Augustine Ukaegbu","This paper examines the preferences of undergraduate students for two distinct laboratory formats in a computer networks course. The laboratory activities require students to construct various network scenarios to develop their abilities in designing, developing, and assessing computer networks. In each assignment, students construct and evaluate a specific network scenario using a simulation tool, Cisco Packet Tracer, followed by physically executing the same work with network equipment such as PCs, switches, and routers. Through a survey, this study evaluates the students' learning experiences and preferences for the two lab formats. The results indicate that computer simulations are as effective as hands-on work in comprehending the concepts taught in the course. Additionally, the students expressed no particular preference between the two lab formats and found that the formats complemented each other."
Networking (cs.NI),2023,15,Technologies for Detecting Malicious Requests in Computer Networks Based on the DNS Protocol,2,N/A,https://www.semanticscholar.org/paper/df0b4d2d5ee0ebfc8dbed70e51e813565ddc1f56,"O. Leshchenko, Oleksandr Trush, M. Trush et al.",No Abstract
Networking (cs.NI),2023,16,Multi-Label Learning in Computer Networks,1,N/A,https://www.semanticscholar.org/paper/e4532531dc94193964530b1d894260c20ba9c256,"O. Sheluhin, D. Rakovskiy",An important problem of intelligent data processing of system logs is the existence of data sets containing records with multiple associations of class labels. Research objective: To formalize the problem of multi-label classification of experimental data (binary or multi-class) on the example of computer networks (CN) log records. Novelty: consists in illustrating the presence of multi-label class labels in the analysis of system log records generated by the CN. Results: It is shown that the problem of multivaluedness of system log class labels is relevant for the analysis of accessibility and integrity of information circulating in the CN.
Networking (cs.NI),2023,17,Constructing tests methods for the interactive computer networks at the structural-logical level,1,N/A,https://www.semanticscholar.org/paper/9fcc38cb48b17a5d1fe53afaa8401909170e4f99,"M. Miroshnyk, O. Shkil, D. Rakhlis et al.","Synthesizing test sequences methods for interactive computer networks using cyclic, distinguishing and characteristic symbols for the FSM model of a network cell have been developed. A new method for state diagram modification of a cell, which doesn't have a distinguishing sequence and provides for the input of an additional input symbol and usage of state codes, which generates a Hamilton cycle in the sequence of transitions has been developed and substantiated. Methods and procedures for the synthesis of one-dimensional and two-dimensional networks with distributed configuration control have been developed. Figs.: 1. Refs.: 10 titles."
Networking (cs.NI),2023,18,Analysis of mobile edge computer networks based on a specialized framework,1,N/A,https://www.semanticscholar.org/paper/dbdb778c0ef4312fdaed4d65339f73258966a969,"A. Mikov, A. Mikov","A framework is presented as a set of programs designed to analyze various computer networks of edge computing. It includes special classes for describing mobile units, servers, as well as workloads – streams of tasks to be solved. The framework allows you to simulate the characteristics of the terrain on which the network nodes are located. The work with the framework is demonstrated when analyzing such parameters as the amount of information obsolescence due to delays in solving problems and the time of active functioning of peripheral nodes in random walk models. The results of the analysis are presented as dependency plots."
Networking (cs.NI),2023,19,Discussion on SPOC online and offline blended mode of Computer Networks,1,N/A,https://www.semanticscholar.org/paper/8cb9051d1bdcdde863ca1e7df841401be643eeb0,"Jing Li, Bi-Hong Yang, Xishang Dong","Computer networks is a compulsory course of network engineering, software engineering, computer science and other engineering majors. The foundational nature of this course in the computer industry determines its important position in education. Computer networks cover a lot of ground, and involve a large amount of knowledge, which makes it difficult to understand and remember. and the examination pass rate is always at a low level. Therefore, we plan to implement a new teaching model, SPOC online and offline blended mode. Before class, we will upload the course objectives, knowledge points, learning tasks and online videos using Chaoxing platform. After class, we also put expand resource and homework tasks on the Chaoxing platform. The investigation and feedback about this model show that our proposed SPOC online and offline blended model is very effective. In addition, we put forward some improvement measures for the problems encountered, which have guiding significance for the future teaching process."
Networking (cs.NI),2023,20,Computer Networks Cyber Security Via an Intrusion Detection System,1,N/A,https://www.semanticscholar.org/paper/4199456a2777d4ce43adb5145783107e3249ecaa,"L. J, KarthickMurugan S, Logalakshmi A","Effectively identifying computer network attacks is still a challenge. This is due to recent attempts by cybercriminals to spoof intrusion detection systems (IDS) by altering packet contents. Additionally, the computer networks constantly add a large number of additional devices. Additionally posing a security risk to computer networks are these novel gadgets. To regulate computer network flows and offer security beforehand, you must do a thorough examination of the elements of your network, including the IDSs, the methodologies and devices used, particular kinds of attacks, and the tools that are used. This essay discusses intrusion detection methods, methodology, and tactics in addition to exploring innovative attack types, defenses, and current scientific study in the subject."
Operating Systems (cs.OS),2020,1,"IoT Ecosystem: A Survey on Devices, Gateways, Operating Systems, Middleware and Communication",194,N/A,https://www.semanticscholar.org/paper/d3f6031af9c1e52ab03d4eb3b49ebcc9da692d22,"Sharu Bansal, Dilip Kumar",No Abstract
Operating Systems (cs.OS),2020,5,Custos: Practical Tamper-Evident Auditing of Operating Systems Using Trusted Execution,88,N/A,https://www.semanticscholar.org/paper/34ab3f31f842a6f06996da8fb7ca83d563e95812,"Riccardo Paccagnella, Pubali Datta, Wajih Ul Hassan et al.","—System auditing is a central concern when investigating and responding to security incidents. Unfortunately, attackers regularly engage in anti-forensic activities after a break-in, covering their tracks from the system logs in order to frustrate the efforts of investigators. While a variety of tamper-evident logging solutions have appeared throughout the industry and the literature, these techniques do not meet the operational and scalability requirements of system-layer audit frameworks. In this work, we introduce C USTOS , a practical framework for the detection of tampering in system logs. C USTOS consists of a tamper-evident logging layer and a decentralized auditing protocol. The former enables the veriﬁcation of log integrity with minimal changes to the underlying logging framework, while the latter enables near real-time detection of log integrity violations within an enterprise-class network. C USTOS is made practical by the observation that we can decouple the costs of cryptographic log commitments from the act of creating and storing log events, without trading off security, leveraging features of off-the-shelf trusted execution environments. Supporting over one million events per second, we show that C USTOS ’ tamper-evident logging protocol is three orders of magnitude (1000 × ) faster than prior solutions and incurs only between 2% and 7% runtime overhead over insecure logging on intensive workloads. Further, we show that C USTOS ’ auditing protocol can detect violations in near real-time even in the presence of a powerful distributed adversary and with minimal (3%) network overhead. Our case study on a real-world APT attack scenario demonstrates that C USTOS forces anti-forensic attackers into a “lose-lose” situation, where they can either be covert and not tamper with logs (which can be used for forensics), or erase logs but then"
Operating Systems (cs.OS),2020,3,Comparison of Bioinformatics Pipelines and Operating Systems for the Analyses of 16S rRNA Gene Amplicon Sequences in Human Fecal Samples,64,N/A,https://www.semanticscholar.org/paper/c62f5d4d6f62cacc1a29859e30a9aee7422e7971,"M. Marizzoni, Thomas Gurry, S. Provasi et al.","Amplicon high-throughput sequencing of 16S ribosomal RNA (rRNA) gene is currently the most widely used technique to investigate complex gut microbial communities. Microbial identification might be influenced by several factors, including the choice of bioinformatic pipelines, making comparisons across studies difficult. Here, we compared four commonly used pipelines (QIIME2, Bioconductor, UPARSE and mothur) run on two operating systems (OS) (Linux and Mac), to evaluate the impact of bioinformatic pipeline and OS on the taxonomic classification of 40 human stool samples. We applied the SILVA 132 reference database for all the pipelines. We compared phyla and genera identification and relative abundances across the four pipelines using the Friedman rank sum test. QIIME2 and Bioconductor provided identical outputs on Linux and Mac OS, while UPARSE and mothur reported only minimal differences between OS. Taxa assignments were consistent at both phylum and genus level across all the pipelines. However, a difference in terms of relative abundance was identified for all phyla (p < 0.013) and for the majority of the most abundant genera (p < 0.028), such as Bacteroides (QIIME2: 24.5%, Bioconductor: 24.6%, UPARSE-linux: 23.6%, UPARSE-mac: 20.6%, mothur-linux: 22.2%, mothur-mac: 21.6%, p < 0.001). The use of different bioinformatic pipelines affects the estimation of the relative abundance of gut microbial community, indicating that studies using different pipelines cannot be directly compared. A harmonization procedure is needed to move the field forward."
Operating Systems (cs.OS),2020,2,End the Senseless Killing: Improving Memory Management for Mobile Operating Systems,54,N/A,https://www.semanticscholar.org/paper/01e6d54065755f7b546298558d43090d9a6b79f8,"Niel Lebeck, A. Krishnamurthy, H. Levy et al.",No Abstract
Operating Systems (cs.OS),2020,7,Fuzzy test model for performance evaluation matrix of service operating systems,40,N/A,https://www.semanticscholar.org/paper/8454d11ee1880b88b7d29004477c8de798769c3b,"Kuen-Suan Chen, Chun-Min Yu",No Abstract
Operating Systems (cs.OS),2020,4,"A Comparative Study of Operating Systems: Case of Windows, UNIX, Linux, Mac, Android and iOS",37,N/A,https://www.semanticscholar.org/paper/82a9547ddb4b76bb88b5f4e042ed41f9dd7f62f1,"A. Adekotujo, Adedoyin Odumabo, Ademola Adedokun et al.","Varieties of operating systems (OS) have emerged over the years having different features and functionalities. Understanding the functionalities of each OS guides users’ decisions about the OS to install on their computers. In view of this, the comparative analysis of different OS is needed to provide details on the similarities and difference in recent types of OS vis-à-vis their strengths and weaknesses. This paper focus on the comparative analysis of Windows, Unix, Linux, Mac, Android and iOS operating systems based on the OS features and their strengths and weaknesses. A qualitative analysis of six different operating systems and result showed that Windows 10 had 0.04 malware file present while Windows 7 machine was 0.08. Higher percentage of mobile malware target Androids than iOS. Windows 10, Linux, UNIX and Mac OS are more secured and reliable. Windows and Android are more popular, user-friendly, easy to use and allow more application program than Mac OS. Linux and Android are free while Windows is moderately costly and Mac OS is very costly. Except for Mac and iOS others allow compatibility. Windows 10 and Mac OS integrated firewall. Windows and Android tend to be the"
Operating Systems (cs.OS),2020,10,Urban Operating Systems,25,N/A,https://www.semanticscholar.org/paper/b501d7384e8814effd49332953fe611a55781222,"Andrés Luque-Ayala, S. Marvin",No Abstract
Operating Systems (cs.OS),2020,6,Timing Comparison of the Real-Time Operating Systems for Small Microcontrollers,24,N/A,https://www.semanticscholar.org/paper/f5100423851dc1d9b1391b2b89d7c1d745527108,I. Ungurean,"In automatic systems used in the control and monitoring of industrial processes, fieldbuses with specific real-time requirements are used. Often, the sensors are connected to these fieldbuses through embedded systems, which also have real-time features specific to the industrial environment in which it operates. The embedded operating systems are very important in the design and development of embedded systems. A distinct class of these operating systems is real-time operating systems (RTOSs) that can be used to develop embedded systems, which have hard and/or soft real-time requirements on small microcontrollers (MCUs). RTOSs offer the basic support for developing embedded systems with applicability in a wide range of fields such as data acquisition, internet of things, data compression, pattern recognition, diversity, similarity, symmetry, and so on. The RTOSs provide basic services for multitasking applications with deterministic behavior on MCUs. The services provided by the RTOSs are task management and inter-task synchronization and communication. The selection of the RTOS is very important in the development of the embedded system with real-time requirements and it must be based on the latency in the handling of the critical operations triggered by internal or external events, predictability/determinism in the execution of the RTOS primitives, license costs, and memory footprint. In this paper, we measured and compared the timing performance for synchronization throughout an event, semaphore, and mailbox for the following RTOSs: FreeRTOS 9.0.0, FreeRTOS 10.2.0, rt-thread, Keil RTX, uC/OS-II, and uC/OS-III. For the experimental tests, we developed test applications for two MCUs: ARM Cortex™-M4 and ARM Cortex™-M0+ based MCUs."
Operating Systems (cs.OS),2020,8,A Review on IoT Operating Systems,10,N/A,https://www.semanticscholar.org/paper/0f6eae0d2c19870d998651e2e8ec1dff593ffc05,"A. Antony, Sarika S.","An IoT development board is a small-form-factor system, complete with microprocessor(s), memory, input/output functions providing the user with all the features of a functional computer. The MCU based smaller variants house limited hardware resources and do not demand an operating system. But the more powerful single board computers require an operating system to efficiently manage its resources and control the hardware. The choice of operating system depends on the microcontroller architecture, on-board memory, software stack used, real-time computing requirements, implementation environment and cost of the system. Operating systems for IoT applications require additional functionalities like network support, power usage monitoring, secondary storage management, multithreading and so on. This paper intends to survey the different IoT operating systems available in the market and studies the various considerations on the selection of OS for IoT development boards."
Operating Systems (cs.OS),2020,9,The version effect of apps and operating systems in mobile commerce,10,N/A,https://www.semanticscholar.org/paper/9c2e78fee21e7146fbac1132fa823d0e6a8e1ba8,"X. Zhang, Ruomeng Cui, Oliver Yao","Different versions of mobile operating systems or shopping apps enable different functionalities and information flows, thus creating various mobile shopping environments. In general, up‐to‐date versions provide better information flows and richer functionalities. However, mobile operating systems and shopping apps affect consumer behavior through different mechanisms. An up‐to‐date mobile operating system reduces the system response time, while an up‐to‐date shopping app improves algorithms for better search accuracy. The former encourages consumer explore and search, whereas the latter improves consumer search efficiency and reduces chances for consumers to discover more products. Using a unique large‐scale clickstream data set from a mobile commerce retailer, we examine the effect of mobile operating system and app versions on consumer search and impulse purchase behaviors in mobile commerce. Our results show that consumers with an up‐to‐date mobile operating system or a previous version of a shopping app conduct more searches in terms of increased product page views and time spent on product pages, which results in a higher probability of consumer impulse purchase. However, consumers' search for individual products is not affected by versions. Surprisingly, though more page views or time spent may boost purchases, we find that consumer search affects impulse purchases nonlinearly in that page views and time spent have a decreasing rate of impact. Our computations show that using an up‐to‐date operating system increases consumer search activities by 60.45 product pages or 521.30 seconds spent browsing compared to using a previous version of an operation system. Using an up‐to‐date app decreases consumer search activities by 129.34 product pages or 1446.48 seconds spent browsing compared to using a previous version of a mobile app."
Operating Systems (cs.OS),2020,12,An Analytical Approach to Assess and Compare the Vulnerability Risk of Operating Systems,9,N/A,https://www.semanticscholar.org/paper/8fcde1387f5b4c2c35107e4646026211c65cd51c,"P. K. H. Kaluarachchilage, C. Attanayake, Sasith M. Rajasooriya et al.","—Operating system (OS) security is a key component of computer security. Assessing and improving OSs strength to resist against vulnerabilities and attacks is a mandatory requirement given the rate of new vulnerabilities discovered and attacks occur. Frequency and the number of different kinds of vulnerabilities found in an OS can be considered an index of its information security level. In the present study we assess five mostly used OSs, Microsoft Windows (windows 7, windows 8 and windows 10), Apple’s Mac and Linux for their discovered vulnerabilities and the risk associated in each. Each discovered and reported vulnerability has an Exploitability score assigned in CVSS [27] of the national vulnerability data base. We compare the risk from vulnerabilities in each of the five Operating Systems. The Risk Indexes used are developed based on the Markov model to evaluate the risk of each vulnerability [11, 21, 22]. Statistical methodology and underlying mathematical approach is described. The analysis includes all the reported vulnerabilities in the National Vulnerability Database [19]"
Operating Systems (cs.OS),2020,11,Performance Evaluation of Linux Operating Systems,8,N/A,https://www.semanticscholar.org/paper/a2ee3b13469f8b3bf0f2f8c2308089fa3c35e50f,"Marko Boras, J. Balen, Krešimir Vdovjak","Recently, Linux has undergone a significant progress and since it provides many helpful features to companies and home users, it has become one of the most commonly used operating systems in IT industry. Considering the popularity of available Linux distributions, three Linux desktop distributions were selected for further evaluation. The idea of this paper is to evaluate performance and compare three different Linux distributions and their influence on processor, memory, graphics system and disk drive performance. Measurements were performed with a three different benchmarking tools specialized for a specific computer component. All Linux operating system distributions were installed on the same desktop computer and based on the achieved performance measurement results it was concluded that the best results were achieved by using Pop!_OS 20.04. Linux distribution, which is very surprising because it is a relatively new distribution on the market."
Operating Systems (cs.OS),2020,16,The impact of using virtual reality on student’s motivation for operating systems course learning,8,N/A,https://www.semanticscholar.org/paper/28f3f9561d6044ca217d3459a55110835f83fc1a,"M. Abdelaziz, H. El-Bakry, Alaa El-Din et al.",No Abstract
Operating Systems (cs.OS),2020,13,Systematicity of students’ independent work in the course of operating systems,7,N/A,https://www.semanticscholar.org/paper/6a9e04da82a49ac7b4fa826fbae0c388bd39667d,"O. Kolgatin, D. Holubnychyi, L. Kolgatina","The paper is devoted to the study of systematicity of students’ learning activity as a parameter of student’s model, and influence of systematicity at learning results in the course “Operating Systems”. The necessity to equip the student himself as the subject of the educational process with the skills and appropriate pedagogical forecasting tools for independent choice of the appropriate variant of educational activity is shown as theoretical framework. Parameters of models in such pedagogical diagnostics system are suggested and discussed. Empirical work has been realised on the base of learning management system Moodle and give possibility to analyse correlation between timeliness of completing the learning tasks by students and their educational achievements as well as to analyse the structure of students’ time planning at homework. Recommendations to improve the educational process have been suggested"
Operating Systems (cs.OS),2020,14,BrowserVM: Running Unmodified Operating Systems and Applications in Browsers,7,N/A,https://www.semanticscholar.org/paper/db8bcb3aa33447e5fd4fefd1f30f4969561b9c28,"Elliott Wen, J. Warren, Gerald Weber","Web browsers are becoming a de-facto universal computing platform. Recently, research communities are attempting to enhance browsers with the capacity to run applications written in general programming languages. Existing approaches mainly compile source codes to browsers' native instruction sets JavaScript or WebAssembly. However, they usually fall short in practice because browsers lack operating system abstractions (e.g., thread and filesystem) and many programs would require extensive modifications. This paper presents BroswerVM, a new approach to run unmodified and complete operating systems and applications inside browsers. BrowserVM is a WebAssembly-based virtual machine hypervisor. BrowserVM efficiently conducts processor emulation through dynamic binary translation. It also provides performant hardware emulation for hard disks, graphics cards and network adapters. Implementing BrowserVM is challenging because of the unique characteristics of WebAssembly: semantic gap with low-level CPU assembly and high initialization overhead. We detail the methods to deal with these challenges and conduct a performance benchmark on BrowserVM. Our results indicate that though slower than native hypervisors, BroswerVM provides acceptable performance to execute existing applications that are not compute-intensive."
Operating Systems (cs.OS),2020,15,Real-Time Operating Systems for Cyber-Physical Systems: Current Status and Future Research,7,N/A,https://www.semanticscholar.org/paper/b1fd94fd65206f79f3fd844fed499fcc377a2008,"A. Serino, Liang Cheng","This paper studies the current status and future directions of RTOS (Real-Time Operating Systems) for time-sensitive CPS (Cyber-Physical Systems). GPOS (General Purpose Operating Systems) existed before RTOS but did not meet performance requirements for time sensitive CPS. Many GPOS have put forward adaptations to meet the requirements of real-time performance, and this paper compares RTOS and GPOS and shows their pros and cons for CPS applications. Furthermore, comparisons among select RTOS such as VxWorks, RTLinux, and FreeRTOS have been conducted in terms of scheduling, kernel, and priority inversion. Various tools for WCET (Worst-Case Execution Time) estimation are discussed. This paper also presents a CPS use case of RTOS, i.e. JetOS for avionics, and future advancements in RTOS such as multi-core RTOS, new RTOS architecture and RTOS security for CPS."
Operating Systems (cs.OS),2020,18,Linux Online Virtual Environments in Teaching Operating Systems,5,N/A,https://www.semanticscholar.org/paper/2a241283f20005f5ba3eb154c731e51c59aa69aa,Olena S. Holovnia,No Abstract
Operating Systems (cs.OS),2020,17,Machine Learning Approach to Predict Computer Operating Systems Vulnerabilities,3,N/A,https://www.semanticscholar.org/paper/17ec45bd17e4723eb110d95904b4743eb93d6822,"Freeh Alenezi, C. Tsokos","Information security is everyone’s concern. Computer systems are used to store sensitive data. Any weakness in their reliability and security makes them vulnerable. The Common Vulnerability Scoring System (CVSS) is a commonly used scoring system, which helps in knowing the severity of a software vulnerability. In this research, we show the effectiveness of common machine learning algorithms in predicting the computer operating systems security using the published vulnerability data in Common Vulnerabilities and Exposures and National Vulnerability Database repositories. The Random Forest algorithm has the best performance, compared to other algorithms, in predicting the computer operating system vulnerability severity levels based on precision, recall, and F-measure evaluation metrics. In addition, a predictive model was developed to predict whether a newly discovered computer operating system vulnerability would allow attackers to cause denial of service to the subject system."
Operating Systems (cs.OS),2020,19,The Impact of Teaching Operating Systems using Two Different Teaching Modalities,2,N/A,https://www.semanticscholar.org/paper/f4547cd7122e74f1b33a0fdd947d60291aec7578,Ingrid A. Buckley,"—This paper presents a preliminary look at the performance of two cohorts enrolled in an Operating System course which was taught using two different teaching delivery methods. Operating systems is a technical, senior-level, undergraduate course that includes abstract concepts, mechanisms, and their implementations. This course exposes students to a UNIX-based operating system and includes concurrent programming (threads and synchronization), inter-process communication, CPU scheduling main memory, and virtual memory management. Technical courses present an additional dimension of difficulty when compared to non-technical courses which are more focused on soft skills because they require strong technical skills such as programming and problem-solving. This paper discusses other research studies and statistical data which underscore some of the challenges and differences encountered when teaching a traditional face-to-face versus an online course and the impact on student success. In this work, the 2019 cohort was taught operating systems in the traditional face-to-face modality, while the 2020 cohort was taught the course using the synchronous online modality. The synchronous online modality is very similar to the face-to-face traditional class, in that, lectures are delivered in real-time; this allows students to ask the instructor questions in real-time. Each cohort was tested on the same course objectives (topics) over one semester in 2019 and 2020. The instructor presents the students’ performance on three(3) course exams and discusses the differences and similarities in their overall performance between the two groups."
Operating Systems (cs.OS),2020,20,A Survey on Resource Management in IoT Operating Systems,2,N/A,https://www.semanticscholar.org/paper/32dd1fb25791eec83ec9a7239b888e5ddcf8ce3b,"Arslan Musaddiq, Y. B. Zikria, Ieee Oliver Hahm Senior Member et al.",No Abstract
Operating Systems (cs.OS),2021,4,Real-Time Operating Systems,84,N/A,https://www.semanticscholar.org/paper/722700b3992d519accda0093fd2f6988b043599b,Colin Walls,No Abstract
Operating Systems (cs.OS),2021,6,Inter-hours rolling scheduling of behind-the-meter storage operating systems using electricity price forecasting based on deep convolutional neural network,73,N/A,https://www.semanticscholar.org/paper/4e1178d59e739e0d6057a377d857eb53b9f6c46f,"Zhuofu Deng, Chenxu Liu, Zhiliang Zhu",No Abstract
Operating Systems (cs.OS),2021,1,A Comprehensive Study of Kernel (Issues and Concepts) in Different Operating Systems,36,N/A,https://www.semanticscholar.org/paper/2b6bbcb06ae7f5a341e6a18e221ae25155ad9ab1,"HayfaaSubhi Malallah, Subhi R. M. Zeebaree, R. Zebari et al.","Various operating systems (OS) with numerous functions and features have appeared over time. As a result, they know how each OS has been implemented guides users' decisions on configuring the OS on their machines. Consequently, a comparative study of different operating systems is needed to provide specifics on the same and variance in novel types of OS to address their flaws. This paper's center of attention is the visual operating system based on the OS features and their limitations and strengths by contrasting iOS, Android, Mac, Windows, and Linux operating systems. Linux, Android, and Windows 10 are more stable, more compatible, and more reliable operating systems. Linux, Android, and Windows are popular enough to become user-friendly, unlike other OSs, and make more application programs. The firewalls in Mac OS X and Windows 10 are built-in. The most popular platforms are Android and Windows, specifically the novelist versions. It is because they are low-cost, dependable, compatible, safe, and easy to use. Furthermore, modern developments in issues resulting from the advent of emerging technology and the growth of the cell phone introduced many features such as high-speed processors, massive memory, multitasking, high-resolution displays, functional telecommunication hardware, and so on."
Operating Systems (cs.OS),2021,5,Parallel Mining Operating Systems: From Digital Twins to Mining Intelligence,36,N/A,https://www.semanticscholar.org/paper/38b109d722a256f7cfbc96b47c853953dbdd0923,"Long Chen, Xiaoming Hu, Ge Wang et al.","With the rapid development and modernization requirement of global coal industry, there is an emerging need for intelligent and unmanned mining systems. In this paper, the Intelligent Mining Operating System (IMOS) is proposed and developed, based on the parallel management and control of mining operating infrastructure that integrates the intelligent mining theory, the ACP-based (Artificial societies, Computational experiments, Parallel execution) parallel intelligence approaches, and the new generation of artificial intelligence (AI) technologies. To satisfy the intelligent and unmanned demand of open-pit mines, the IMOS architecture is developed by integrating the theory of digital quadruplets. The main subsystems and functions of IMOS are elaborated in detail, including a single-vehicle operating subsystem, multi-vehicle collaboration subsystem, vehicle-road collaboration subsystem, unmanned intelligent subsystem, dispatch management subsystem, parallel management and control subsystem, supervisory subsystem, remote takeover subsystem, and communication subsystem. The IMOS presented in this paper is the first integrated solution for intelligent and unmanned mines in China, and has been implemented over ten main open pits in the past few years. Its deployment and utilization will effectively improve the production efficiency and safety level of open-pit mines, promote the construction of ecological mines, and bring great significance to the realization of sustainable mining development."
Operating Systems (cs.OS),2021,2,"The Presence, Trends, and Causes of Security Vulnerabilities in Operating Systems of IoT’s Low-End Devices",33,N/A,https://www.semanticscholar.org/paper/cc546d45d2b6c02a3db736082a035c56bd4456b0,"Abdullah Al-Boghdady, Khaled Wassif, M. El-Ramly","Internet of Things Operating Systems (IoT OSs) run, manage and control IoT devices. Therefore, it is important to secure the source code for IoT OSs, especially if they are deployed on devices used for human care and safety. In this paper, we report the results of our investigations of the security status and the presence of security vulnerabilities in the source code of the most popular open source IoT OSs. Through this research, three Static Analysis Tools (Cppcheck, Flawfinder and RATS) were used to examine the code of sixteen different releases of four different C/C++ IoT OSs, with 48 examinations, regarding the presence of vulnerabilities from the Common Weakness Enumeration (CWE). The examination reveals that IoT OS code still suffers from errors that lead to security vulnerabilities and increase the opportunity of security breaches. The total number of errors in IoT OSs is increasing from version to the next, while error density, i.e., errors per 1K of physical Source Lines of Code (SLOC) is decreasing chronologically for all IoT Oss, with few exceptions. The most prevalent vulnerabilities in IoT OS source code were CWE-561, CWE-398 and CWE-563 according to Cppcheck, (CWE-119!/CWE-120), CWE-120 and CWE-126 according to Flawfinder, and CWE-119, CWE-120 and CWE-134 according to RATS. Additionally, the CodeScene tool was used to investigate the development of the evolutionary properties of IoT OSs and the relationship between them and the presence of IoT OS vulnerabilities. CodeScene reveals strong positive correlation between the total number of security errors within IoT OSs and SLOC, as well as strong negative correlation between the total number of security errors and Code Health. CodeScene also indicates strong positive correlation between security error density (errors per 1K SLOC) and the presence of hotspots (frequency of code changes and code complexity), as well as strong negative correlation between security error density and the Qualitative Team Experience, which is a measure of the experience of the IoT OS developers."
Operating Systems (cs.OS),2021,3,"Hardware, Software Platforms, Operating Systems and Routing Protocols for Internet of Things Applications",32,N/A,https://www.semanticscholar.org/paper/ae9453b0577cec568ce4f8eef213c60834d51eaa,A. Zrelli,No Abstract
Operating Systems (cs.OS),2021,8,Forensic Analysis of Tor Browser on Windows 10 and Android 10 Operating Systems,17,N/A,https://www.semanticscholar.org/paper/bc96eb247ddf35f235ccfa4ad3928895e2531dad,"Muhammad Raheel Arshad, M. Hussain, Hasan Tahir et al.","Smartphones and Internet have become prevalent in our society with various applications in businesses, education, healthcare, gaming, and research. One of the major issues with the Internet today is its lack of security since an eavesdropper can potentially intercept the communication. This has contributed towards an increased number of cyber-crime incidents, resulting in an increase in users’ consciousness about the security and privacy of their communication. One example is the shift towards using private browsers such as Tor. Tor is a well-recognized and widely used privacy browser based on The Onion Router network that provisions anonymity over the insecure Internet. This functionality of Tor has been a major hurdle in cybercrime investigations due to the complex nature of its anonymity. This paper investigates artifacts from the Tor privacy browser on the latest Windows 10 and Android 10 devices to determine potential areas where evidence can be found. We examine the registry, storage, and memory of Windows 10 devices and the memory, storage, logs, and Zram of Android 10 devices for three possible scenarios i.e. before, during, and after use of the Tor browser. Our results do not support the claims made by the Tor Project regarding user privacy and anonymity. We find that it is possible to retrieve significant details about a user’s browsing activities while the Tor browser is in use as well as after it is closed (on both operating systems). This paper also provides an investigative methodology for the acquisition and analysis of Tor browser artifacts from different areas of the targeted operating systems. Therefore, it can serve as a base to expand research in the forensic analysis of other privacy browsers and improve the efficiency of cybercrime investigations efficiency."
Operating Systems (cs.OS),2021,18,Memory forensic: Acquisition and analysis mechanism for operating systems,16,N/A,https://www.semanticscholar.org/paper/bf73d01a3ee81eec6bae860415350585230f9a98,"Raj Shree, A. Shukla, R. Pandey et al.",No Abstract
Operating Systems (cs.OS),2021,7,An Overview of Microkernel Based Operating Systems,8,N/A,https://www.semanticscholar.org/paper/ba3a9fdbc772f4d8ebd8ac5cc578a3fa7bcf4ba9,"Odun-Ayo Isaac, K. Okokpujie, Hannah Akinwumi et al.","The creation of Operating Systems (OSs) with Microkernels was in response to the various challenges presented by Operating Systems with Monolithic kernels. Microkernel based Operating Systems provides security and flexibility in the system. This paper reviews seven different microkernel-based Operating Systems: L4, GNU Hurd, Genode, L4re, NOVA, seL4, and Muen Separation Kernel. This analysis provides an understanding of the various trends in the Microkernel Based Operating Systems design. Research papers and official documentation of the individual microkernels served as data sources. The result in this paper shows that there has not been a significant variation in the underlying principle of minimality and how Microkernel Operating Systems approach the implementations of their inter-process communication (IPC), memory management, and scheduling."
Operating Systems (cs.OS),2021,9,Operating Systems for IoT Devices,7,N/A,https://www.semanticscholar.org/paper/c7910b0f51fff4221eb5aafc527b88723e7c4f45,"Neven Nikolov, O. Nakov, D. Gotseva","In this paper are described and compared the operating systems for IoT devices. There are so many operating systems and to make the right choose what to use is very complex. There are described most used RTOS in IoT and they are compared. Depending on the application, the appropriate RTOS for IoT must to be selected."
Operating Systems (cs.OS),2021,13,How ISO C became unusable for operating systems development,5,2201.07845,https://www.semanticscholar.org/paper/4a12c48d393aa58b1bd22a087e09620a111383f2,Victor Yodaiken,"The C programming language was developed in the 1970s as a fairly unconventional systems and operating systems development tool, but has, through the course of the ISO Standards process, added many attributes of more conventional programming languages and become less suitable for operating systems development. Operating system programming continues to be done in non-ISO dialects of C. The differences provide a glimpse of operating system requirements for programming languages."
Operating Systems (cs.OS),2021,14,SmartOS: towards automated learning and user-adaptive resource allocation in operating systems,5,N/A,https://www.semanticscholar.org/paper/8e0d30969d05237f2ae27dce016680bcc6923aed,"Sepideh Goodarzy, Maziyar Nazari, Richard Han et al.","Today's operating systems typically apply a one-size-fits-all approach to resource management, such as applying a scheduler that treats all processes of equal importance. The goal of this paper is to explore a learning-based approach to resource management in modern operating systems in which the OS automatically learns what tasks the user deems to be most important at that time and seamlessly adjusts allocation of CPU, memory, I/O, and network bandwidth to prioritize user preferences on demand. We demonstrate an implementation of such a learning-based OS in Linux and present evaluation results showing that a reinforcement learning-based approach can rapidly learn and adjust system resources to meet user demands."
Operating Systems (cs.OS),2021,11,Service Portability and Information Discovery in Building Operating Systems using Semantic Modeling,4,N/A,https://www.semanticscholar.org/paper/6ece48803204f23aabc80b31b0139a2e77b778ca,"Jakob Hviid, Aslak Johansen, Gabe Fierro et al.","To achieve cost-efficient IoT based Building Operating Systems (BOS), portable building services are needed. Most previous work has gone into hardware abstraction, while service abstraction has been neglected. This paper presents an information discovery mechanism for BOSs that is based on an ontology which integrates with other semantic models used in the space. The built environment is characterized by extreme heterogeneity; no buildings are entirely alike. Equipment is replaced or updated, control systems and building functionality evolve, as applications, models, forecasters, and controllers improve. For services deployed in such settings to operate at a scale, they must be robust to change. Describing service interfaces using a semantic model, together with the physical context in a building, enables applications to query for their service dependencies. Applications then depend on an abstract query, instead of specific services. For evaluation, nine services running on models of the service ecosystems of three concrete buildings, are implemented, demonstrated, and discussed. Results show services have successfully been made portable and adapts to the changing environments of buildings. Merging and splitting services without code changes to depending services also work as intended, as well as increasing system resilience, by arbitrating similar services."
Operating Systems (cs.OS),2021,12,History of Operating Systems,4,N/A,https://www.semanticscholar.org/paper/dd024473c3afee5339532bcefaa5b80c983a28e0,Gerard O’Regan,No Abstract
Operating Systems (cs.OS),2021,15,Comparative Analysis of Network Forensic Tools on Different Operating Systems,4,N/A,https://www.semanticscholar.org/paper/4d88a48b741ba3ca4792471baeb9f20fe3792323,"D. Delija, Ivan Mohenski, Goran Sirovatka","This paper deals with the theoretical and practical elaboration of the mentioned topics, which gives an insight into digital forensics, network forensics, collection and analysis of digital evidence, and the tools with which the above is done. An insight into the comparison of tools is provided, which begins with the selection of tools according to the stated criteria and the description of the tools with the operating systems on which they run. The comparison itself begins with defining tasks to test functionality. Upon completion of the above tasks, the obtained results are recorded and later used to analyze the performance of the tool. After the tool comparison, the obtained results are scored and ranked, and then a conclusion is given about the acquired knowledge and experience during the preparation of this paper."
Operating Systems (cs.OS),2021,16,Comparative Analysis of Power Consumption of the Linux and its Distribution Operating Systems vs Windows and Mac Operating Systems.,4,N/A,https://www.semanticscholar.org/paper/ae640a6873317596bd8869f0a2155e7bc4d5e899,"Sayed Najmuddin, Zabihullah Atal, Riaz Ahmad Ziar","Comparison and analysis of different operating systems by different aspects such as color schemes, resolutions, brightness, memory management, process management, scheduler tasks and other modules, and identifying why Linux kernel and Linux distributions consume more power and battery than Windows and Mac operating systems"
Operating Systems (cs.OS),2021,10,Operating Systems for Ethical Hackers - A Platform Comparison of Kali Linux and Parrot OS,3,N/A,https://www.semanticscholar.org/paper/c5ee293ac6ef57d77b37510ef39b52e957178ec6,"Syed Zain ul Hassan, Zainab Muzaffar, S. Ahmad","Many operating systems are used for ethical hacking, which has emerged over the years. These operating systems have multiple tools and features to encounter malicious attacks performed by hackers. This study aims to discuss the benefits of various operating systems used for ethical hacking and to present a platform comparison study of two well-known Debian-derived Linux distributions used for ethical hacking, namely Kali Linux and Parrot OS. These tools and features assist ethical hackers in determining which operating system is best for penetration testing. In this paper, we will explore what penetration testing is, why we use this testing technique and how to secure the computer and the network from cyber-attacks using different ethical hacking operating systems. The paper deals with a qualitative analysis of the tools and features to deeply analyze some of their metrics which have been common in these operating systems. This paper will help ethical hackers to nail down the operating systems that are most suitable for them."
Operating Systems (cs.OS),2021,17,The Influence of Mobile Operating Systems on User Security Behavior,2,N/A,https://www.semanticscholar.org/paper/138b410e8f5c77fc86456dfe36654ed35dcc23c8,"M. Butler, R. Butler","Mobile security remains a concern for multiple stakeholders. Safe user behavior is crucial key to avoid and mitigate mobile threats. The research used a survey design to capture key constructs of mobile user threat avoidance behavior. Analysis revealed that there is no significant difference between the two key drivers of secure behavior, threat appraisal and coping appraisal, for Android and iOS users. However, statistically significant differences in avoidance motivation and avoidance behavior of users of the two operating systems were displayed. This indicates that existing threat avoidance models may be insufficient to comprehensively deal with factors that affect mobile user behavior. A newly introduced variable, perceived security, shows a difference in the perceptions of their level of protection among the users of the two operating systems, providing a new direction for research into mobile security."
Operating Systems (cs.OS),2021,19,Power-Aware Real-Time Operating Systems on Reconfigurable Architectures,2,N/A,https://www.semanticscholar.org/paper/b0994da13a86f51473378937ad709b2c6985fd11,"Gökhan Akgün, D. Göhringer","Real-time Operating Systems (RTOSs) are mainly implemented in software and sequentially executed on processors. The periodic call of the task scheduling service introduces additional overhead in software and eventually leads to jitter. However, the occurring overhead can be shortened or eliminated by using reconfigurable systems. Besides, dynamically adjusting power dissipation of reconfigurable systems leads to a change in the execution time of applications, so deadlines may not be met. Therefore, careful study of the impact of such optimizations on real-time capabilities is needed. The presented PhD project deals with offloading of RTOS components considering power dissipation on reconfigurable platforms. For this purpose, the task scheduling of FreeRTOS has already been offloaded to a co-processor while scaling voltage and frequency on XC7Z020. This reduced the execution time of the task scheduling by 38.9%."
Operating Systems (cs.OS),2021,20,Exploring Variability of Visual Accessibility Options in Operating Systems,2,N/A,https://www.semanticscholar.org/paper/8aae10c1eef52409564a388e7fd548be72c7548e,"Austin Waffo Kouhoué, Yoann Bonavero, T. Bouétou et al.","Digital technologies are an opportunity to overcome disabilities, provided that accessibility is ensured. In this paper, we focus on visual accessibility and the way it is supported in Operating Systems (OS). The significant variability in this support has practical consequences, e.g., the difficulty to recommend or select an OS, or migrate from one OS to another. This suggests building a variability model for OS that would classify them and would serve as a reference. We propose a methodology to build such a variability model with the help of the Formal Concept Analysis (FCA) framework. In addition, as visual accessibility can be divided into several concerns (e.g., zoom, or contrast), we leverage an extension of FCA, namely Relational Concept Analysis. We also build an ontology to dispose of a standardized description of visual accessibility options. We apply our proposal to the analysis of the variability of a few representative operating systems."
Operating Systems (cs.OS),2022,5,Urban operating systems: producing the computational city,38,N/A,https://www.semanticscholar.org/paper/f2b4f279d537e0d8a86b034b5f34d188b8c38ee3,A. Krisch,"urban digital infrastructures operationalize, homogenize, reintegrate and simplify the urban by focusing on the relationship between established infrastructure systems and newly emerging digital infrastructures. The book provides an important synthesis of historical and contemporary perspectives on digital urbanism by bridging concepts of smart cities, platform urbanism and data politics in an urban context. The analysis of the underlying computational logics in different cities provides valuable insights into the emergence of a computational urbanism that reworks the governance of urban processes in specific ways"
Operating Systems (cs.OS),2022,4,BlackBox: A Container Security Monitor for Protecting Containers on Untrusted Operating Systems,37,N/A,https://www.semanticscholar.org/paper/3af13b96191578ccb41388b3017829246859ea00,"Alexander Van't Hof, Jason Nieh",No Abstract
Operating Systems (cs.OS),2022,7,"A Reference Architecture for Cloud–Edge Meta-Operating Systems Enabling Cross-Domain, Data-Intensive, ML-Assisted Applications: Architectural Overview and Key Concepts",28,N/A,https://www.semanticscholar.org/paper/698350d245871eb7998846cd81a9d9702139c5bf,"P. Trakadas, X. Masip-Bruin, F. Facca et al.","Future data-intensive intelligent applications are required to traverse across the cloud-to-edge-to-IoT continuum, where cloud and edge resources elegantly coordinate, alongside sensor networks and data. However, current technical solutions can only partially handle the data outburst associated with the IoT proliferation experienced in recent years, mainly due to their hierarchical architectures. In this context, this paper presents a reference architecture of a meta-operating system (RAMOS), targeted to enable a dynamic, distributed and trusted continuum which will be capable of facilitating the next-generation smart applications at the edge. RAMOS is domain-agnostic, capable of supporting heterogeneous devices in various network environments. Furthermore, the proposed architecture possesses the ability to place the data at the origin in a secure and trusted manner. Based on a layered structure, the building blocks of RAMOS are thoroughly described, and the interconnection and coordination between them is fully presented. Furthermore, illustration of how the proposed reference architecture and its characteristics could fit in potential key industrial and societal applications, which in the future will require more power at the edge, is provided in five practical scenarios, focusing on the distributed intelligence and privacy preservation principles promoted by RAMOS, as well as the concept of environmental footprint minimization. Finally, the business potential of an open edge ecosystem and the societal impacts of climate net neutrality are also illustrated."
Operating Systems (cs.OS),2022,8,AuthROS: Secure Data Sharing Among Robot Operating Systems based on Ethereum,26,2208.14269,https://www.semanticscholar.org/paper/7aacfd408cb4555f9b7632528c8dc27572320043,"Shenhui Zhang, Wenkai Li, Xiaoqi Li et al.","The Robot Operating System (ROS) streamlines human processes, increasing the efficiency of various production tasks. However, the security of data transfer operations in ROS is still in its immaturity. Securing data exchange between several robots is a significant problem. This paper proposes AuthROS, an Ethereum blockchain-based secure data sharing method, for robot communication. It is a ROS node authorization system capable of ensuring the immutability and security of private data flow between ROS nodes of any size. To ensure data security, AuthROS employs the smart contract for permission granting and identification, SM2-based key exchange, and SM4-based plaintext encryption techniques. In addition, we deploy a data digest upload technique to optimize data query and upload performance. Finally, the experimental findings reveal that AuthROS has strong security, time performance, and node forging in cases where data should be recorded and robots need to remain immobile."
Operating Systems (cs.OS),2022,2,Operating Systems and Hypervisors for Network Functions: A Survey of Enabling Technologies and Research Studies,22,N/A,https://www.semanticscholar.org/paper/c8bfb8c03e25cc94308ea603d98d3aee0e947334,"Akhilesh S. Thyagaturu, Prateek Shantharama, Ahmed Nasrallah et al.","Scalable and flexible communication networks increasingly conduct the packet processing for Network Functions (NFs) in General Purpose Computing (GPC) platforms. The input/output (I/O)-intensive and latency-sensitive packet processing is challenging for the operating systems and hypervisors running on GPC platforms. This article surveys the existing enabling technologies and research studies on operating system and hypervisor aspects that directly influence the packet processing for NFs on GPC platforms. We organize this survey according to the main categories abstraction approach, memory access, and I/O strategy. We further categorize abstraction approach technologies and research studies into the categories operation systems, hypervisors, and containers. We partition the memory access category into the two sub-categories of memory allocation and memory access, while we partition the I/O strategy category into the sub-categories I/O device virtualization and I/O device access. Our survey gives a comprehensive summary of the capabilities and limitations of the existing enabling technologies and researched approaches for abstraction, memory access, and I/O for NF packet processing. We outline critical future research directions for advancing NF packet processing on GPC platforms."
Operating Systems (cs.OS),2022,11,This paper is included in the Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation.,18,N/A,https://www.semanticscholar.org/paper/67207a79a346e53d3210960bc5e15a69e7338d43,"†. ColinUnger, ♠. Zhihao, ♠. Jia‡♭ et al.",No Abstract
Operating Systems (cs.OS),2022,12,This paper is included in the Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation.,17,N/A,https://www.semanticscholar.org/paper/064e6ed8f8a1cf3526934828bfe25f8aaf1a3586,"Yuhong Zhong, Haoyu Li, Y. Wu et al.",No Abstract
Operating Systems (cs.OS),2022,1,iDetect for vulnerability detection in internet of things operating systems using machine learning,16,N/A,https://www.semanticscholar.org/paper/ec3d01467ae058bfc77f5c88d7039f47d92e9027,"Abdullah Al-Boghdady, M. El-Ramly, Khaled Wassif","Internet of Things (IoT) 's devices are ubiquitous and operate in a heterogonous environment with potential security breaches. IoT Operating Systems (IoT OSs) are the backbone software for running such devices. If IoT OSs are vulnerable to security breaches, higher-level security measures may not help. This paper aims to use Machine Learning (ML) to create a tool called iDetect for detecting vulnerabilities in C/C++ source code of IoT OSs. The source code for 16 releases of IoT OSs (RIOT, Contiki, FreeRTOS, Amazon FreeRTOS) and the Software Assurance Reference Dataset (SARD) were used to create a labeled dataset of vulnerable and benign code with the reference being the Common Weakness Enumeration (CWE) vulnerabilities present in IoT OSs. Studies showed that only a subset of CWEs is present in the C/C++ source code of low-end IoT OSs.The labeled dataset was used to train three ML models for vulnerability detection: Random Forest (RF), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN). The three models were used independently and RF; compared to CNN and RNN, gave the highest accuracy during the testing phase for binary and multiclass classification. RF was chosen as iDetect's ML classifier. Further evaluation was done on an unseen dataset of 322 code snippets taken from TinyOS. iDetect achieved a macro-averaged F1 score (mF1) of 98.5% and weighted-average F1 score (wF1) of 98% for multiclass classification, F1 score (F1) of 97.8% for binary classification, and superior results compared to all three Static Analysis Tools (SATs) used to collect the training dataset."
Operating Systems (cs.OS),2022,6,SFuzz: Slice-based Fuzzing for Real-Time Operating Systems,16,N/A,https://www.semanticscholar.org/paper/835c6d8718567f33ad9e72e9025461cfc0b50dd6,"Libo Chen, Quanpu Cai, Zhenbang Ma et al.","Real-Time Operating System (RTOS) has become the main category of embedded systems. It is widely used to support tasks requiring real-time response such as printers and switches. The security of RTOS has been long overlooked as it was running in special environments isolated from attackers. However, with the rapid development of IoT devices, tremendous RTOS devices are connected to the public network. Due to the lack of security mechanisms, these devices are extremely vulnerable to a wide spectrum of attacks. Even worse, the monolithic design of RTOS combines various tasks and services into a single binary, which hinders the current program testing and analysis techniques working on RTOS. In this paper, we propose SFuzz, a novel slice-based fuzzer, to detect security vulnerabilities in RTOS. Our insight is that RTOS usually divides a complicated binary into many separated but single-minded tasks. Each task accomplishes a particular event in a deterministic way and its control flow is usually straightforward and independent. Therefore, we identify such code from the monolithic RTOS binary and synthesize a slice for effective testing. Specifically, SFuzz first identifies functions that handle user input, constructs call graphs that start from callers of these functions, and leverages forward slicing to build the execution tree based on the call graphs and pruning the paths independent of external inputs. Then, it detects and handles roadblocks within the coarse-grain scope that hinder effective fuzzing, such as instructions unrelated to the user input. And then, it conducts coverage-guided fuzzing on these code snippets. Finally, SFuzz leverages forward and backward slicing to track and verify each path constraint and determine whether a bug discovered in the fuzzer is a real vulnerability. SFuzz successfully discovered 77 zero-day bugs on 35 RTOS samples, and 67 of them have been assigned CVE or CNVD IDs. Our empirical evaluation shows that SFuzz outperforms the state-of-the-art tools (e.g., UnicornAFL) on testing RTOS."
Operating Systems (cs.OS),2022,13,Integrated maintenance planning approach to optimize budget allocation for subway operating systems,16,N/A,https://www.semanticscholar.org/paper/1389eeff0b24b9c3dc723b458edadf7596c64a5b,"Omar El Hamshary, Mona Abouhamad, M. Marzouk",No Abstract
Operating Systems (cs.OS),2022,3,Selecting cloud computing software for a virtual online laboratory supporting the Operating Systems course,13,N/A,https://www.semanticscholar.org/paper/82475df348b282d0cfe9290630c1cfc42457bbe6,"Olena S. Holovnia, Vasyl P. Oleksiuk","The article provides a survey on cloud platforms suitable for a virtual online laboratory, which contains Linux online environments and is intended to support the Operating Systems course.The study justifies the choice of utilizing private cloud as a deployment model and IaaS as a service model and substantiates the decision to create specially tailored cloud environments adapted for educational needs in contrast to applying ready-made IaaS (Infrastructure as a Service) cloud services given by providers. The related works on cloud platforms for teaching operating systems are analyzed. The study also makes a review of the authors' previous research on virtualization tools and environments for the Operating Systems course and Cisco CyberSecurity Operations course. The basic and additional requirements for cloud computing software for virtual online laboratory supporting Operating Systems course have been elaborated. Finally, the work makes the comparison of Eucalyptus, OpenStack, CloudStack and OpenNebula cloud platforms and substantiates the selection among these cloud computing software the platforms of the first and the second choice."
Operating Systems (cs.OS),2022,9,A novel approach to continuous CVE analysis on enterprise operating systems for system vulnerability assessment,9,N/A,https://www.semanticscholar.org/paper/7650fe171c579921d520d5990b33546f8f4c5666,"Yusuf Kocaman, Serkan Gönen, Mehmet Ali Barişkan et al.",No Abstract
Operating Systems (cs.OS),2022,10,Exploring the Impact of Soft Errors on the Reliability of Real-Time Embedded Operating Systems,9,N/A,https://www.semanticscholar.org/paper/432358ccd6e69871346086b49608c7f34b144ee3,"S. Azimi, C. De Sio, A. Portaluri et al.","The continuous scaling of electronic components has led to the development of high-performance microprocessors that are suitable even for safety-critical applications where radiation-induced errors such as Single Event Effects (SEEs) can have a significant impact on the performance and reliability of the system. This work is dedicated to investigating the reliability of systems based on programmable hardware and Real-time operating Systems (RTOS) in the presence of architectural faults induced by soft errors in the configuration memory of the programmable hardware. We performed a proton radiation test campaigned at PSI radiation facility to identify the fault model affecting the configuration memory of Xilinx Zynq-7020 reconfigurable AP-Soc Device. The identified fault model in terms of SEU and MBU clusters has been used to evaluate the impact of proton-induced faults on applications running within FreeRTOS on a Microblaze soft processor. A Single Event Multiple Upset fault model resulting from a proton test is presented, focusing on characteristics such as shape, size, and frequency of observed cluster of errors. We conduct two fault injection campaigns and analyze the results to assess the effect of cluster size on system reliability. Moreover, we discuss software exceptions caused by faults that can affect the hardware structure of the soft processor."
Operating Systems (cs.OS),2022,14,Tinkertoy: Build Your Own Operating Systems for IoT Devices,6,N/A,https://www.semanticscholar.org/paper/540a393a16a8e2ebfda751cdc143bd47ebd50975,"Bingyao Wang, M. Seltzer","The Internet of Things (IoT) makes it possible for tiny devices with sensing and communication capabilities to be interconnected and interact with the cyber–physical world. However, these tiny devices have limited computing power and memory, so they often cannot run commodity operating systems, such as Windows and Linux. IoT devices are deployed everywhere, from smart home appliances to self-driving vehicles, and their applications impose ever-increasing and more heterogeneous demands on software architecture. There are many special-purpose and embedded operating systems built to satisfy these wildly different requirements, from early sensor network operating systems, such as TinyOS and Contiki, to more modern robot and real-time control systems, such as FreeRTOS and Zephyr. However, the rapid evolution and heterogeneity of IoT applications calls for a different solution. Specifically, this work introduces Tinkertoy, a collection of standard operating system modules from which developers can easily assemble customized operating systems. A customized operating system provides precisely the functionality needed by an application and consumes up to four times less memory than other IoT operating systems without sacrificing performance."
Operating Systems (cs.OS),2022,15,Simultaneous scheduling of replacement and repair of common components in operating systems,5,N/A,https://www.semanticscholar.org/paper/fd61077bc49d4df5ccc59a85e186a80777a2eca7,"Gabrijela Obradović, Ann-Brith Strömberg, K. Lundberg","In order for a system to stay operational, its components need maintenance. We consider two stakeholders—a system operator and a maintenance workshop—and a contract governing their joint activities. Components in the operating systems that are to be maintained are sent to the maintenance workshop, which should perform all maintenance activities on time in order to satisfy the contract. The maintained components are then sent back to be used in the operating systems. Our modeling of this system-of-systems includes stocks of damaged and repaired components, the workshop scheduling, and the planning of preventive maintenance for the operating systems. Our modeling is based on a mixed-binary linear optimization (MBLP) model of a preventive maintenance scheduling problem with so-called interval costs over a finite and discretized time horizon. We generalize and extend this model with the flow of components through the workshop, including the stocks of spare components. The resulting scheduling model—a mixed-integer optimization (MILP) model—is then utilized to optimize the main contract in a bi-objective setting: maximizing the availability of repaired (or new) components and minimizing the costs of maintaining the operating systems over the time horizon. We analyze the main contract and briefly discuss a turn-around time contract. Our results concern the effect of our modeling on the levels of the stocks of components over time, in particular minimizing the risk for lack of spare components."
Operating Systems (cs.OS),2022,17,"Comparative analysis of different Operating systems for Raspberry Pi in terms of scheduling, synchronization, and memory management",5,N/A,https://www.semanticscholar.org/paper/a69313f232ee26c5269baff5bbf1f2e433003188,"Umair Saeed, M. Khuhro, Muhammad Waqas et al.","Deep learning, big data, and the internet of things (IoT) have changed the world entirely. As an embedded computer, Raspberry Pi is playing a dynamic and prominent role in the era of ubiquitous computing. In ubiquitous computing, performance and real-time throughput are still an area of focus for Raspberry Pi. Indeed, process scheduling, page swapping, and process synchronization techniques are essential and crucial parameters of the operating system for Raspberry Pi. The key study objectives were; (i) explore the recent trend of applications of Raspberry Pi and (ii) comparison of process scheduling, page swapping and process synchronization techniques with different Raspberry Pi operating systems. The study concluded that Linux-based operating systems are offering an optimized and efficient computing environment for Raspberry Pi."
Operating Systems (cs.OS),2022,18,Recent Trends and Opportunities in Domain Specific Operating Systems,5,N/A,https://www.semanticscholar.org/paper/e2aeb55305f68fbb032c3b00fa69bf04af97cd8c,"Akhbar Sha, Kalwa Anvesh, Gogineni Narasimha Naidu et al.","Operating System forms an integral part of any device with computing capabilities. They form a layer between the hardware and software which helps the software to better utilize the hardware by performing many tasks like scheduling, protection, management, etc. In the recent years, Operating systems have evolved to accommodate the needs of many new devices such as edge devices, Real Time devices embedded devices, cloud computing, IoT specifications, etc. Many new fields of study such as Artificial Intelligence and Machine Learning have been experimented and implemented to increase the performance of the Operating Systems. In this work, we look at the latest improvements and trends shown by present day operating systems mainly IoT, Robotic, Real-Time systems as well as analyze the new features presented and discussed in their corresponding literary works."
Operating Systems (cs.OS),2022,19,Toward the hardening of real-time operating systems,5,N/A,https://www.semanticscholar.org/paper/d3870c13f3a4d0a19a8c06289c40afe517bd131e,"A. Bosio, Stefano Di Carlo, Maurizio Rebaudengo et al.","Safety and Mission-critical systems are evolving daily, requiring increasing levels of complexity in their design. While bare-metal single CPU systems were dedicated to such systems in the past, nowadays, multicore CPUs, GPUs, and other accelerators require more complex software management, with the need for an operating system controlling everything. The presence of the operating system opens more challenges to securing the final system’s full dependability. This paper analyses the hardening scenarios based on the evidence gathered by selective fault injection analysis of Real-Time Operating systems. While solutions might be delivered in different fashions, the emphasis on the paper is on the right approach to spot the sensitive part of the Operating system, saving the design from massive overheads."
Operating Systems (cs.OS),2022,16,Is Kernel Code Different From Non-Kernel Code? A Case Study of BSD Family Operating Systems,4,2206.05616,https://www.semanticscholar.org/paper/e990e2636e1324391ebe94e189010a7f48cb81cf,"Gunnar Kudrjavets, Jeff Thomas, Nachiappan Nagappan et al.","Studies on software evolution explore code churn and code velocity at the abstraction level of a company or an entire project. We argue that this approach misses the differences among abstractions layers and subsystems of large projects. We conduct a case study on four BSD family operating systems: DragonFlyBSD, FreeBSD, NetBSD, and OpenBSD, to investigate the evolution of code churn and code velocity across kernel and non-kernel code. We mine commits for characteristics such as annual growth rate, commit types, change type ratio, and size taxonomy, indicating code churn. Likewise, we investigate code velocity in terms of code review periods, i.e., time-to-first-response, time-to-accept, and time-to-merge.Our study provides evidence that software evolves differently at abstraction layers: kernel and non-kernel. The study finds similarities in the code base growth rate and distribution of commit types (neutral, additive, and subtractive) across BSD subsystems, however, (a) most commits contain either kernel or non-kernel code, (b) kernel commits are larger than non-kernel commits, and (c) code reviews for kernel code take longer than non-kernel code."
Operating Systems (cs.OS),2022,20,Docker Container Performance Comparison on Windows and Linux Operating Systems,3,N/A,https://www.semanticscholar.org/paper/bcaf7deecc61c509da2473d786c86538b9770345,"Anatoliy Sergeev, E. Rezedinova, A. Khakhina","Docker virtualization technology is now widely used not just in Linux, but also in Windows. When working with containers, it's critical to understand how Docker's performance on Windows compares to Docker's performance on Linux. Is it reasonable to execute a Linux program in a Docker container on Windows? A test tool was created to evaluate Docker's performance on Linux and Windows. This software determines the speed at which simple arithmetic operations are performed, the speed at which RAM is used, and the speed at which read/write operations on a disk drive are performed. This software has been tested on both Linux and Windows operating systems using a Docker container. Docker's arithmetic and memory performance on Linux is marginally better than on Windows, according to testing. Significant performance reduction is found only when communicating with an NVMe SSD under Windows. Thus, in the majority of scenarios, running Docker on Windows makes sense and does not result in substantial performance reduction."
Operating Systems (cs.OS),2023,1,MemGPT: Towards LLMs as Operating Systems,268,2310.08560,https://www.semanticscholar.org/paper/908dad62c0e43d80e3e3cb3c0402f7c71c70499c,"Charles Packer, Vivian Fang, Shishir G. Patil et al.","Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory. Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM's limited context window, and utilizes interrupts to manage control flow between itself and the user. We evaluate our OS-inspired design in two domains where the limited context windows of modern LLMs severely handicaps their performance: document analysis, where MemGPT is able to analyze large documents that far exceed the underlying LLM's context window, and multi-session chat, where MemGPT can create conversational agents that remember, reflect, and evolve dynamically through long-term interactions with their users. We release MemGPT code and data for our experiments at https://memgpt.ai."
Operating Systems (cs.OS),2023,2,ChatGPT for Computational Social Systems: From Conversational Applications to Human-Oriented Operating Systems,48,N/A,https://www.semanticscholar.org/paper/129487a87e137a982003ae1587f816b756970e7a,"Fei-Yue Wang, Juanjuan Li, Rui Qin et al.",No Abstract
Operating Systems (cs.OS),2023,3,The Catheter and Guidewire Operating Systems of Vascular Interventional Surgical Robots: A Systematic Review,13,N/A,https://www.semanticscholar.org/paper/6a62c1ca7834128308b1674afc8b9c83749567c8,"Pengfei Chen, Yutang Wang, Dapeng Tian et al.","Vascular interventional surgical robots (VISR) assisted doctors in surgery can not only protect doctors from X-ray radiation, but also improve the accuracy of surgery. The catheter and guidewire operating systems with master-slave operation mode play an important role in VISR. In recent years, the operating systems have gradually become a research hotspot. After nearly two decades of development, they have made great progress, but there are still some problems to be solved. This review first introduces the research necessity and development history of these operating systems. Then, we summarize the research direction of operating systems from the perspective of hardware devices and algorithms. In the hardware devices, we analyzed the catheter and guidewire operating mechanisms, contact force detection devices, master operating mechanisms and master force feedback devices. In the algorithm, we introduce the bilateral control methods, security strategies and skill evaluation methods. Next, we discuss the actual performance and shortcomings of the operating systems from the perspective of clinical application. Finally, we summarize the current problems of the operating systems and propose the future development direction. This review is helpful for researchers to understand the current situation, and provides a reference framework of catheter and guidewire operating system."
Operating Systems (cs.OS),2023,4,"We are meeting on Microsoft Teams: Forensic analysis in Windows, Android, and iOS operating systems",12,N/A,https://www.semanticscholar.org/paper/cd94947b599c136cf7c90deec3c0f4993dd0818b,"H. Bowling, Kathryn C. Seigfried-Spellar, Umit Karabiyik et al.","Microsoft released a new communication platform, Microsoft Teams, in 2017. Due in part to COVID‐19, the popularity of communication platforms, like Microsoft Teams, increased exponentially. Given its user base and increased popularity, it seems likely that digital forensic investigators will encounter cases where Microsoft Teams is a relevant component. However, because Microsoft Teams is a relatively new application, there is limited forensic research on the application particularly focusing on mobile operating systems. To address this gap, an analysis of data stored at rest by Microsoft Teams was conducted on the Windows 10 operating system as well as on Android and Apple iOS mobile operating systems. Basic functionalities, such as messaging, sharing files, participating in video conferences, and other functionalities that Teams provides, were performed in an isolated testing environment. Cellebrite UFED Physical Analyzer and Magnet AXIOM Examine tools were used to analyze the mobile devices and the Windows device, respectively. Manual or non‐automated investigation recovered, at least partially, the majority of artifacts across all three operating systems. In this study, a total of 77.6% of the populated artifacts were partially or fully recovered in the manual investigation. On the other hand, forensic tools used did not automatically recover many of the artifacts found with the manual investigation. Only 13.8% of artifacts were partially or fully recovered by the forensic tools across all three devices. These discovered artifacts and the results of the investigations are presented in order to aid digital forensic investigations."
Operating Systems (cs.OS),2023,6,An Overview of Computer Operating Systems and Emerging Trends,5,N/A,https://www.semanticscholar.org/paper/ba69f6267cba6d438d6436fa6d86eff9cfcb4716,"Robert Bazuku, Anaamotulim Anab, Seth Gyemerah et al.","This article presents an overview of computer operating systems (OS) and emerging trends. OS is simply defined as an interface between computer hardware and the user. The objective of the study is to investigate the emerging trends of OS and to find out the direction of OS for modern computing systems. To achieve this goal the paper looks at the concepts of OS, its underlying architectures and evolution. The papers also outline the components of the OS provide knowledge on security issues with OS architectures and provide best practices to secure OS. The paper found out that the current trends in OS include IoT OS, Cloud OS, AI-powered OS, Blockchain OS, Hybrid OS and Container OS. The paper compares the strengths and weaknesses of the major OS. The Paper proposes a double-layer security approach where the OS is hardened with security policies and embedding security protocols in the Hardware architecture of the OS. It was discovered that every technology comes with its unique architecture and OS. This makes it worrisome for engineers to crack their brains to develop such a system. The paper further proposes the development of a universal OS for all architectures leaving room for further expansion while mitigating power consumption issues by incorporating green computing technology in the design architecture."
Operating Systems (cs.OS),2023,5,A Comprehensive Review on Functional Analysis of Real-Time Operating Systems,4,N/A,https://www.semanticscholar.org/paper/e9a6cd5aaf8efc27130901eb3d62dd4dadf41ea4,"B. Sharan, Nripesh Reddy, B. S. Venkat et al.","A real-time operating system (RTOS) is a system made to help us in real-time using real-time applications that provide no delay. A RTOS is time-bound, which means that time is the main part of the system, as the system will fail if it goes beyond the prescribed time. Processing the time requirements in this system are measured in tenths of seconds. The integrity of an RTOS system established not only takes the logical effects of computation into account but also the amount of time required to get such results. It must prioritize vital jobs while keeping context-switching time to a minimum. This research aims to perform a comprehensive functional analysis of real-time operating systems (RTOS), with a particular emphasis on key components such as interrupt handling strategies, synchronization mechanisms, and job scheduling algorithms. The purpose of the study is to shed light on the state of the art at the moment, point out roadblocks, and suggest possible enhancements for raising RTOS capability and performance in significant embedded systems."
Operating Systems (cs.OS),2023,7,RPM: Ransomware Prevention and Mitigation Using Operating Systems' Sensing Tactics,4,N/A,https://www.semanticscholar.org/paper/40c4dbb93b0f37f89b6ed22a878eafb127519b2c,"Ricardo Misael Ayala Molina, E. Bou-Harb, Sadegh Torabi et al.","Ransomware, an extortion type of malware, continues to create havoc targeting critical infrastructure and organizations at large, causing an estimated $20 Billion in direct and collateral damages in 2022. While significant efforts from both academia and industry are being pledged to address this debilitating and disrupting phenomena, the ransomware pandemic continues to expand rapidly in frequency, spread and stealthiness. To this end, in this work, we propose RPM, a Ransomware Prevention and Mitigation scheme. RPM is rooted in the proactive analysis of operating systems' API artifacts through the exploitation of a neat observation related to ransomware behavior, namely, activities generated prior to the actual execution of the malicious payloads. RPM employs OS-centric process hooking tactics to develop an offensive approach leveraging such sensing activities. To demonstrate the effectiveness of RPM, we empirically evaluated it using 100 of the most prominent ransomware samples. The results demonstrate very motivating accuracy metrics with low system footprint, asserting the rationale of the proposed scheme. We posture RPM as a strong step towards proactive mitigation, which aims at complimenting ongoing ransomware thwarting efforts."
Operating Systems (cs.OS),2023,8,On a Foundation Model for Operating Systems,3,2312.07813,https://www.semanticscholar.org/paper/9b580b32de576d76ed6522c5e478c33ca9ced953,"Divyanshu Saxena, Nihal Sharma, Donghyun Kim et al.","This paper lays down the research agenda for a domain-specific foundation model for operating systems (OSes). Our case for a foundation model revolves around the observations that several OS components such as CPU, memory, and network subsystems are interrelated and that OS traces offer the ideal dataset for a foundation model to grasp the intricacies of diverse OS components and their behavior in varying environments and workloads. We discuss a wide range of possibilities that then arise, from employing foundation models as policy agents to utilizing them as generators and predictors to assist traditional OS control algorithms. Our hope is that this paper spurs further research into OS foundation models and creating the next generation of operating systems for the evolving computing landscape."
Operating Systems (cs.OS),2023,9,Encryption Methods and Algorithms Based on Domestic Standards in Open-Source Operating Systems,3,N/A,https://www.semanticscholar.org/paper/ec923fddac9b4dbcebdc51cd61fa7c0a0693e04c,"M. Karimov, N. Ochilov, Abdiqahhar Egamovich Tangirov","The paper describes the principles and methods underlying the creation of an application in secure operating systems, which provides reliable data encryption. The research aims to analyze and indicate the specifics of encryption methods and algorithms based on domestic standards in open-source operating systems. Cryptanalysis was used in the article, as this avoids vulnerabilities identified in previously created implementations. In the article, the authors draw attention to the fact that 7-Zip uses CBC encryption (concatenation of encrypted text blocks), but the Counter Mode is supported. The same support was provided in the encrypt implementation. Since the key expansion function initially fills the special array created by p7zip with round keys using a unique property of the domestic standard, only one round encryption function was created (performed both during encryption and decryption). This method is also used in various modes. In many cases, initialization time deviations depending on the selected mode are insignificant. The created cryptographic module was tested to meet the domestic standard, which contains several test cases. It was confirmed during the tests that the created module implements the algorithm of the domestic standard. The article shows a way to implement a fairly convenient graphical interface for accessing the cryptographic module, which enables the user not to call the command line and remember the sequence and types of parameters passed to p7zip. This implementation also takes into account the verification of the correctness of decryption and the reading of other error codes."
Operating Systems (cs.OS),2023,10,A Formal Approach to Design and Security Verification of Operating Systems for Intelligent Transportation Systems Based on Object Model,2,N/A,https://www.semanticscholar.org/paper/cea3263b7dc5d40a0591c49151beb1c57d0415c2,"Zhenjiang Qian, Shan Zhong, Gaofei Sun et al.","Operating system in intelligent transportation systems (ITSs) is a complex software system whose correctness and security are not obvious. There are advances in formal description and verification of operating systems in ITSs recently and they mainly focus on bottom-up proofs in which the source codes satisfy certain expected properties expressed by logic formulae. In this paper, we propose a layered object model for operating systems in ITSs. This model includes functionality layer, refinement layer and concrete layer. We consider the operating system object model as a logic system ( $L$ ) with variables representing the objects of $L$ , and a series of logic formulae for security and functional configurations in security of ITSs. We establish a mathematical structure as a domain of discourse for operating system in ITSs and accordingly, construct a mapping from operating system objects to the domain. In this way, we propose a formal method to verify the operating system security properties and configurations in ITSs. We use the virtual memory management part of our self-designed operating system VSOS as an example to illustrate the model and show that the claimed security properties can be rigorously proven for ITSs. The evaluation and verification of VSOS indicate that the proposed model implementation is feasible and achieves the security goals."
Operating Systems (cs.OS),2023,11,Back to the Core-Memory Age: Running Operating Systems in NVRAM only,2,N/A,https://www.semanticscholar.org/paper/9aef8c4619918602fceca1a029bc204d79922bf9,"Jonas Rabenstein, D. Nguyen, Oliver Giersch et al.",No Abstract
Operating Systems (cs.OS),2023,12,Automation and Management in Operating Systems: The Role of Artificial Intelligence and Machine Learning,2,N/A,https://www.semanticscholar.org/paper/180afb66a5a20b97bb85b3cb9dc5a72f3673aaea,"Nataliia Korshun, Ivan Myshko, Olha Tkachenko",No Abstract
Operating Systems (cs.OS),2023,13,Mobile Operating Systems’ Impact on Customer Value: IOS vs. Android,2,N/A,https://www.semanticscholar.org/paper/a8c31348a16455939fc358b491b1849e21407f7f,"Jiyao Xun, Woon Kian Chong, Les Dolega","ABSTRACT Amidst the growing focus on media engagement and customer value in retail marketing literature, mobile commerce (MC) research has gained prominence. This research explores how customers employ mobile operating systems to engage with retailers and extract value within the context of Fast Moving Consumer Goods (FMCG) in retail. In Study 1, a survey involving 398 users uncovered that the customer handset OS moderates the effects of social media, traditional media engagement, and retail “place” on customer value. In Study 2, leveraging data from a foreign FMCG brand deeply immersed in social media platforms, we scrutinize how such engagement dynamics affect the influence of “place” on product sales across e-commerce and conventional retail channels. Our findings make significant theoretical contributions to comprehending customer value in MC, with practical implications for marketers, emphasizing the potential of customer mobile operating system as a valuable tool for effective marketing strategies."
Operating Systems (cs.OS),2023,14,Design and implementation of a real-time simulation platform for embedded applications on general-purpose operating systems,2,N/A,https://www.semanticscholar.org/paper/6fac931b8deb190a76dca4bdde1df39d30476b05,"Jinchao Chen, Haoran Zhang, Ruimeng He et al.","In recent years, the number of invested resources adopted in experiments of embedded applications dropped significantly as many simulation technologies are widely used. However, the efficiency of simulations is seriously influenced by some expensive and difficult-to-obtain devices. It is urgent and of great significance to build a universal simulation platform for embedded applications on general-purpose operating systems with an objective of improving the efficiency and effectiveness of system development and implementation. Since virtualization technology can greatly enhance the simulation efficiency by providing virtual models to simulate the behaviors of real devices, this paper designs and realizes a real-time simulation platform on general-purpose operating systems with the virtualization technology such that embedded applications would be correctly and efficiently debugged and tested on the general-purpose operating systems. The proposed simulation platform contains four layers named hardware resource, virtualization, virtual runtime environment, and interface adaptation, allowing dynamic debugging and testing of embedded applications without requiring the actual presence of real devices. Experiments are conducted to verify the functionalities of the proposed simulation platform, and results demonstrate that the proposed simulation platform can meet the real-time and high reliability requirements of embedded applications."
Operating Systems (cs.OS),2023,15,"A Comparative Study of Modern Operating Systems in terms of Memory and Security: A Case Study of Windows, iOS, and Android",2,N/A,https://www.semanticscholar.org/paper/d863e307f5c6195a5cf3841ae0a13b3ffce7801b,A. Umar,"Modern computer systems have an operating system, which serves as an interface between the device and the user and has the dual objectives of making the device easier to operate and making optimal use of device resources. The operating system offers some level of computer security like user authentication, file permission, firewall, encryption etc., but occasionally, problems develop due to societal or technical challenges like: vulnerable to malicious programs and viruses, which can cause the system to become sluggish or malicious actors be able to have an access to confidential user data, which compromise computer security. This comparative study provides insight into each of these operating systems and their relative strengths and weaknesses. The paper begins by discussing the concepts of memory management and security in general and then examines the specifics of each OS's memory management and security features. A case study of three popular applications is presented to illustrate how memory management and security features can be used in practice. The results of the comparison show that while each operating system has its own advantages and disadvantages, Windows is generally the most powerful and secure of the three, while iOS and Android offer more flexibility and ease of use."
Operating Systems (cs.OS),2023,16,Augmented reality and virtual reality technologies in surgical operating systems,2,N/A,https://www.semanticscholar.org/paper/0bc19c901aa36ebb431bad00d0422f803f4cd70e,"Eswaran Ushaa, Eswaran Vishal","Augmented Reality (AR) and Virtual Reality (VR) technologies have been used to transform surgical operating systems by enhancing visualization, preoperative planning, intraoperative navigation, and surgical training. AR and VR are simulated imaging tools used in surgery. Using 2D and 3D image rendering from VR/AR tools, surgeons can mimic real surgical procedures and anatomy, thereby boosting preparedness and efficiency in the operating room. However, validity, cost, training requirements, and ethical concerns remain. This study provided a comprehensive review of AR/VR applications across surgical workflows. A conceptual framework was proposed which included safety, accuracy, regulation, education, and workflow integration. Future research must balance innovation with clinical prudence to realize the potential of AR/VR while managing risks. This review synthesizes insights that serve as a knowledge base for transforming surgical systems using immersive technologies."
Operating Systems (cs.OS),2023,17,Model-Checking in the Loop Model-Based Testing for Automotive Operating Systems,2,2310.00973,https://www.semanticscholar.org/paper/590cbc5a9b4e33bca15ef564fe3a193531d76fe6,"Toshiaki Aoki, Aritoshi Hata, Kazusato Kanamori et al.","While vehicles have primarily been controlled through mechanical means in years past, an increasing number of embedded control systems are being installed and used, keeping pace with advances in electronic control technology and performance. Automotive systems consist of multiple components developed by a range of vendors. To accelerate developments in embedded control systems, industrial standards such as AUTOSAR are being defined for automotive systems, including the design of operating system and middleware technologies. Crucial to ensuring the safety of automotive systems, the operating system is foundational software on which many automotive applications are executed. In this paper, we propose an integrated model-based method for verifying automotive operating systems; our method is called Model-Checking in the Loop Model-Based Testing (MCIL-MBT). In MCIL-MBT, we create a model that formalizes specifications of automotive operating systems and verifies the specifications via model-checking. Next, we conduct model-based testing with the verified model to ensure that a specific operating system implementation conforms to the model. These verification and testing stages are iterated over until no flaws are detected. Our method has already been introduced to an automotive system supplier and an operating system vendor. Through our approach, we successfully identified flaws that were not detected by conventional review and testing methods."
Operating Systems (cs.OS),2023,18,Obsolescence in Operating Systems and Microprocessors,2,N/A,https://www.semanticscholar.org/paper/8b3c96b23f4f08acf05e81c05a46ffcb084ba69e,"Dheeraj N. Naraharisetti, R. Karne, J. Weymouth et al.",Obsolescence and its impacts on software and systems continue to be of interest. Reducing obsolescence in operating systems and microprocessors will help to reduce software obsolescence. We examine obsolescence in Intel microprocessors and Windows operating systems. We first present data that illustrates the extent of the problem. We then consider extensible designs to reduce obsolescence in operating systems and microprocessors. This approach can be adapted to design software and hardware that are resilient to obsolescence.
Operating Systems (cs.OS),2023,19,The Effect of Business Operating Systems on Nursing Home Termination,2,N/A,https://www.semanticscholar.org/paper/62e49150369330ba0fbb180e23d17faeddb8c373,"Xueying Jin, K. Uda, Miho Ishimaru et al.","Objectives: Nursing home terminations have increased worldwide due to rising costs, staffing shortages, and the coronavirus disease pandemic. However, little is known about the impact that business operating systems have on nursing home termination. Methods: This study used the National Long-term Care database, which comprised 7,842 operating nursing homes in January 2018. Nursing home termination was identified when nursing homes discontinued provision of long-term care services to all residents between January 2018 and December 2020. Business operating systems that were reimbursed by the LTC insurance system were the exposure of interest. The logistic regression model for nursing home termination included a series of organizational, internal, and external factors as covariates. Results: From 2018 to 2020, 83 (1.1%) nursing homes were terminated. The proportion of reimbursed nursing homes varied greatly depending on the type of business operating systems. Implementing physical function training and improving working conditions were significantly associated with a lower risk of nursing home termination. Conclusion: Financial incentives to several business operating systems are an effective way to build a sustainable environment for nursing homes to continue to exist."
Operating Systems (cs.OS),2023,20,Towards Just-In-Time Compiling of Operating Systems,2,N/A,https://www.semanticscholar.org/paper/b18add210b3012b16840e8fa59a0ba48a6d07f44,"Maximilian Ott, Phillip Raffeck, V. Sieh et al.","Operating systems are crucial for the performance of the overall system. Any inefficiency leads to a suboptimal use of the available resources and causes performance loss. The wide range of processors in use today makes it challenging to generate the most efficient code for the current hardware ahead of time. Just-in-time compilation, on the other hand, is able to generate efficient code tailored to the current execution context going beyond the processor, also including operating-system configuration or application demands. Moreover, its configuration can even be adapted at runtime to match the current external and internal requirements. Unfortunately, on-demand compilation of operating-system code has not found widespread use due to inherent difficulties stemming from the fact that any just-in-time approach requires extensive runtime support (e.g., for memory allocation for the generated code) usually provided by the operating system itself. A chicken-and-egg problem is found. We believe that this problem of mutual dependency can be resolved and that on-demand compilation of operating-system code can yield the most suitable code for the actual execution context by exploiting runtime knowledge. In this paper, we outline the DOSY approach for just-in-time compilation of operating systems, focusing on the necessary means of overcoming all resource restrictions in the form of a standalone auxiliary interpreter. We implement an interpreter prototype in the memory-safe programming language Rust. Initial measurements indicate promising performance results, encouraging further work towards complete just-in-time compilation of operating systems."
Operating Systems (cs.OS),2024,1,"Smart Mining With Autonomous Driving in Industry 5.0: Architectures, Platforms, Operating Systems, Foundation Models, and Applications",30,N/A,https://www.semanticscholar.org/paper/1e026892e9aa9bfb212b6fd46efee79428a49b5e,"Long Chen, Yuchen Li, Wushour Silamu et al.","The increasing importance of mineral resources in contemporary society is becoming more prominent, playing an indispensable and crucial role in the global economy. These resources not only provide essential raw materials for the global economic system but also play an irreplaceable role in supporting the development of modern industry, technology, and infrastructure. With the rapid development of intelligent technologies such as Industry 5.0 and advanced Large Language Models (LLMs), the mining industry is facing unprecedented opportunities and challenges. The development of smart mines has become a crucial direction for industry progress. This article aims to explore the strategic requirements for the development of smart mines by combining advanced products or technologies such as Chat-GPT (one of the successful applications of LLMs), digital twins, and scenario engineering. We propose a comprehensive architecture consisting of three different levels, the mining industrial Internet of Things (IoT) platform, mining operating systems, and foundation models. The systems and models empower the mining equipment for transportation. The architecture delivers a comprehensive solution that aligns perfectly with the demands of Industry 5.0. The application and validation outcomes of this intelligent solution showcase a noteworthy enhancement in mining efficiency and a reduction in safety risks, thereby laying a sturdy groundwork for the advent of Mining 5.0."
Operating Systems (cs.OS),2024,3,LLM-Based Operating Systems for Automated Vehicles: A New Perspective,18,N/A,https://www.semanticscholar.org/paper/4ebb04b8b1496f2dd3a0d56ec32f84fa8e198b06,"Jingwei Ge, Chen Chang, Jiawei Zhang et al.","The deployment of large language models (LLMs) brings challenges to intelligent systems because its capability of integrating large-scale training data facilitates contextual reasoning. This paper envisions a revolution of the LLM based (Artificial) Intelligent Operating Systems (IOS, or AIOS) to support the core of automated vehicles. We explain the structure of this LLM-OS and discuss the resulting benefits and implementation difficulties."
Operating Systems (cs.OS),2024,2,Evaluating the role of cloud integration in mobile and desktop operating systems,17,N/A,https://www.semanticscholar.org/paper/3b7b5ff75ccb145e89c390b9346166a940357e6f,"Osinachi Deborah Segun-Falade, Olajide Soji Osundare, Wagobera Edgar Kedi et al.","The integration of cloud computing has fundamentally transformed the landscape of mobile and desktop operating systems, enabling new levels of functionality, efficiency, and user experience. This review examines the role of cloud integration in these operating systems and its implications for both users and developers. Cloud integration enhances mobile and desktop operating systems by offering scalable storage solutions, seamless data synchronization, and enhanced computing power. For mobile systems, cloud services provide users with the ability to access their data and applications from any device, promoting a consistent user experience across different platforms. This synchronization feature not only streamlines personal data management but also enables developers to create more dynamic and responsive applications that leverage cloud resources for realtime updates and performance improvements. In desktop environments, cloud integration facilitates the storage of large volumes of data and the execution of resourceintensive applications without burdening local hardware. Cloudbased virtual machines and application delivery platforms offer users the flexibility to run highperformance software on less powerful devices, thus broadening the accessibility and usability of advanced desktop applications. Furthermore, cloud integration supports collaborative tools and shared workspaces, enhancing productivity and fostering realtime collaboration among users. The evaluation of cloud integration also involves assessing its impact on security, data privacy, and system performance. Cloudbased solutions introduce new security considerations, such as the need for robust encryption and secure authentication protocols to protect sensitive data. Additionally, the reliance on internet connectivity for accessing cloud services can pose challenges for users in areas with limited or unreliable network access. In conclusion, cloud integration plays a crucial role in modernizing both mobile and desktop operating systems, driving improvements in data accessibility, application performance, and user experience. As cloud technologies continue to evolve, their influence on operating systems will likely expand, offering new opportunities for innovation and addressing emerging challenges in security and connectivity. This ongoing integration represents a significant shift towards more flexible, efficient, and interconnected computing environments."
Operating Systems (cs.OS),2024,5,Securing Operating Systems (OS): A Comprehensive Approach to Security with Best Practices and Techniques,12,N/A,https://www.semanticscholar.org/paper/b09bc0e08b72983ebf6b54559f38f80e54065b04,Zarif Bin Akhtar,"Abstract Operating system (OS) security is paramount in ensuring the integrity, confidentiality, and availability of computer systems and data. This research manuscript presents a comprehensive investigation into the multifaceted domain of OS security, aiming to enhance understanding, identify challenges, and propose effective solutions. The research methodology integrates diverse approaches, including an extensive exploration for available knowledge process mechanics, empirical data collection, case studies investigations, experimental analysis, comparative studies, qualitative analysis, synthesis, and interpretation. Through various experimental perspectives, theoretical foundations, historical developments, and current trends in OS security are also explored. Empirical data collection involves gathering insights from publicly available reports, security advisories, case studies, and expert interviews to capture real-world perspectives and experiences. Case studies illustrate practical implications of security strategies, while experimental analysis evaluates the efficacy of security measures in controlled environments. Comparative studies and qualitative analysis provide insights into strengths, limitations, and emerging trends in OS security. The synthesis and interpretation of the findings offer actionable insights for improving OS security practices, policy recommendations, and providing towards future research directions. This research contributes to advancing knowledge in OS security and informs the development of effective strategies to safeguard computer systems against evolving threats and vulnerabilities."
Operating Systems (cs.OS),2024,6,A survey on security issues in IoT operating systems,12,N/A,https://www.semanticscholar.org/paper/511ae9c052e0fb47e92d2b7a5bdd793dc84cc34c,"Panjun Sun, Yi Wan, Zong-Bing Wu et al.",No Abstract
Operating Systems (cs.OS),2024,4,Passively sensing smartphone use in teens with rates of use by sex and across operating systems,10,N/A,https://www.semanticscholar.org/paper/016425bbf54a3899df4327bf5275a8aa57ecada4,"Jordan D. Alexander, Janosch Linkersdörfer, Katherine Toda-Thorne et al.","Youth screen media activity is a growing concern, though few studies include objective usage data. Through the longitudinal, U.S.-based Adolescent Brain Cognitive Development (ABCD) Study, youth (mage = 14; n = 1415) self-reported their typical smartphone use and passively recorded three weeks of smartphone use via the ABCD-specific Effortless Assessment Research System (EARS) application. Here we describe and validate passively-sensed smartphone keyboard and app use measures, provide code to harmonize measures across operating systems, and describe trends in adolescent smartphone use. Keyboard and app-use measures were reliable and positively correlated with one another (r = 0.33) and with self-reported use (rs = 0.21–0.35). Participants recorded a mean of 5 h of daily smartphone use, which is two more hours than they self-reported. Further, females logged more smartphone use than males. Smartphone use was recorded at all hours, peaking on average from 8 to 10 PM and lowest from 3 to 5 AM. Social media and texting apps comprised nearly half of all use. Data are openly available to approved investigators (https://nda.nih.gov/abcd/). Information herein can inform use of the ABCD dataset to longitudinally study health and neurodevelopmental correlates of adolescent smartphone use."
Operating Systems (cs.OS),2024,7,Docker Performance Evaluation across Operating Systems,7,N/A,https://www.semanticscholar.org/paper/b2f7d8b5a979e87c2aeb9e8e437784e3dae1644b,"Maciej Sobieraj, Daniel Kotyński","Docker has gained significant popularity in recent years. With the introduction of Docker Desktop for Windows and macOS, there is a need to determine the impact of the operating system on the performance of the Docker platform. This paper aims to investigate the performance of Docker containers based on the operating system. One of the fundamental goals of this study is to conduct a comprehensive analysis of the Docker architecture. This technology utilizes Linux kernel virtualization mechanisms such as namespaces and cgroups. Upon analyzing the distribution of Docker Desktop for Windows and Docker Desktop for macOS, it was discovered that running the Docker environment on these requires a lightweight virtual machine that emulates the Linux system. This information suggests that the additional virtualization layer may hinder the performance of non-Linux operating systems hosting Docker containers. The paper presents a performance test of the Docker runtime on Linux, Microsoft Windows, and macOS. The test evaluated specific aspects of operating system performance on a MacBook computer with an ×86/64 processor architecture. The experiment carried out examined the performance in terms of CPU speed, I/O speed, and network throughput. This test measured the efficiency of software that utilizes various system resources."
Operating Systems (cs.OS),2024,11,Reusable formal models for concurrency and communication in custom real-time operating systems,6,N/A,https://www.semanticscholar.org/paper/89f4e42821cecb15c07372539bf0e53e2d319961,"Julius Adelt, Julian Gebker, Paula Herber","In embedded systems, the execution semantics of the real-time operating system (RTOS), which is responsible for scheduling and timely execution of concurrent processes, is crucial for the correctness of the overall system. However, existing approaches for the formal verification of embedded systems typically abstract from the RTOS completely, or provide a detailed and synthesizable formal model of the RTOS. While the former may lead to unsafe systems, the latter is not compatible with industrial design processes. In this paper, we present an approach for reusable abstract formal models that can be configured for custom RTOS. Our key idea is to formally capture common execution mechanisms of RTOS like preemptive scheduling, event synchronization, and communication abstractly in configurable timed automata models. These abstract formal models can be configured for a concrete custom RTOS, and they can be combined into a formal system model together with a concrete application. Our reusable models significantly reduce the manual effort of defining a formal model that captures concurrency and real-time behavior, together with the functionality of an application. The resulting formal model enables analysis, verification, and graphical simulation. We validate our approach by formalizing and analyzing a rescue robot application running the custom open source RTOS EV3RT."
Operating Systems (cs.OS),2024,8,Overview of Embedded Rust Operating Systems and Frameworks,5,N/A,https://www.semanticscholar.org/paper/07eab5f04c988aee710edb3535e712517c4a1c9b,"T. Vandervelden, Ruben de Smet, Diana Deac et al.","Embedded Operating Systems (OSs) are often developed in the C programming language. Developers justify this choice by the performance that can be achieved, the low memory footprint, and the ease of mapping hardware to software, as well as the strong adoption by industry of this programming language. The downside is that C is prone to security vulnerabilities unknowingly introduced by the software developer. Examples of such vulnerabilities are use-after-free, and buffer overflows. Like C, Rust is a compiled programming language that guarantees memory safety at compile time by adhering to a set of rules. There already exist a few OSs and frameworks that are entirely written in Rust, targeting sensor nodes. In this work, we give an overview of these OSs and frameworks and compare them on the basis of the features they provide, such as application isolation, scheduling, inter-process communication, and networking. Furthermore, we compare the OSs on the basis of the performance they provide, such as cycles and memory usage."
Operating Systems (cs.OS),2024,9,NExt generation Meta Operating systems (NEMO) and Data Space: envisioning the future,4,N/A,https://www.semanticscholar.org/paper/7a2c6256675abd5bb4b2d3575d8d916e23da7500,"Olga Segou, Dimitris S. Skias, T. Velivassaki et al.","Data Spaces are the vehicle for data-driven innovation and great opportunity for European industries. Data spaces will establish a framework for the responsible and ethical use of data, with a focus on data privacy, security, and sovereignty that ensures seamless exchange of data across different sectors, organizations, and member states. Effective delivery of services within Data Spaces mandate for efficient and effective use of available resources across the IoT, edge and cloud continuum, while enforcing security and privacy policies, monitoring infrastructure and transaction mechanisms required to ensure data sovereignty, observability and accountability of data exchanges. Herein, we present the NExt generation Meta Operating systems (NEMO)https://meta-os.eu/ architecture approach embracing Data Spaces, hosting Connectors and services within Data Spaces, delivered as extensible element of the metaOS architecture. We also propose a Fiware-based Industrial Data Space Connector for NEMO enabling to organise and valorise large pools of data, as a significant cornerstone of data-driven innovation."
Operating Systems (cs.OS),2024,10,Effectively Sanitizing Embedded Operating Systems,3,N/A,https://www.semanticscholar.org/paper/40defeee9f68096ef2fbd01e7a6881208bbf1275,"Jianzhong Liu, Yuheng Shen, Yiru Xu et al.","Embedded operating systems, considering their widespread use in security-critical applications, are not effectively tested with sanitizers to effectively root out bugs. Sanitizers provide a means to detect bugs that are not visible directly through exceptional or erroneous behaviors, thus uncovering more potent bugs during testing. In this paper, we propose EmbSan, an embedded systems sanitizer for a diverse range of embedded operating system firmware through the use of dynamic instrumentation of sanitizer facilities and de-coupled on-host runtime libraries. This allows us to perform sanitation for multiple embedded OSs during fuzzing, such as many Embedded Linux-based firmware, various FreeRTOS firmware, and detect actual bugs within them. We evaluated EmbSan's effective-ness on firmware images based on Embedded Linux, FreeRTOS, LiteOS, and VxWorks. Our results show that EmbSan can detect the same criteria of actual bugs found in the Embedded Linux kernel as reference implementations of KASAN, and exhibits a slowdown of 2.2× to 3.2× and 5.2× to 5.7× for KASAN and KCSAN, respectively, which is on par with established kernel sanitizers. EmbSan and embedded OS fuzzers also found a total of 41 new bugs in Embedded Linux, FreeRTOS, LiteOS and VxWorks."
Operating Systems (cs.OS),2024,13,An Intelligent Approach to Automated Operating Systems Log Analysis for Enhanced Security,2,N/A,https://www.semanticscholar.org/paper/780a6fa8fc264bcf69c60597c99d09c44bdb820c,"Obinna Johnphill, A. Sadiq, Omprakash Kaiwartya et al.","Self-healing systems have become essential in modern computing for ensuring continuous and secure operations while minimising downtime and maintenance costs. These systems autonomously detect, diagnose, and correct anomalies, with effective self-healing relying on accurate interpretation of system logs generated by operating systems (OSs). Manual analysis of these logs in complex environments is often cumbersome, time-consuming, and error-prone, highlighting the need for automated, reliable log analysis methods. Our research introduces an intelligent methodology for creating self-healing systems for multiple OSs, focusing on log classification using CountVectorizer and the Multinomial Naive Bayes algorithm. This approach involves preprocessing OS logs to ensure quality, converting them into a numerical format with CountVectorizer, and then classifying them using the Naive Bayes algorithm. The system classifies multiple OS logs into distinct categories, identifying errors and warnings. We tested our model on logs from four major OSs; Mac, Android, Linux, and Windows; sourced from Zenodo to simulate real-world scenarios. The model’s accuracy, precision, and reliability were evaluated, demonstrating its potential for deployment in practical self-healing systems."
Operating Systems (cs.OS),2024,14,Development and Analysis of Mathematical Algorithms Models and Processes Synchronization Functions in Operating Systems for Embedded Reconfigurable Computing Systems,2,N/A,https://www.semanticscholar.org/paper/9e432eb3766319eb02809d118cc7e5ce6919893e,A. Martyshkin,"The study presented in this article delves into mathematical models pertaining to algorithmic and process synchronization functions within operating systems tailored for embedded reconfigurable computing systems. Furthermore, the article explores the hardware implementation of these algorithms and process synchronization functions. The discussion encompasses an examination of the key merits and drawbacks associated with existing models, along with considerations for potential updates. Included are diagrams illustrating a hardware-implemented reconfigurable system and its operational processes. The practical application of the obtained results is situated within computing systems, emphasizing the significance of productivity and efficiency enhancement. In the conclusion are presented the inferences based on the main results of the research."
Operating Systems (cs.OS),2024,17,WIMS : A Modern Web-Based MIPS Simulator for Improved Learning in Computer Architecture and Operating Systems,2,N/A,https://www.semanticscholar.org/paper/756b8a77b69348647c37af1773cf95cab4c8eaa3,"Reinaldo Assis, Bruno Nogueira","The MIPS processor is well-regarded in teaching Computer Architecture and Operating Systems due to its simpler architecture and efficient design. Simulators are a highly effective method for learning MIPS. Current simulators, like MARS, face issues such as lack of data path visualization, outdated interfaces, and installation requirements, which impede student learning. This work aims to develop an accessible online MIPS simulator featuring a modern code editor, data path visualization, step-by-step execution, and memory visualization. The simulator runs in a web browser, eliminating installation barriers and enhancing usability. This tool aims to improve the educational experience and deepen students’ understanding of MIPS architecture and assembly programming."
Operating Systems (cs.OS),2024,18,Implementing the principle of least administrative privilege on operating systems: challenges and perspectives,2,N/A,https://www.semanticscholar.org/paper/952cfaee0f78ecbf9afe31849b3815dda05974f7,"Eddie Billoir, R. Laborde, A. Wazan et al.",No Abstract
Operating Systems (cs.OS),2024,12,Enhanced Intrusion Detection in Robot Operating Systems via Grid Search Based Multi-Head Attention Stacked Convolutional Network,1,N/A,https://www.semanticscholar.org/paper/7e20bf2e2893567cc5c49d152d18087e1008c870,"M. H. Zafar, Even Falkenberg Langås, Muhammad Faisal Aftab et al.","This study presents a novel intrusion detection system (IDS) for Robot Operating Systems (ROS), utilising a hybrid neural network combining 1D Convolutional Neural Networks (CNNs) with Multi-head Attention (MHA). This approach effectively captures both local and global data features, essential for detecting security threats in ROS. The model architecture includes layers of 1D-CNNs for detailed temporal feature extraction, complemented by MHA to identify complex intrusion patterns. Extensive hyperparameter optimisation through grid search ensures optimal model performance. A key aspect of this research is the use of the recently introduced ROSIDS23 dataset, which provides a comprehensive and realistic benchmark for testing. The model demonstrated exceptional accuracy, achieving 99% in training and greater than 97% in testing, highlighting its efficacy in ROS security enhancement. These results and the utilisation of ROSIDS23 dataset mark significant advancements in the field of robotic security."
Operating Systems (cs.OS),2024,15,Advances In CPU Scheduling Algorithms in Operating Systems,1,N/A,https://www.semanticscholar.org/paper/fc94f406cda2886c5f6d42cc31e66e9215e80199,Lei Li,"CPU scheduling algorithms significantly influence Operating System (OS) performance. Many studies have proposed optimized scheduling algorithms. This paper outlines the main characteristics of common scheduling algorithms, including First Come First Served (FCFS), Shortest Job First (SJF), Round Robin (RR), Priority Scheduling, and Highest Response Ratio Next (HRRN). It reviews comparative performance research on these algorithms and mentions their optimizations to summarize the progress in this field. This paper also analyses two specific operating systems - Time-Sharing Systems and Embedded Systems, and introduces scheduling algorithms applicable to these two systems and their typical applications. The review finds that SJF & SPTF perform better than FCFS and RR in terms of waiting time, while HRRN also significantly outperforms RR. The optimization of the scheduling algorithm mainly focuses on RR, by clustering techniques and dynamically resizing the quantum time. For time-sharing systems, RR is the most common strategy, while the Linux kernel adopts the Completely Fair Scheduler (CFS). For embedded systems, the real-time scheduling algorithms, Earliest Deadline First(EDF) and Least Slack Time(LST), are applicable to soft real-time systems."
Operating Systems (cs.OS),2024,16,Performance Comparison Analysis of Digital Forensic Tools in Various Operating Systems,1,N/A,https://www.semanticscholar.org/paper/77ed9f3dc1d5536c6bbc2c7f7e5f6cde9c47665c,"Christos Liambas, Athanasios Manios","It is known that experts widely use digital forensics tools, in order to investigate criminal cases. The main scope of this research is considered as the performance comparison of digital forensic tools in various Operating Systems, such as “Windows 10”, “Windows 11”, “Ubuntu”, and “Windowsfx”. This is done for optimization reasons and more specifically for the minimization of processing time in forensic data analysis. The research was divided into two main parts by using exactly the same hardware as well as the default Operating Systems' configuration. The first part presents the performance comparison of the above Operating Systems by using two benchmarking tools such as “Phoronix Test Suite” and “Indigobench”. The second part focuses on the performance measurements of the corresponding digital forensic tools “FTK Imager”, “Photorec”, “Quickhash” and “Peautils”. It should be noted that every tool is tested ten times in order to increase the accuracy of the averaged total execution time of every iteration. The results indicate that the “Windowsfx” Operating System has the best overall performance after exhausting research of testing all the aforementioned tools."
Operating Systems (cs.OS),2024,19,Open Source in NExt Generation Meta Operating Systems (NEMO),1,N/A,https://www.semanticscholar.org/paper/b2c150d4201ef113f0510b935b216e34a2d2f498,"R. Rossini, T. Velivassaki, Artemis C. Voulkidis et al.","The open source approach aligns with the values of transparency, collaboration, security, and digital sovereignty that are important to many European countries and institutions. It offers practical advantages, cost savings, and opportunities for innovation that contribute to the region's technological advancement and competitiveness. Open source software also fosters collaboration among developers and encourages innovation. On top of these values, NExt generation Meta Operating systems (NEMO) builds the future of the Artificial Intelli-gence of Things(AIoT)-edge-cloud continuum by introducing an open source, modular and cybersecure meta-operating system (metaOS). In this paper, the open source components of the NEMO metaOS are presented for each functional layer in the NEMO architecture, demonstrating the value of open source for the metaOS sustainability."
Operating Systems (cs.OS),2024,20,Teaching Process Management with an Operating Systems Simulator: The UR-OS Experience,1,N/A,https://www.semanticscholar.org/paper/b5a5594192f5104096f9f2ed1191e1fdb7ab2e79,Pedro Wightman,"Every computer science student must learn about operating systems fundamentals, including topics related to process planning, memory management, etc. Some basic concepts are mostly theoretical and have to be tested by hand because they are not implemented in modern OSs; however, understanding them is critical because they set the basis for all the existing techniques. This paper presents the first version of UR_OS. This new Java-based operating system simulator allows learning about process planning algorithms and the creation of new ones to evaluate their performance. This tool has been used in class and evaluated by the students in terms of how it supported their understanding of the topic and the usability of the tool. In addition, the grades in similar evaluations are compared to a traditional strategy to assess the tool's impact. The results show that the students had a very positive perception of working with the platform and felt that it indeed helped them to learn the concepts. Also, all students felt more motivated to work with a digital platform compared to a paper-based methodology."
Robotics (cs.RO),2020,1,Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey,889,2009.13303,https://www.semanticscholar.org/paper/5a1b92aa50797a7c1e99b8840ff01aad66038596,"Wenshuai Zhao, J. P. Queralta, Tomi Westerlund","Deep} reinforcement learning has recently seen huge success across multiple areas in the robotics domain. Owing to the limitations of gathering real-world data, i.e., sample inefficiency and the cost of collecting it, simulation environments are utilized for training the different agents. This not only aids in providing a potentially infinite data source, but also alleviates safety concerns with real robots. Nonetheless, the gap between the simulated and real worlds degrades the performance of the policies once the models are transferred into real robots. Multiple research efforts are therefore now being directed towards closing this sim-toreal gap and accomplish more efficient policy transfer. Recent years have seen the emergence of multiple methods applicable to different domains, but there is a lack, to the best of our knowledge, of a comprehensive review summarizing and putting into context the different methods. In this survey paper, we cover the fundamental background behind sim-to-real transfer in deep reinforcement learning and overview the main methods being utilized at the moment: domain randomization, domain adaptation, imitation learning, meta-learning and knowledge distillation. We categorize some of the most relevant recent works, and outline the main application scenarios. Finally, we discuss the main opportunities and challenges of the different approaches and point to the most promising directions."
Robotics (cs.RO),2020,2,Triboelectric nanogenerator sensors for soft robotics aiming at digital twin applications,516,N/A,https://www.semanticscholar.org/paper/2ded44b2a8691ad09d60e086ebfa79cbaab4980a,"Tao Jin, Zhongda Sun, Long Li et al.","Designing efficient sensors for soft robotics aiming at human machine interaction remains a challenge. Here, we report a smart soft-robotic gripper system based on triboelectric nanogenerator sensors to capture the continuous motion and tactile information for soft gripper. With the special distributed electrodes, the tactile sensor can perceive the contact position and area of external stimuli. The gear-based length sensor with a stretchable strip allows the continuous detection of elongation via the sequential contact of each tooth. The triboelectric sensory information collected during the operation of soft gripper is further trained by support vector machine algorithm to identify diverse objects with an accuracy of 98.1%. Demonstration of digital twin applications, which show the object identification and duplicate robotic manipulation in virtual environment according to the real-time operation of the soft-robotic gripper system, is successfully created for virtual assembly lines and unmanned warehouse applications. Designing efficient sensors for human machine interaction remains a challenge. Here, the authors present a soft robotic fingers system based on a triboelectric nanogenerator (L-TENG) sensor to capture the continuous motion of soft gripper and a soft tactile (T-TENG) sensor for tactile sensing, that can achieve an object recognition accuracy of 98.1%."
Robotics (cs.RO),2020,3,From high-touch to high-tech: COVID-19 drives robotics adoption,472,N/A,https://www.semanticscholar.org/paper/bb12d4ed7cd04935277e3c7b51675faf05dd77fa,"Zhanjing Zeng, Po-Ju Chen, A. Lew","Abstract Global economic and social life has been severely challenged since the World Health Organization (WHO) declared the COVID-19 disease a pandemic. Travel, tourism and hospitality, in particular, has been massively impacted by the lockdowns used to maintain social distance to manage the disease. Robotics, artificial intelligence, and human-robot interactions have gained an increased presence to help manage the spread of COVID-19 in hospitals, airports, transportation systems, recreation and scenic areas, hotels, restaurants, and communities in general. Humanoid robots, autonomous vehicles, drones, and other intelligent robots are used in many different ways to reduce human contact and the potential spread of the SARS-CoV-2 virus, including delivering materials, disinfecting and sterilizing public spaces, detecting or measuring body temperature, providing safety or security, and comforting and entertaining patients. While controversial in the past due to concerns over job losses and data privacy, the adoption of robotics and artificial intelligence in travel and tourism will likely continue after the COVID-19 pandemic becomes less serious. Tourism scholars should seize this opportunity to develop robotic applications that enhance tourist experiences, the protection of natural and cultural resources, citizen participation in tourism development decision making, and the emergence of new ‘high-touch’ employment opportunities for travel, tourism and hospitality workers."
Robotics (cs.RO),2020,5,"Functional Fibers and Fabrics for Soft Robotics, Wearables, and Human–Robot Interface",454,N/A,https://www.semanticscholar.org/paper/f47fb9d585568c64ebe279d739c8ef78013e2e35,"Jiaqing Xiong, Jian Chen, Pooi See Lee","Soft robotics inspired by the movement of living organisms, with excellent adaptability and accuracy for accomplishing tasks, are highly desirable for efficient operations and safe interactions with human. With the emerging wearable electronics, higher tactility and skin affinity are pursued for safe and user‐friendly human–robot interactions. Fabrics interlocked by fibers perform traditional static functions such as warming, protection, and fashion. Recently, dynamic fibers and fabrics are favorable to deliver active stimulus responses such as sensing and actuating abilities for soft‐robots and wearables. First, the responsive mechanisms of fiber/fabric actuators and their performances under various external stimuli are reviewed. Fiber/yarn‐based artificial muscles for soft‐robots manipulation and assistance in human motion are discussed, as well as smart clothes for improving human perception. Second, the geometric designs, fabrications, mechanisms, and functions of fibers/fabrics for sensing and energy harvesting from the human body and environments are summarized. Effective integration between the electronic components with garments, human skin, and living organisms is illustrated, presenting multifunctional platforms with self‐powered potential for human–robot interactions and biomedicine. Lastly, the relationships between robotic/wearable fibers/fabrics and the external stimuli, together with the challenges and possible routes for revolutionizing the robotic fibers/fabrics and wearables in this new era are proposed."
Robotics (cs.RO),2020,4,Combating COVID-19—The role of robotics in managing public health and infectious diseases,452,N/A,https://www.semanticscholar.org/paper/ea062ed85bc4f9c765d2a47061ddfeea01145074,"Guang-Zhong Yang, Bradley J. Nelson, R. Murphy et al.",COVID-19 may drive sustained research in robotics to address risks of infectious diseases. COVID-19 may drive sustained research in robotics to address risks of infectious diseases.
Robotics (cs.RO),2020,7,Hydrogel soft robotics,384,N/A,https://www.semanticscholar.org/paper/ea5c17d0e2dc9fc37bd8d8f8db85f3cac4aba8ef,"Younghoon Lee, Won Jun Song, Jeong-Yun Sun",No Abstract
Robotics (cs.RO),2020,6,Ethics of artificial intelligence and robotics,293,N/A,https://www.semanticscholar.org/paper/06b5090c00326183f7b3fe6e891586449e14650e,V. C. Müller,No Abstract
Robotics (cs.RO),2020,18,A Survey of Behavior Trees in Robotics and AI,285,2005.05842,https://www.semanticscholar.org/paper/595c7aeb6a9c9033a68aff1b25067ce967ea2a77,"Matteo Iovino, Edvards Scukins, J. Styrud et al.",No Abstract
Robotics (cs.RO),2020,10,Soft Robotics: A Review of Recent Developments of Pneumatic Soft Actuators,284,N/A,https://www.semanticscholar.org/paper/625c4cdf9336ac3865e71f5c939350ce3c2832a4,"James Walker, T. Zidek, Cory Harbel et al.","This paper focuses on the recent development of soft pneumatic actuators for soft robotics over the past few years, concentrating on the following four categories: control systems, material and construction, modeling, and sensors. This review work seeks to provide an accelerated entrance to new researchers in the field to encourage research and innovation. Advances in methods to accurately model soft robotic actuators have been researched, optimizing and making numerous soft robotic designs applicable to medical, manufacturing, and electronics applications. Multi-material 3D printed and fiber optic soft pneumatic actuators have been developed, which will allow for more accurate positioning and tactile feedback for soft robotic systems. Also, a variety of research teams have made improvements to soft robot control systems to utilize soft pneumatic actuators to allow for operations to move more effectively. This review work provides an accessible repository of recent information and comparisons between similar works. Future issues facing soft robotic actuators include portable and flexible power supplies, circuit boards, and drive components."
Robotics (cs.RO),2020,11,Magnetic Methods in Robotics,282,N/A,https://www.semanticscholar.org/paper/51a4639fa0d2251f009d8341856af35cbcc6080a,"J. Abbott, E. Diller, A. Petruska","The goal of this article is to provide a thorough introduction to the state of the art in magnetic methods for remote-manipulation and wireless-actuation tasks in robotics. The article synthesizes prior works using a unified notation, enabling straightforward application in robotics. It begins with a discussion of the magnetic fields generated by magnetic materials and electromagnets, how magnetic materials become magnetized in an applied field, and the forces and torques generated on magnetic objects. It then describes systems used to generate and control applied magnetic fields, including both electromagnetic and permanent-magnet systems. Finally, it surveys work from a variety of robotic application areas in which researchers have utilized magnetic methods, including microrobotics, medical robotics, haptics, and aerospace."
Robotics (cs.RO),2020,9,Toward a Common Framework and Database of Materials for Soft Robotics,263,N/A,https://www.semanticscholar.org/paper/cdfce0d2e0788b060b1f3c759690bf450951faf6,"L. Marechal, P. Balland, Lukas Lindenroth et al.","To advance the field of soft robotics, a unified database of material constitutive models and experimental characterizations is of paramount importance. This will facilitate the use of finite element analysis to simulate their behavior and optimize the design of soft-bodied robots. Samples from seventeen elastomers, namely Body Double™ SILK, Dragon Skin™ 10 MEDIUM, Dragon Skin 20, Dragon Skin 30, Dragon Skin FX-Pro, Dragon Skin FX-Pro + Slacker, Ecoflex™ 00–10, Ecoflex 00–30, Ecoflex 00–50, Rebound™ 25, Mold Star™ 16 FAST, Mold Star 20T, SORTA-Clear™ 40, RTV615, PlatSil® Gel-10, Psycho Paint®, and SOLOPLAST 150318, were subjected to uniaxial tensile tests according to the ASTM D412 standard. Sample preparation and tensile test parameters are described in detail. The tensile test data are used to derive parameters for hyperelastic material models using nonlinear least-squares methods, which are provided to the reader. This article presents the mechanical characterization and the resulting material properties for a wide set of commercially available hyperelastic materials, many of which are recognized and commonly applied in the field of soft robotics, together with some that have never been characterized. The experimental raw data and the algorithms used to determine material parameters are shared on the Soft Robotics Materials Database GitHub repository to enable accessibility, as well as future contributions from the soft robotics community. The presented database is aimed at aiding soft roboticists in designing and modeling soft robots while providing a starting point for future material characterizations related to soft robotics research."
Robotics (cs.RO),2020,15,Agricultural Robotics for Field Operations,254,N/A,https://www.semanticscholar.org/paper/70d86ae71102bf004fc85496ba4a0b35493b6eff,"S. Fountas, N. Mylonas, Ioannis Malounas et al.","Modern agriculture is related to a revolution that occurred in a large group of technologies (e.g., informatics, sensors, navigation) within the last decades. In crop production systems, there are field operations that are quite labour-intensive either due to their complexity or because of the fact that they are connected to sensitive plants/edible product interaction, or because of the repetitiveness they require throughout a crop production cycle. These are the key factors for the development of agricultural robots. In this paper, a systematic review of the literature has been conducted on research and commercial agricultural robotics used in crop field operations. This study underlined that the most explored robotic systems were related to harvesting and weeding, while the less studied were the disease detection and seeding robots. The optimization and further development of agricultural robotics are vital, and should be evolved by producing faster processing algorithms, better communication between the robotic platforms and the implements, and advanced sensing systems."
Robotics (cs.RO),2020,14,3D Printing Materials for Soft Robotics,252,N/A,https://www.semanticscholar.org/paper/4e842dddb3c6a6da67d87af3a77c5e7e7243f023,"Ela Sachyani Keneth, A. Kamyshny, M. Totaro et al.","Soft robotics is a growing field of research, focusing on constructing motor‐less robots from highly compliant materials, some are similar to those found in living organisms. Soft robotics has a high potential for applications in various fields such as soft grippers, actuators, and biomedical devices. 3D printing of soft robotics presents a novel and promising approach to form objects with complex structures, directly from a digital design. Here, recent developments in the field of materials for 3D printing of soft robotics are summarized, including high‐performance flexible and stretchable materials, hydrogels, self‐healing materials, and shape memory polymers, as well as fabrication of all‐printed robots (multi‐material printing, embedded electronics, untethered and autonomous robotics). The current challenges in the fabrication of 3D printed soft robotics, including the materials available and printing abilities, are presented and the recent activities addressing these challenges are also surveyed."
Robotics (cs.RO),2020,16,Reflections on the future of swarm robotics,243,N/A,https://www.semanticscholar.org/paper/1ea871b24beefcf682cd835316e25208d8839fe4,"M. Dorigo, G. Theraulaz, V. Trianni","Swarm robotics will tackle real-world applications by leveraging automatic design, heterogeneity, and hierarchical self-organization. Swarm robotics will tackle real-world applications by leveraging automatic design, heterogeneity, and hierarchical self-organization."
Robotics (cs.RO),2020,12,The adoption of artificial intelligence and robotics in the hotel industry: prospects and challenges,227,N/A,https://www.semanticscholar.org/paper/3b3b294731b858c3b53a02819ec6815c94a5f2fa,"K. Nam, Chris Dutt, P. Chathoth et al.",No Abstract
Robotics (cs.RO),2020,8,Augmented Reality for Robotics: A Review,217,N/A,https://www.semanticscholar.org/paper/0c9c93d889ac2ae90e836494010df6b403e238ef,"Z. Makhataeva, H. A. Varol","Augmented reality (AR) is used to enhance the perception of the real world by integrating virtual objects to an image sequence acquired from various camera technologies. Numerous AR applications in robotics have been developed in recent years. The aim of this paper is to provide an overview of AR research in robotics during the five year period from 2015 to 2019. We classified these works in terms of application areas into four categories: (1) Medical robotics: Robot-Assisted surgery (RAS), prosthetics, rehabilitation, and training systems; (2) Motion planning and control: trajectory generation, robot programming, simulation, and manipulation; (3) Human-robot interaction (HRI): teleoperation, collaborative interfaces, wearable robots, haptic interfaces, brain-computer interfaces (BCIs), and gaming; (4) Multi-agent systems: use of visual feedback to remotely control drones, robot swarms, and robots with shared workspace. Recent developments in AR technology are discussed followed by the challenges met in AR due to issues of camera localization, environment mapping, and registration. We explore AR applications in terms of how AR was integrated and which improvements it introduced to corresponding fields of robotics. In addition, we summarize the major limitations of the presented applications in each category. Finally, we conclude our review with future directions of AR research in robotics. The survey covers over 100 research works published over the last five years."
Robotics (cs.RO),2020,13,"Becoming Sustainable, The New Frontier in Soft Robotics",207,N/A,https://www.semanticscholar.org/paper/6d0f71c31550e6168dcdd9145f1f775226e6705a,"Florian Hartmann, Melanie Baumgartner, M. Kaltenbrunner","The advancement of technology has a profound and far‐reaching impact on the society, now penetrating all areas of life. From cradle to grave, one is supported by and depends on a wide range of electronic and robotic appliances, with an ever more intimate integration of the digital and biological spheres. These advances, however, often come at the price of negatively impacting our ecosystem, with growing demands on energy, contributions to greenhouse gas emissions and environmental pollution—from production to improper disposal. Mitigating these adverse effects is among the grand challenges of the society and at the forefront of materials research. The currently emerging forms of soft, biologically inspired electronics and robotics have the unique potential of becoming not only like their natural antitypes in performance and capabilities, but also in terms of their ecological footprint. This review outlines the rise of sustainable materials in soft and bioinspired robotics, targeting all robotic components from actuators to energy storage and electronics. The state‐of‐the‐art in biobased robotics spans flourishing fields and applications ranging from microbots operating in vivo to biohybrid machines and fully biodegradable yet resilient actuators. These first steps initiate the evolution of robotics and guide them into a sustainable future."
Robotics (cs.RO),2020,17,Robotics Utilization for Healthcare Digitization in Global COVID-19 Management,206,N/A,https://www.semanticscholar.org/paper/fb5df212b65b27f57e4c2d4159d08c9a061ea860,"Z. Khan, Afifa Siddique, Chang Won Lee","This paper describes the evolving role of robotics in healthcare and allied areas with special concerns relating to the management and control of the spread of the novel coronavirus disease 2019 (COVID-19). The prime utilization of such robots is to minimize person-to-person contact and to ensure cleaning, sterilization and support in hospitals and similar facilities such as quarantine. This will result in minimizing the life threat to medical staff and doctors taking an active role in the management of theCOVID-19 pandemic. The intention of the present research is to highlight the importance of medical robotics in general and then to connect its utilization with the perspective of COVID-19 management so that the hospital management can direct themselves to maximize the use of medical robots for various medical procedures. This is despite the popularity of telemedicine, which is also effective in similar situations. In essence, the recent achievement of the Korean and Chinese health sectors in obtaining active control of the COVID-19 pandemic was not possible without the use of state of the art medical technology."
Robotics (cs.RO),2020,20,Transparent Soft Actuators/Sensors and Camouflage Skins for Imperceptible Soft Robotics,182,N/A,https://www.semanticscholar.org/paper/2db2548558837db00ff9002a464f596f89ee0bf3,"P. Won, K. Kim, Hyeonseok Kim et al.","The advent of soft robotics has led to great advancements in robots, wearables, and even manufacturing processes by employing entirely soft‐bodied systems that interact safely with any random surfaces while providing great mechanical compliance. Moreover, recent developments in soft robotics involve advances in transparent soft actuators and sensors that have made it possible to construct robots that can function in a visually and mechanically unobstructed manner, assisting the operations of robots and creating more applications in various fields. In this aspect, imperceptible soft robotics that mainly consist of optically transparent imperceptible hardware components is expected to constitute a new research focus in the forthcoming era of soft robotics. Here, the recent progress regarding extended imperceptible soft robotics is provided, including imperceptible transparent soft robotics (transparent soft actuators/sensors) and imperceptible nontransparent camouflage skins. Their principles, materials selections, and working mechanisms are discussed so that key challenges and perspectives in imperceptible soft robotic systems can be explored."
Robotics (cs.RO),2020,19,Impact of AI and robotics in the tourism sector: a critical insight,180,N/A,https://www.semanticscholar.org/paper/eded05c804d2c91a1653efbe36143dca22fe9cfe,"Nagaraj Samala, Bharath Shashanka Katkam, R. Bellamkonda et al."," Purpose The purpose of the present article is to highlight the role of Artificial Intelligence (AI) and Robotics in the tourism industry. The various technologies being integrated to improve the service and customer experience in tourism. The expected changes and challenges in tourism in the future are focused in this paper.   Design/methodology/approach A systematic study on the emerging technologies of AI and Robotics applied in the tourism sector is presented in the form of a viewpoint.   Findings AI certainly enhances tourism experiential services however cannot surpass the human touch which is an essential determinant of experiential tourism. AI acts as an effective complementary dimension to the future of tourism. With the emergence of artificial travel intelligence, it is simpler to make travel arrangements. AI offers travel services that are automated, customized and insightful. AI allows travelers to learn about their behaviors, interests to inclinations and provide a personalized experience. Gone are the days to consult a travel agent, meet him physically and indulge in an endless chain of troubling phone calls to inquire about travel arrangements.   Practical implications Tourism marketing to see a positive and improved change that will enhance the tourists’ overall experience due to the application of AI and Robotics. New emerging technologies like chatbots, virtual reality, language translators, etc. can be effectively applied in Travel, Tourism & Hospitality industry.   Originality/value The present viewpoint discusses the application and role of AI and Robotics with the help of relevant industry examples and theory. The present paper highlights the different technologies being used and will be used in the future. "
Robotics (cs.RO),2021,5,Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning,763,2108.06266,https://www.semanticscholar.org/paper/d6e783bce3b8e3ad082c2757235c34cb86c4e653,"Lukas Brunke, Melissa Greeff, Adam W. Hall et al.","The last half decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision-making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. It includes learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximity to humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 5 is May 2022. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates."
Robotics (cs.RO),2021,2,"Artificial intelligence, robotics, advanced technologies and human resource management: a systematic review",713,N/A,https://www.semanticscholar.org/paper/bd3d0238549555bd07fd25ff61b3d7e01eb02296,"D. Vrontis, M. Christofi, V. Pereira et al.","Abstract Although academic production in intelligent automation (e.g. artificial intelligence, robotics) has grown rapidly, we still lack a comprehensive understanding of the impacts of the utilization of these technologies in human resource management (HRM) at an organizational (firms) and individual (employees) level. This study therefore aims to systematize the academic inputs on intelligent automation so far and to clarify what are its main contributions to and challenges for HRM. In a systematic search of 13,136 potentially relevant studies published in the top HRM, international business (IB), general management (GM) and information management (IM) journals, we found 45 articles studying artificial intelligence, robotics and other advanced technologies within HRM settings. Results show that intelligent automation technologies constitute a new approach to managing employees and enhancing firm performance, thus offering several opportunities for HRM but also considerable challenges at a technological and ethical level. The impact of these technologies has been identified to concentrate on HRM strategies, namely, job replacement, human-robot/AI collaboration, decision-making and learning opportunities, and HRM activities, namely, recruiting, training and job performance. This study discusses these shifts in detail, along with the main contributions to theory and practice and directions for future research."
Robotics (cs.RO),2021,4,Flexible Electronics and Devices as Human–Machine Interfaces for Medical Robotics,418,N/A,https://www.semanticscholar.org/paper/e645103fc974bf2de15dc3f0ae94734a757312ec,"Wenzheng Heng, Samuel A. Solomon, Wei Gao","Medical robots are invaluable players in non‐pharmaceutical treatment of disabilities. Particularly, using prosthetic and rehabilitation devices with human–machine interfaces can greatly improve the quality of life for impaired patients. In recent years, flexible electronic interfaces and soft robotics have attracted tremendous attention in this field due to their high biocompatibility, functionality, conformability, and low‐cost. Flexible human–machine interfaces on soft robotics will make a promising alternative to conventional rigid devices, which can potentially revolutionize the paradigm and future direction of medical robotics in terms of rehabilitation feedback and user experience. In this review, the fundamental components of the materials, structures, and mechanisms in flexible human‐machine interfaces are summarized by recent and renowned applications in five primary areas: physical and chemical sensing, physiological recording, information processing and communication, soft robotic actuation, and feedback stimulation. This review further concludes by discussing the outlook and current challenges of these technologies as a human–machine interface in medical robotics."
Robotics (cs.RO),2021,7,Substantial capabilities of robotics in enhancing industry 4.0 implementation,399,N/A,https://www.semanticscholar.org/paper/fb8a51b1eb62d54ec0415adb3cdc89d4bc72520f,"M. Javaid, Abid Haleem, R. Singh et al.",No Abstract
Robotics (cs.RO),2021,3,A decade retrospective of medical robotics research from 2010 to 2020,373,N/A,https://www.semanticscholar.org/paper/4a02061f8623f68502991d8bdf7728ae50669091,"P. Dupont, Bradley J. Nelson, M. Goldfarb et al.","Description Eighty percent of medical robotics papers have been published in the past decade—What has been accomplished? Robotics is a forward-looking discipline. Attention is focused on identifying the next grand challenges. In an applied field such as medical robotics, however, it is important to plan the future based on a clear understanding of what the research community has recently accomplished and where this work stands with respect to clinical needs and commercialization. This Review article identifies and analyzes the eight key research themes in medical robotics over the past decade. These thematic areas were identified using search criteria that identified the most highly cited papers of the decade. Our goal for this Review article is to provide an accessible way for readers to quickly appreciate some of the most exciting accomplishments in medical robotics over the past decade; for this reason, we have focused only on a small number of seminal papers in each thematic area. We hope that this article serves to foster an entrepreneurial spirit in researchers to reduce the widening gap between research and translation."
Robotics (cs.RO),2021,1,Advances in Agriculture Robotics: A State-of-the-Art Review and Challenges Ahead,320,N/A,https://www.semanticscholar.org/paper/6760f97cd0ec4b721ceec96205a846e6b56f05bc,"Luiz F. P. Oliveira, A. Moreira, Manuel Silva","The constant advances in agricultural robotics aim to overcome the challenges imposed by population growth, accelerated urbanization, high competitiveness of high-quality products, environmental preservation and a lack of qualified labor. In this sense, this review paper surveys the main existing applications of agricultural robotic systems for the execution of land preparation before planting, sowing, planting, plant treatment, harvesting, yield estimation and phenotyping. In general, all robots were evaluated according to the following criteria: its locomotion system, what is the final application, if it has sensors, robotic arm and/or computer vision algorithm, what is its development stage and which country and continent they belong. After evaluating all similar characteristics, to expose the research trends, common pitfalls and the characteristics that hinder commercial development, and discover which countries are investing into Research and Development (R&D) in these technologies for the future, four major areas that need future research work for enhancing the state of the art in smart agriculture were highlighted: locomotion systems, sensors, computer vision algorithms and communication technologies. The results of this research suggest that the investment in agricultural robotic systems allows to achieve short—harvest monitoring—and long-term objectives—yield estimation."
Robotics (cs.RO),2021,8,Emerging research fields in safety and ergonomics in industrial collaborative robotics: A systematic literature review,313,N/A,https://www.semanticscholar.org/paper/4d7cadfe53d2b29a64e1a919d0dd3ce51965eba1,"Luca Gualtieri, E. Rauch, R. Vidoni",No Abstract
Robotics (cs.RO),2021,9,"Swarm Robotics: Past, Present, and Future",282,N/A,https://www.semanticscholar.org/paper/248b15c7f9bfd37d25db115efe75ed556120eca6,"M. Dorigo, G. Theraulaz, V. Trianni","By MARCO DORIGO , Fellow IEEE Institut de Recherches Interdisciplinaires et de Développements en Intelligence Artificielle (IRIDIA), Université Libre de Bruxelles (ULB), 1050 Brussels, Belgium GUY THERAULAZ Centre de Recherches sur la Cognition Animale (CRCA), Centre de Biologie Intégrative (CBI), CNRS, Université de Toulouse-Paul Sabatier, 31062 Toulouse, France VITO TRIANNI Institute of Cognitive Sciences and Technologies (ISTC), National Research Council (CNR), 00185 Rome, Italy"
Robotics (cs.RO),2021,6,A Survey on AI-Driven Digital Twins in Industry 4.0: Smart Manufacturing and Advanced Robotics,269,N/A,https://www.semanticscholar.org/paper/8e76c41f4df07fdc512cb13f8e9b14e1692577ed,"Ziqi Huang, Yang Shen, Jiayi Li et al.","Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined."
Robotics (cs.RO),2021,11,A Comprehensive Review of Coverage Path Planning in Robotics Using Classical and Heuristic Algorithms,251,N/A,https://www.semanticscholar.org/paper/da002c1059707a542772b14bb2b4558658fe53af,"Chee Sheng Tan, R. Mohd-Mokhtar, M. Arshad","The small battery capacities of the mobile robot and the un-optimized planning efficiency of the industrial robot bottlenecked the time efficiency and productivity rate of coverage tasks in terms of speed and accuracy, putting a great constraint on the usability of the robot applications in various planning strategies in specific environmental conditions. Thus, it became highly desirable to address the optimization problems related to exploration and coverage path planning (CPP). In general, the goal of the CPP is to find an optimal coverage path with generates a collision-free trajectory by reducing the travel time, processing speed, cost energy, and the number of turns along the path length, as well as low overlapped rate, which reflect the robustness of CPP. This paper reviews the principle of CPP and discusses the development trend, including design variations and the characteristic of optimization algorithms, such as classical, heuristic, and most recent deep learning methods. Then, we compare the advantages and disadvantages of the existing CPP-based modeling in the area and target coverage. Finally, we conclude numerous open research problems of the CPP and make suggestions for future research directions to gain insights."
Robotics (cs.RO),2021,10,"Robotics cyber security: vulnerabilities, attacks, countermeasures, and recommendations",232,N/A,https://www.semanticscholar.org/paper/cc289996d8b14b9bdb22f240055a185316273461,"Jean-Paul A. Yaacoub, Hassan N. Noura, Ola Salman et al.","The recent digital revolution led robots to become integrated more than ever into different domains such as agricultural, medical, industrial, military, police (law enforcement), and logistics. Robots are devoted to serve, facilitate, and enhance the human life. However, many incidents have been occurring, leading to serious injuries and devastating impacts such as the unnecessary loss of human lives. Unintended accidents will always take place, but the ones caused by malicious attacks represent a very challenging issue. This includes maliciously hijacking and controlling robots and causing serious economic and financial losses. This paper reviews the main security vulnerabilities, threats, risks, and their impacts, and the main security attacks within the robotics domain. In this context, different approaches and recommendations are presented in order to enhance and improve the security level of robotic systems such as multi-factor device/user authentication schemes, in addition to multi-factor cryptographic algorithms. We also review the recently presented security solutions for robotic systems."
Robotics (cs.RO),2021,15,Dynamic movement primitives in robotics: A tutorial survey,225,2102.03861,https://www.semanticscholar.org/paper/75fbe9143d8d6f6d10b1880b97fc94cc442378a7,"Matteo Saveriano, Fares J. Abu-Dakka, Aljaz Kramberger et al.","Biological systems, including human beings, have the innate ability to perform complex tasks in a versatile and agile manner. Researchers in sensorimotor control have aimed to comprehend and formally define this innate characteristic. The idea, supported by several experimental findings, that biological systems are able to combine and adapt basic units of motion into complex tasks finally leads to the formulation of the motor primitives’ theory. In this respect, Dynamic Movement Primitives (DMPs) represent an elegant mathematical formulation of the motor primitives as stable dynamical systems and are well suited to generate motor commands for artificial systems like robots. In the last decades, DMPs have inspired researchers in different robotic fields including imitation and reinforcement learning, optimal control, physical interaction, and human–robot co-working, resulting in a considerable amount of published papers. The goal of this tutorial survey is two-fold. On one side, we present the existing DMP formulations in rigorous mathematical terms and discuss the advantages and limitations of each approach as well as practical implementation details. In the tutorial vein, we also search for existing implementations of presented approaches and release several others. On the other side, we provide a systematic and comprehensive review of existing literature and categorize state-of-the-art work on DMP. The paper concludes with a discussion on the limitations of DMPs and an outline of possible research directions."
Robotics (cs.RO),2021,18,Bubble casting soft robotics,218,N/A,https://www.semanticscholar.org/paper/cb9f150ec1fd19cdd24ecbbdf6cfa62035582b5b,"Trevor J. Jones, E. Jambon-Puillet, J. Marthelot et al.",No Abstract
Robotics (cs.RO),2021,19,Review of machine learning methods in soft robotics,215,N/A,https://www.semanticscholar.org/paper/fa4cac01f1c8cef88b4e1896838c1e96ae8269e7,"Daekyum Kim, Sang-Hun Kim, Taekyoung Kim et al.","Soft robots have been extensively researched due to their flexible, deformable, and adaptive characteristics. However, compared to rigid robots, soft robots have issues in modeling, calibration, and control in that the innate characteristics of the soft materials can cause complex behaviors due to non-linearity and hysteresis. To overcome these limitations, recent studies have applied various approaches based on machine learning. This paper presents existing machine learning techniques in the soft robotic fields and categorizes the implementation of machine learning approaches in different soft robotic applications, which include soft sensors, soft actuators, and applications such as soft wearable robots. An analysis of the trends of different machine learning approaches with respect to different types of soft robot applications is presented; in addition to the current limitations in the research field, followed by a summary of the existing machine learning methods for soft robots."
Robotics (cs.RO),2021,16,Robotics and artificial intelligence in healthcare during COVID-19 pandemic: A systematic review,210,N/A,https://www.semanticscholar.org/paper/f9c59ba4ac7e0fc52399d4b1489ef8df93076912,"Sujan Sarker, Lafifa Jamal, Syeda Faiza Ahmed et al.",No Abstract
Robotics (cs.RO),2021,12,"Exploiting Mechanical Instabilities in Soft Robotics: Control, Sensing, and Actuation",174,N/A,https://www.semanticscholar.org/paper/6fd88eec519f3172a512c63cb6bbd1949f34fbd1,"Aniket Pal, Vanessa Restrepo, Debkalpa Goswami et al.","The rapidly expanding field of soft robotics has provided multiple examples of how entirely soft machines and actuators can outperform conventional rigid robots in terms of adaptability, maneuverability, and safety. Unfortunately, the soft and flexible materials used in their construction impose intrinsic limitations on soft robots, such as low actuation speeds and low output forces. Nature offers multiple examples where highly flexible organisms exploit mechanical instabilities to store and rapidly release energy. Guided by these examples, researchers have recently developed a variety of strategies to overcome speed and power limitations in soft robotics using mechanical instabilities. These mechanical instabilities provide, through rapid transitions from structurally stable states, a new route to achieve high output power amplification and attain impressive actuation speeds. Here, an overview of the literature related to the development of soft robots and actuators that exploit mechanical instabilities to expand their actuation speed, output power, and functionality is presented. Additionally, strategies using structural phase transitions to address current challenges in the area of soft robotic control, sensing, and actuation are discussed. Approaches using instabilities to create entirely soft logic modules to imbue soft robots with material intelligence and distributed computational capabilities are also reviewed."
Robotics (cs.RO),2021,13,"Selective Harvesting Robotics: Current Research, Trends, and Future Directions",168,N/A,https://www.semanticscholar.org/paper/7bc76d4f3d0f287f8f07fb353f65b5ddf1fe3212,"G. Kootstra, Xin Wang, P. Blok et al.","The world-wide demand for agricultural products is rapidly growing. However, despite the growing population, labor shortage becomes a limiting factor for agricultural production. Further automation of agriculture is an important solution to tackle these challenges. Selective harvesting of high-value crops, such as apples, tomatoes, and broccoli, is currently mainly performed by humans, rendering it one of the most labor-intensive and expensive agricultural tasks. This explains the large interest in the development of selective harvesting robots. Selective harvesting, however, is a challenging task for a robot, due to the high levels of variation and incomplete information, as well as safety. This review paper provides an overview of the state of the art in selective harvesting robotics in three different production systems; greenhouse, orchard, and open field. The limitations of current systems are discussed, and future research directions are proposed."
Robotics (cs.RO),2021,14,Advanced Applications of Industrial Robotics: New Trends and Possibilities,156,N/A,https://www.semanticscholar.org/paper/a571f3a7e3a14b8c1212966941c8147bd9f69b26,"Andrius Dzedzickis, Jurga Subačiūtė-Žemaitienė, E. Šutinys et al.","This review is dedicated to the advanced applications of robotic technologies in the industrial field. Robotic solutions in areas with non-intensive applications are presented, and their implementations are analysed. We also provide an overview of survey publications and technical reports, classified by application criteria, and the development of the structure of existing solutions, and identify recent research gaps. The analysis results reveal the background to the existing obstacles and problems. These issues relate to the areas of psychology, human nature, special artificial intelligence (AI) implementation, and the robot-oriented object design paradigm. Analysis of robot applications shows that the existing emerging applications in robotics face technical and psychological obstacles. The results of this review revealed four directions of required advancement in robotics: development of intelligent companions; improved implementation of AI-based solutions; robot-oriented design of objects; and psychological solutions for robot–human collaboration."
Robotics (cs.RO),2021,17,Towards Real-Time Monocular Depth Estimation for Robotics: A Survey,148,2111.08600,https://www.semanticscholar.org/paper/dec0ac4510d65616c887e3699807ff345dc4cf9e,"Xingshuai Dong, M. Garratt, S. Anavatti et al.","As an essential component for many autonomous driving and robotic activities such as ego-motion estimation, obstacle avoidance and scene understanding, monocular depth estimation (MDE) has attracted great attention from the computer vision and robotics communities. Over the past decades, a large number of methods have been developed. To the best of our knowledge, however, there is not a comprehensive survey of MDE. This paper aims to bridge this gap by reviewing 197 relevant articles published between 1970 and 2021. In particular, we provide a comprehensive survey of MDE covering various methods, introduce the popular performance evaluation metrics and summarize publically available datasets. We also summarize available open-source implementations of some representative methods and compare their performances. Furthermore, we review the application of MDE in some important robotic tasks. Finally, we conclude this paper by presenting some promising directions for future research. This survey is expected to assist readers to navigate this research field."
Robotics (cs.RO),2021,20,A Roadmap for US Robotics - From Internet to Robotics 2020 Edition,132,N/A,https://www.semanticscholar.org/paper/bd6d8840ecbdddab31e9fbbb79fc8ce2f11830b7,"Henrik I. Christensen, N. Amato, H. Yanco et al.","Recently, the robotics industry celebrated its 60-year anniversary. We have used robots for more than six decades to empower people to do things that are typically dirty, dull and/or dangerous. The industry has progressed significantly over the period from basic mechanical assist systems to fully autonomous cars, environmental monitoring and exploration of outer space. We have seen tremendous adoption of IT technology in our daily lives for a diverse set of support tasks. Through use of robots we are starting to see a new revolution, as we not only will have IT support from tablets, phones, computers but also systems that can physically interact with the world and assist with daily tasks, work, and leisure activities. The present document is a summary of the main societal opportunities identified, the associated challenges to deliver desired solutions and a presentation of efforts to be undertaken to ensure that US will continue to be a leader in robotics both in terms of research innovation, adoption of the latest technology, and adoption of appropriate policy frameworks that ensure that the technology is utilized in a responsible fashion. H. I. Christensen, N. Amato, H. Yanco, M. Mataric, H. Choset, A. Drobnis, K. Goldberg, J. Grizzle, G. Hager, J. Hollerbach, S. Hutchinson, V. Krovi, D. Lee, W. Smart and J. Trinkle (2021), “A Roadmap for US Robotics – From Internet to Robotics 2020 Edition”, Foundations and Trends® in Robotics: Vol. 8, No. 4, pp 307–424. DOI: 10.1561/2300000066. Full text available at: http://dx.doi.org/10.1561/2300000066"
Robotics (cs.RO),2022,1,RT-1: Robotics Transformer for Real-World Control at Scale,1660,2212.06817,https://www.semanticscholar.org/paper/fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d,"Anthony Brohan, Noah Brown, Justice Carbajal et al.","By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io"
Robotics (cs.RO),2022,2,"Safe Control With Learned Certificates: A Survey of Neural Lyapunov, Barrier, and Contraction Methods for Robotics and Control",310,2202.11762,https://www.semanticscholar.org/paper/a8cd8d3e76ce4d986f938764a086e1a3d4706973,"Charles Dawson, Sicun Gao, Chuchu Fan","Learning-enabled control systems have demonstrated impressive empirical performance on challenging control problems in robotics, but this performance comes at the cost of reduced transparency and lack of guarantees on the safety or stability of the learned controllers. In recent years, new techniques have emerged to provide these guarantees by learning certificates alongside control policies—these certificates provide concise data-driven proofs that guarantee the safety and stability of the learned control system. These methods not only allow the user to verify the safety of a learned controller but also provide supervision during training, allowing safety and stability requirements to influence the training process itself. In this article, we provide a comprehensive survey of this rapidly developing field of certificate learning. We hope that this article will serve as an accessible introduction to the theory and practice of certificate learning, both to those who wish to apply these tools to practical robotics problems and to those who wish to dive more deeply into the theory of learning for control."
Robotics (cs.RO),2022,4,"Accelerating materials discovery using artificial intelligence, high performance computing and robotics",302,N/A,https://www.semanticscholar.org/paper/51bb51b06f57fada5d8f338aa484a87f93226468,"Edward O. Pyzer-Knapp, J. Pitera, P. Staar et al.","New tools enable new ways of working, and materials science is no exception. In materials discovery, traditional manual, serial, and human-intensive work is being augmented by automated, parallel, and iterative processes driven by Artificial Intelligence (AI), simulation and experimental automation. In this perspective, we describe how these new capabilities enable the acceleration and enrichment of each stage of the discovery cycle. We show, using the example of the development of a novel chemically amplified photoresist, how these technologies’ impacts are amplified when they are used in concert with each other as powerful, heterogeneous workflows."
Robotics (cs.RO),2022,5,"Advances in Biodegradable Electronic Skin: Material Progress and Recent Applications in Sensing, Robotics, and Human–Machine Interfaces",248,N/A,https://www.semanticscholar.org/paper/afe7c15d2aa21b73c8058604fe32f9bad1651433,"M. Zarei, Giwon Lee, Seung Goo Lee et al.","The rapid growth of the electronics industry and proliferation of electronic materials and telecommunications technologies has led to the release of a massive amount of untreated electronic waste (e‐waste) into the environment. Consequently, catastrophic environmental damage at the microbiome level and serious human health diseases threaten the natural fate of the planet. Currently, the demand for wearable electronics for applications in personalized medicine, electronic skins (e‐skins), and health monitoring is substantial and growing. Therefore, “green” characteristics such as biodegradability, self‐healing, and biocompatibility ensure the future application of wearable electronics and e‐skins in biomedical engineering and bioanalytical sciences. Leveraging the biodegradability, sustainability, and biocompatibility of natural materials will dramatically influence the fabrication of environmentally friendly e‐skins and wearable electronics. Here, the molecular and structural characteristics of biological skins and artificial e‐skins are discussed. The focus then turns to the biodegradable materials, including natural and synthetic‐polymer‐based materials, and their recent applications in the development of biodegradable e‐skin in wearable sensors, robotics, and human–machine interfaces (HMIs). Finally, the main challenges and outlook regarding the preparation and application of biodegradable e‐skins are critically discussed in a near‐future scenario, which is expected to lead to the next generation of biodegradable e‐skins."
Robotics (cs.RO),2022,3,Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces,225,2203.03254,https://www.semanticscholar.org/paper/30f2959cf34b0d6585c8679db76b860400a49d0e,"R. Suzuki, Adnan Karim, Tian Xia et al.","This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics."
Robotics (cs.RO),2022,12,An Overview of Soft Robotics,186,N/A,https://www.semanticscholar.org/paper/b40bf2ec225ee6a469c28f44288ae7bfbc322852,"O. Yasa, Yasunori Toshimitsu, M. Michelis et al.","Soft robots’ flexibility and compliance give them the potential to outperform traditional rigid-bodied robots while performing multiple tasks in unexpectedly changing environments and conditions. However, soft robots have not yet revealed their full potential since nature is still far more advanced in several areas, such as locomotion and manipulation. To understand what limits their performance and hinders their transition from laboratory to real-world conditions, future studies should focus on understanding the principles behind the design and operation of soft robots. Such studies should also consider the major challenges with regard to complex materials, accurate modeling, advanced control, and intelligent behaviors. As a starting point for such studies, this review provides a current overview of the field by examining the working mechanisms of advanced actuation and sensing modalities, modeling techniques, control strategies, and learning architectures for soft robots. Next, we summarize how these approaches can be applied to create sophisticated soft robots and examine their application areas. Finally, we provide future perspectives on what key challenges should be tackled first to advance soft robotics to truly add value to our society. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 14 is May 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates."
Robotics (cs.RO),2022,6,DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics,174,2210.02438,https://www.semanticscholar.org/paper/4fd4e392fb39124744bdfbb6d71ae2030be5132e,"Ivan Kapelyukh, Vitalis Vosylius, Edward Johns","We introduce the first work to explore web-scale diffusion models for robotics. DALL-E-Bot enables a robot to rearrange objects in a scene, by first inferring a text description of those objects, then generating an image representing a natural, human-like arrangement of those objects, and finally physically arranging the objects according to that goal image. We show that this is possible zero-shot using DALL-E, without needing any further example arrangements, data collection, or training. DALL-E-Bot is fully autonomous and is not restricted to a pre-defined set of objects or scenes, thanks to DALL-E's web-scale pre-training. Encouraging real-world results, with both human studies and objective metrics, show that integrating web-scale diffusion models into robotics pipelines is a promising direction for scalable, unsupervised robot learning."
Robotics (cs.RO),2022,11,Socially Assistive Robotics: Methods and Implications for the Future of Work and Care,165,N/A,https://www.semanticscholar.org/paper/8984ce3123e185a2fdefa7951e16bd938faafd15,M. Matarić,No Abstract
Robotics (cs.RO),2022,7,The Franka Emika Robot: A Reference Platform for Robotics Research and Education,160,N/A,https://www.semanticscholar.org/paper/79e362d2c9afaccc7c62d8d7a8d723b140e92548,"Sami Haddadin, Sven Parusel, Lars Johannsmeier et al.","The importance of robots for industry, research, education, and society as a whole is steadily increasing as reflected by the number of available systems and installed robots, not only in industry but also in the public sector and households. Software-only robotics researchers usually rely on commercially available robots which, in the case of manipulators, are primarily designed for industrial purposes and are often far from their needs. This article is a hands-on tutorial on the Franka Emika robot, the first series of industrial artificial intelligence (AI)-ready tactile robot platforms. Beyond industrial use, the systems can be seamlessly expanded to fulfill the demands of research and education across all robotics and AI disciplines. To satisfy the needs of such a wide variety of fields, it provides three different interfaces: Desk, a high-level app-based user interface for easy and fast task programming; Robot Integrated Development Environment (RIDE), a command-based programming environment used to create high-performance robot skills that enables programming custom apps and integrating external sensors; and the Franka control interface (FCI), a 1-kHz low-level torque and position control interface that exploits the also-available Langrangian dynamics robot model. We take a close look at implementations with all interfaces, ranging from simple solutions, apps, and controllers to robot-learning examples illustrating how to exploit all the advantages of this platform in ongoing robotics research and education."
Robotics (cs.RO),2022,9,Robot-Assisted Minimally Invasive Surgery—Surgical Robotics in the Data Age,156,N/A,https://www.semanticscholar.org/paper/91dbf411995724ad8ac776a0521541a515c26384,"T. Haidegger, S. Speidel, D. Stoyanov et al.","Telesurgical robotics, as a technical solution for robot-assisted minimally invasive surgery (RAMIS), has become the first domain within medicosurgical robotics that achieved a true global clinical adoption. Its relative success (still at a low single-digit percentile total market penetration) roots in the particular human-in-the-loop control, in which the trained surgeon is always kept responsible for the clinical outcome achieved by the robot-actuated invasive tools. Nowadays, this paradigm is challenged by the need for improved surgical performance, traceability, and safety reaching beyond the human capabilities. Partially due to the technical complexity and the financial burden, the adoption of telesurgical robotics has not reached its full potential, by far. Apart from the absolutely market-dominating da Vinci surgical system, there are already 60+ emerging RAMIS robot types, out of which 15 have already achieved some form of regulatory clearance. This article aims to connect the technological advancement with the principles of commercialization, particularly looking at engineering components that are under development and have the potential to bring significant advantages to the clinical practice. Current RAMIS robots often do not exceed the functionalities deriving from their mechatronics, due to the lack of data-driven assistance and smart human–machine collaboration. Computer assistance is gradually gaining more significance within emerging RAMIS systems. Enhanced manipulation capabilities, refined sensors, advanced vision, task-level automation, smart safety features, and data integration mark together the inception of a new era in telesurgical robotics, infiltrated by machine learning (ML) and artificial intelligence (AI) solutions. Observing other domains, it is definite that a key requirement of a robust AI is the good quality data, derived from proper data acquisition and sharing to allow building solutions in real time based on ML. Emerging RAMIS technologies are reviewed both in a historical and a future perspective."
Robotics (cs.RO),2022,14,Partially Observable Markov Decision Processes in Robotics: A Survey,155,2209.10342,https://www.semanticscholar.org/paper/56f4b84959a56f27c109c4065facae01e1a64ecd,"M. Lauri, David Hsu, J. Pajarinen","Noisy sensing, imperfect control, and environment changes are defining characteristics of many real-world robot tasks. The partially observable Markov decision process (POMDP) provides a principled mathematical framework for modeling and solving robot decision and control tasks under uncertainty. Over the last decade, it has seen many successful applications, spanning localization and navigation, search and tracking, autonomous driving, multirobot systems, manipulation, and human–robot interaction. This survey aims to bridge the gap between the development of POMDP models and algorithms at one end and application to diverse robot decision tasks at the other. It analyzes the characteristics of these tasks and connects them with the mathematical and algorithmic properties of the POMDP framework for effective modeling and solution. For practitioners, the survey provides some of the key task characteristics in deciding when and how to apply POMDPs to robot tasks successfully. For POMDP algorithm designers, the survey provides new insights into the unique challenges of applying POMDPs to robot systems and points to promising new directions for further research."
Robotics (cs.RO),2022,8,Partially Observable Markov Decision Processes and Robotics,145,N/A,https://www.semanticscholar.org/paper/17339deade6b44c67644c5b396530482f2f0e43d,H. Kurniawati,"Planning under uncertainty is critical to robotics. The partially observable Markov decision process (POMDP) is a mathematical framework for such planning problems. POMDPs are powerful because of their careful quantification of the nondeterministic effects of actions and the partial observability of the states. But for the same reason, they are notorious for their high computational complexity and have been deemed impractical for robotics. However, over the past two decades, the development of sampling-based approximate solvers has led to tremendous advances in POMDP-solving capabilities. Although these solvers do not generate the optimal solution, they can compute good POMDP solutions that significantly improve the robustness of robotics systems within reasonable computational resources, thereby making POMDPs practical for many realistic robotics problems. This article presents a review of POMDPs, emphasizing computational issues that have hindered their practicality in robotics and ideas in sampling-based solvers that have alleviated such difficulties, together with lessons learned from applying POMDPs to physical robots. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 5 is May 2022. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates."
Robotics (cs.RO),2022,10,Haptic Feedback and Force-Based Teleoperation in Surgical Robotics,134,N/A,https://www.semanticscholar.org/paper/f549760051abf6f44021e996037a5141bdcb25c1,"Rajnikant V. Patel, S. F. Atashzar, M. Tavakoli","This article presents an overview of the current state of research and application of haptic (primarily kinesthetic) feedback and force-based teleoperation in the context of surgical robotics. Telerobotic surgery provides an approach for transferring the sensorimotor skills of a surgeon through a robotic platform to perform surgical intervention inside a patient’s body. Integration of advanced sensing and haptic technologies in telerobotic surgery can help to enhance the sensory awareness and motor accuracy of the surgeon, thereby leading to improved surgical procedures and outcomes for patients. The primary mode of sensory feedback has been through 3-D visual observation using stereo endoscopes. However, until recently, the sense of touch, i.e., haptics, has been missing in the commercial telesurgery robots approved for use in the operating room despite over two decades of research and development in the field of haptics for teleoperated systems (“telehaptics”). Research has shown that high-fidelity force feedback can enhance the performance of telesurgery and potential outcomes by enabling the surgeon to have a more natural feel of interaction between surgical tools and tissue as normally experienced during open surgery. Interaction forces, such as those generated during palpation of tissue, insertion of a needle, unintentional (and potentially unsafe) exertion of force by a tool, suture breakage, needle slippage, or tool interaction, are replaced by indirect (virtual) sensations, termed visual haptics, which provides an alternative to sensory compensation. Although there is a significant amount of literature supporting this benefit, there are still several important technical challenges in introducing haptics in telesurgery, including instrumentation, fidelity (transparency), stability, and modalities for force reflection, e.g., direct or indirect. This article examines these challenges and discusses recent work on haptics-based teleoperated surgical robotic systems."
Robotics (cs.RO),2022,15,"Progress, Challenges, and Prospects of Soft Robotics for Space Applications",130,N/A,https://www.semanticscholar.org/paper/1ec79643154317bd9535f3f791b6e801473ef7ec,"Yongchang Zhang, Pengchun Li, Jiale Quan et al.","The development of space robots is vital to broadening human cognitive boundaries. Space robots have been deployed in space science experiments, extravehicular operations, and deep space exploration. The application of space robots undoubtedly reduces the risk and cost of space activities. Traditional space robots primarily utilize rigid structures, resulting in limited degrees of freedom, which restricts their operational capabilities. In contrast, soft robots with greater flexibility and robustness may be used for future space exploration. Soft robots applied in space environments must overcome significant challenges associated with ultrahigh vacuum, microgravity, extreme temperatures, and high‐energy radiation. Herein, a comprehensive analysis of the key advantages of soft robots is presented based on the special requirements of the space environments for soft robots. Furthermore, brief insights into how soft robots must be changed in terms of their design, modeling, fabrication, sensing, and control to adapt to space environments are discussed. Specifically, soft robot scenarios with potential space application value are introduced. Finally, opinions regarding the potential directions of soft space robots are provided."
Robotics (cs.RO),2022,17,Recent advancements of robotics in construction,128,N/A,https://www.semanticscholar.org/paper/8035f844bb5d580820844c43255691d345c28d36,"Bo Xiao, Chen Chen, Xianfei Yin",No Abstract
Robotics (cs.RO),2022,18,Robust Safety-Critical Control for Dynamic Robotics,126,N/A,https://www.semanticscholar.org/paper/3e204331f185e522273b53b39aff00fdb1387738,"Quan Nguyen, K. Sreenath","We present a novel method of optimal robust control through quadratic programs that offers tracking stability while subject to input and state-based constraints as well as safety-critical constraints for nonlinear dynamical robotic systems in the presence of model uncertainty. The proposed method formulates robust control Lyapunov and barrier functions to provide guarantees of stability and safety in the presence of model uncertainty. We evaluate our proposed control design on dynamic walking of a five-link planar bipedal robot subject to contact force constraints as well as safety-critical precise foot placements on stepping stones, all while subject to model uncertainty. We conduct preliminary experimental validation of the proposed controller on a rectilinear spring-cart system under different types of model uncertainty and perturbations."
Robotics (cs.RO),2022,13,A concise guide to modelling the physics of embodied intelligence in soft robotics,115,N/A,https://www.semanticscholar.org/paper/d42b8056da7529be9ffd8634bc2ee52f7f13d975,"Gianmarco Mengaldo, F. Renda, S. Brunton et al.",No Abstract
Robotics (cs.RO),2022,16,Consumers’ adoption of artificial intelligence and robotics in hospitality and tourism sector: literature review and future research agenda,98,N/A,https://www.semanticscholar.org/paper/69f5cf242675bce4b623821f570ff75b8255745e,"P. Goel, N. Kaushik, Brijesh Sivathanu et al."," Purpose The purpose of this study, a current systematic literature review, is to synthesize the extant literature on consumers’ adoption of artificial intelligence and robotics (AIR) in the context of the hospitality and tourism sector (HATS) to gain a comprehensive understanding of it. This study also outlines insights for academia, practitioners, AI marketers, developers, designers and policymakers.   Design/methodology/approach This study used a content analysis approach to conduct a systematic literature review for the period of 10 years (2011–2020) of the various published studies themed around consumer’s adoption of AIR in HATS.   Findings The synthesis draws upon various factors affecting the adoption of AIR, such as individual factors, service factors, technical and performance factors, social and cultural factors and infrastructural factors. Additionally, the authors identified four major barriers, namely, psychological, social, financial, technical and functional that hinder the consumer’s adoption of artificial intelligence and robots in the hospitality and tourism industry.   Originality/value To the best of the author’s/authors’ knowledge, this study is a first attempt to synthesize the factors that drive consumers’ adoption of artificial intelligence and robots in the hospitality and tourism industry. The present work also advances the tourism and consumer behavior literature by offering an integrated antecedent-outcome framework.   Visual abstract Figure 2 The objective of the current systematic literature review is to synthesize the extant literature on consumer’s adoption of artificial intelligence and robotics (AIR) in the context of the hospitality and tourism sector (HATS) to gain a comprehensive understanding of it. For that purpose, authors conducted content analysis of extant literature on consumer’s adoption of AIR in HATS from 2011 to 2020. Authors presented an integrated antecedent outcome framework of the factors that drive consumer’s adoption of artificial intelligence and robots in the hospitality and tourism industry. "
Robotics (cs.RO),2022,19,Neuromorphic computing hardware and neural architectures for robotics,90,N/A,https://www.semanticscholar.org/paper/188f9727511735722b99ef4408eaafd557651bde,"Yulia Sandamirskaya, Mohsen Kaboli, J. Conradt et al.",No Abstract
Robotics (cs.RO),2022,20,A systematic review study on educational robotics and robots,81,N/A,https://www.semanticscholar.org/paper/253f8602c6ff4fffdcb27f1781a60054835e23c7,"N. A. Uslu, G. Yavuz, Y. Usluel","ABSTRACT This study, which systematically examines educational robotics and robots (ERR), has two purposes. (1) Classifying the research on the ERR to identify research trends and gaps, (2) Summarizing the experimental findings related to ERR and to interpret them according to the claims in the literature. A mixed method combining systematic mapping and systematic review were used in the study. Ninety-three articles published in Social Sciences Citation Index (SSCI) indexed journals and meeting the specified criteria were analyzed using a systematic mapping process. The results showed that 40 out of 93 articles did not include any learning theory. Thirty-two experimental studies were analyzed within the scope of the systematic review. The empirical findings supporting some of the claims about ERR are summarized and the research gaps in the claims that need to be supported by theoretical and pedagogical approaches are revealed."
Robotics (cs.RO),2023,7,"Artificial Intelligence, Machine Learning and Deep Learning in Advanced Robotics, A Review",724,N/A,https://www.semanticscholar.org/paper/d3b7dd1ebf5230503482afea2a255b14333e6c16,"Mohsen Soori, B. Arezoo, Roza Dastres",No Abstract
Robotics (cs.RO),2023,1,ChatGPT for Robotics: Design Principles and Model Abilities,597,2306.17582,https://www.semanticscholar.org/paper/0ba581718f294db1d7b3dbc159cc3d3380f74606,"Sai H. Vemprala, Rogerio Bonatti, A. Bucker et al.","This paper presents an experimental study regarding the use of OpenAI’s ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT’s ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions. In addition to these studies, we introduce an open-sourced research tool called PromptCraft, which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics. Videos and blog: aka.ms/ChatGPT-Robotics PromptCraft, AirSim-ChatGPT code: https://github.com/microsoft/PromptCraft-Robotics"
Robotics (cs.RO),2023,3,"Foundation models in robotics: Applications, challenges, and the future",266,2312.07843,https://www.semanticscholar.org/paper/5f0b826ffe17faa2cdec21752e7d1863bd909f2c,"Roya Firoozi, Johnathan Tucker, Stephen Tian et al.","We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models."
Robotics (cs.RO),2023,2,Affordances from Human Videos as a Versatile Representation for Robotics,247,2304.08488,https://www.semanticscholar.org/paper/253b41369d003952874c6a47a6038277b165cfa0,"Shikhar Bahl, R. Mendonca, Lili Chen et al.","Building a robot that can understand and learn to interact by watching humans has inspired several vision problems. However, despite some successful results on static datasets, it remains unclear how current models can be used on a robot directly. In this paper, we aim to bridge this gap by leveraging videos of human interactions in an environment centric manner. Utilizing internet videos of human behavior, we train a visual affordance model that estimates where and how in the scene a human is likely to interact. The structure of these behavioral affordances directly enables the robot to perform many complex tasks. We show how to seamlessly integrate our affordance model with four robot learning paradigms including offline imitation learning, exploration, goal-conditioned learning, and action parameterization for reinforcement learning. We show the efficacy of our approach, which we call Vision-Robotics Bridge (VRB) across 4 real world environments, over 10 different tasks, and 2 robotic platforms operating in the wild."
Robotics (cs.RO),2023,8,Sensing in Soft Robotics,207,N/A,https://www.semanticscholar.org/paper/25aea54b2a3b532767e7e1c1e093de8c213a84ad,"Chidanand Hegde, Jiangtao Su, J. M. R. Tan et al.","Soft robotics is an exciting field of science and technology that enables robots to manipulate objects with human-like dexterity. Soft robots can handle delicate objects with care, access remote areas, and offer realistic feedback on their handling performance. However, increased dexterity and mechanical compliance of soft robots come with the need for accurate control of the position and shape of these robots. Therefore, soft robots must be equipped with sensors for better perception of their surroundings, location, force, temperature, shape, and other stimuli for effective usage. This review highlights recent progress in sensing feedback technologies for soft robotic applications. It begins with an introduction to actuation technologies and material selection in soft robotics, followed by an in-depth exploration of various types of sensors, their integration methods, and the benefits of multimodal sensing, signal processing, and control strategies. A short description of current market leaders in soft robotics is also included in the review to illustrate the growing demands of this technology. By examining the latest advancements in sensing feedback technologies for soft robots, this review aims to highlight the potential of soft robotics and inspire innovation in the field."
Robotics (cs.RO),2023,5,Large Language Models for Robotics: A Survey,191,2311.07226,https://www.semanticscholar.org/paper/d3367dc9a7a1d7ae70a06eadc02b2430f4529f7c,"Fanlong Zeng, Wensheng Gan, Yongheng Wang et al.","The human ability to learn, generalize, and control complex manipulation tasks through multi-modality feedback suggests a unique capability, which we refer to as dexterity intelligence. Understanding and assessing this intelligence is a complex task. Amidst the swift progress and extensive proliferation of large language models (LLMs), their applications in the field of robotics have garnered increasing attention. LLMs possess the ability to process and generate natural language, facilitating efficient interaction and collaboration with robots. Researchers and engineers in the field of robotics have recognized the immense potential of LLMs in enhancing robot intelligence, human-robot interaction, and autonomy. Therefore, this comprehensive review aims to summarize the applications of LLMs in robotics, delving into their impact and contributions to key areas such as robot control, perception, decision-making, and planning. This survey first provides an overview of the background and development of LLMs for robotics, followed by a discussion of their benefits and recent advancements in LLM-based robotic models. It then explores various techniques, employed in perception, decision-making, control, and interaction, as well as cross-module coordination in practical tasks. Finally, we review current applications of LLMs in robotics and outline potential challenges they may face in the near future. Embodied intelligence represents the future of intelligent systems, and LLM-based robotics is one of the most promising yet challenging paths toward achieving it."
Robotics (cs.RO),2023,4,Language-Driven Representation Learning for Robotics,189,2302.12766,https://www.semanticscholar.org/paper/3396609b96dd24cac3b1542aec686ce362f32fe2,"Siddharth Karamcheti, Suraj Nair, Annie S. Chen et al.","Recent work in visual representation learning for robotics demonstrates the viability of learning from large video datasets of humans performing everyday tasks. Leveraging methods such as masked autoencoding and contrastive learning, these representations exhibit strong transfer to policy learning for visuomotor control. But, robot learning encompasses a diverse set of problems beyond control including grasp affordance prediction, language-conditioned imitation learning, and intent scoring for human-robot collaboration, amongst others. First, we demonstrate that existing representations yield inconsistent results across these tasks: masked autoencoding approaches pick up on low-level spatial features at the cost of high-level semantics, while contrastive learning approaches capture the opposite. We then introduce Voltron, a framework for language-driven representation learning from human videos and associated captions. Voltron trades off language-conditioned visual reconstruction to learn low-level visual patterns, and visually-grounded language generation to encode high-level semantics. We also construct a new evaluation suite spanning five distinct robot learning problems $\unicode{x2013}$ a unified platform for holistically evaluating visual representations for robotics. Through comprehensive, controlled experiments across all five problems, we find that Voltron's language-driven representations outperform the prior state-of-the-art, especially on targeted problems requiring higher-level features."
Robotics (cs.RO),2023,9,Fatigue‐Resistant Conducting Polymer Hydrogels as Strain Sensor for Underwater Robotics,186,N/A,https://www.semanticscholar.org/paper/b012ad42c4b62d44b92f89b9910bb876b4841e72,"Zhilin Zhang, Guangda Chen, Yunhe Xue et al.","Conducting polymer hydrogels are widely used as strain sensors in light of their distinct skin‐like softness, strain sensitivity, and environmental adaptiveness in the fields of wearable devices, soft robots, and human‐machine interface. However, the mechanical and electrical properties of existing conducting polymer hydrogels, especially fatigue‐resistance and sensing robustness during long‐term application, are unsatisfactory, which severely hamper their practical utilities. Herein, a strategy to fabricate conducting polymer hydrogels with anisotropic structures and mechanics is presented through a combined freeze‐casting and salting‐out process. The as‐fabricated conducting polymer hydrogels exhibit high fatigue threshold (>300 J m−2), low Young's modulus (≈100 kPa), as well as long‐term strain sensing robustness (over 10 000 cycles). Such superior performance enables their application as strain sensors to monitor the real‐time movement of underwater robotics. The design and fabrication strategy for conducting polymer hydrogels reported in this study may open up an enticing avenue for functional soft materials in soft electronics and robotics."
Robotics (cs.RO),2023,10,3D-printed PEDOT:PSS for soft robotics,172,N/A,https://www.semanticscholar.org/paper/e4cf0071b69aec82e15a6f3c2a7fcc8e97da20ad,"Jinhao Li, Jie Cao, Baoyang Lu et al.",No Abstract
Robotics (cs.RO),2023,6,Ethical implications of AI and robotics in healthcare: A review,163,N/A,https://www.semanticscholar.org/paper/c1e1e971d993a50fa470710bb7a7bbbb4ce5b1af,"Chukwuka Elendu, Dependable C. Amaechi, T. C. Elendu et al.","Integrating Artificial Intelligence (AI) and robotics in healthcare heralds a new era of medical innovation, promising enhanced diagnostics, streamlined processes, and improved patient care. However, this technological revolution is accompanied by intricate ethical implications that demand meticulous consideration. This article navigates the complex ethical terrain surrounding AI and robotics in healthcare, delving into specific dimensions and providing strategies and best practices for ethical navigation. Privacy and data security are paramount concerns, necessitating robust encryption and anonymization techniques to safeguard patient data. Responsible data handling practices, including decentralized data sharing, are critical to preserve patient privacy. Algorithmic bias poses a significant challenge, demanding diverse datasets and ongoing monitoring to ensure fairness. Transparency and explainability in AI decision-making processes enhance trust and accountability. Clear responsibility frameworks are essential to address the accountability of manufacturers, healthcare institutions, and professionals. Ethical guidelines, regularly updated and accessible to all stakeholders, guide decision-making in this dynamic landscape. Moreover, the societal implications of AI and robotics extend to accessibility, equity, and societal trust. Strategies to bridge the digital divide and ensure equitable access must be prioritized. Global collaboration is pivotal in developing adaptable regulations and addressing legal challenges like liability and intellectual property. Ethics must remain at the forefront in the ever-evolving realm of healthcare technology. By embracing these strategies and best practices, healthcare systems and professionals can harness the potential of AI and robotics, ensuring responsible and ethical integration that benefits patients while upholding the highest ethical standards."
Robotics (cs.RO),2023,11,"Embedment of sensing elements for robust, highly sensitive, and cross-talk–free iontronic skins for robotics applications",159,N/A,https://www.semanticscholar.org/paper/8b1ed7ebe11b79c6dc45b481d7c030a4a0528b61,"Junli Shi, Yuan Dai, Yu Cheng et al.","Iontronic pressure sensors are promising in robot haptics because they can achieve high sensing performance using nanoscale electric double layers (EDLs) for capacitive signal output. However, it is challenging to achieve both high sensitivity and high mechanical stability in these devices. Iontronic sensors need microstructures that offer subtly changeable EDL interfaces to boost sensitivity, while the microstructured interfaces are mechanically weak. Here, we embed isolated microstructured ionic gel (IMIG) in a hole array (28 × 28) of elastomeric matrix and cross-link the IMIGs laterally to achieve enhanced interfacial robustness without sacrificing sensitivity. The embedded configuration toughens and strengthens the skin by pinning cracks and by the elastic dissipation of the interhole structures. Furthermore, cross-talk between the sensing elements is suppressed by isolating the ionic materials and by designing a circuit with a compensation algorithm. We have demonstrated that the skin is potentially useful for robotic manipulation tasks and object recognition."
Robotics (cs.RO),2023,12,Application of AI Techniques and Robotics in Agriculture: A Review,149,N/A,https://www.semanticscholar.org/paper/39f0678bb1f261776f3a9eb74fee525bbbf3e558,"Manas Wakchaure, B. Patle, A. Mahindrakar",No Abstract
Robotics (cs.RO),2023,17,"Robotics, Vision and Control: Fundamental Algorithms in MATLAB®",135,N/A,https://www.semanticscholar.org/paper/ef32474f5a98c43a15a4b938d8d09ff093a0433f,"Peter I. Corke, Witold Jachimczyk, Remo Pillat",No Abstract
Robotics (cs.RO),2023,15,Artificial intelligence meets medical robotics,115,N/A,https://www.semanticscholar.org/paper/54de9ed44bb1022b7c3ec67a9e9c2224dc8bce0f,"Michael C. Yip, S. Salcudean, Ken Goldberg et al.","Description Artificial intelligence (AI) applications in medical robots are bringing a new era to medicine. Advanced medical robots can perform diagnostic and surgical procedures, aid rehabilitation, and provide symbiotic prosthetics to replace limbs. The technology used in these devices, including computer vision, medical image analysis, haptics, navigation, precise manipulation, and machine learning (ML) , could allow autonomous robots to carry out diagnostic imaging, remote surgery, surgical subtasks, or even entire surgical procedures. Moreover, AI in rehabilitation devices and advanced prosthetics can provide individualized support, as well as improved functionality and mobility (see the figure). The combination of extraordinary advances in robotics, medicine, materials science, and computing could bring safer, more efficient, and more widely available patient care in the future. –Gemma K. Alderton"
Robotics (cs.RO),2023,16,Knowledge-integrated machine learning for materials: lessons from gameplaying and robotics,103,N/A,https://www.semanticscholar.org/paper/0f99ec01472af668be23cf14b0f6953f170082ad,"Kedar Hippalgaonkar, Qianxiao Li, Xiaonan Wang et al.",No Abstract
Robotics (cs.RO),2023,19,From the Desks of ROS Maintainers: A Survey of Modern & Capable Mobile Robotics Algorithms in the Robot Operating System 2,101,2307.15236,https://www.semanticscholar.org/paper/51e1ed0f86cb14479acdbf0b922c0d24b1c3e990,"Steve Macenski, Thomas Moore, David V. Lu et al.",No Abstract
Robotics (cs.RO),2023,18,GPT-4V(ision) for Robotics: Multimodal Task Planning From Human Demonstration,99,2311.12015,https://www.semanticscholar.org/paper/30d5a29a35eb7268ff9fe0779f1303a640c9159b,"Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi et al.","We introduce a pipeline that enhances a general-purpose Vision Language Model, GPT-4V(ision), to facilitate one-shot visual teaching for robotic manipulation. This system analyzes videos of humans performing tasks and outputs executable robot programs that incorporate insights into affordances. The process begins with GPT-4 V analyzing the videos to obtain textual explanations of environmental and action details. A GPT-4-based task planner then encodes these details into a symbolic task plan. Subsequently, vision systems spatially and temporally ground the task plan in the videos—objects are identified using an open-vocabulary object detector, and hand-object interactions are analyzed to pinpoint moments of grasping and releasing. This spatiotemporal grounding allows for the gathering of affordance information (e.g., grasp types, waypoints, and body postures) critical for robot execution. Experiments across various scenarios demonstrate the method's efficacy in enabling real robots to operate from one-shot human demonstrations. Meanwhile, quantitative tests have revealed instances of hallucination in GPT-4 V, highlighting the importance of incorporating human supervision within the pipeline."
Robotics (cs.RO),2023,13,RoboVQA: Multimodal Long-Horizon Reasoning for Robotics,95,2311.00899,https://www.semanticscholar.org/paper/0b47356f17aea1de66e39e5f182a105c96af8dd3,"P. Sermanet, Tianli Ding, Jeffrey Zhao et al.","We present a scalable, bottom-up and intrinsically diverse data collection scheme that can be used for high-level reasoning with long and medium horizons and that has 2.2x higher throughput compared to traditional narrow top-down step-by-step collection. We collect realistic data by performing any user requests within the entirety of 3 office buildings and using multiple embodiments (robot, human, human with grasping tool). With this data, we show that models trained on all embodiments perform better than ones trained on the robot data only, even when evaluated solely on robot episodes. We explore the economics of collection costs and find that for a fixed budget it is beneficial to take advantage of the cheaper human collection along with robot collection. We release a large and highly diverse (29,520 unique instructions) dataset dubbed RoboVQA containing 829,502 (video, text) pairs for robotics-focused visual question answering. We also demonstrate how evaluating real robot experiments with an intervention mechanism enables performing tasks to completion, making it deployable with human oversight even if imperfect while also providing a single performance metric. We demonstrate a single video-conditioned model named RoboVQA-VideoCoCa trained on our dataset that is capable of performing a variety of grounded high-level reasoning tasks in broad realistic settings with a cognitive intervention rate 46% lower than the zeroshot state of the art visual language model (VLM) baseline and is able to guide real robots through long-horizon tasks. The performance gap with zero-shot state-of-the-art models indicates that a lot of grounded data remains to be collected for real-world deployment, emphasizing the critical need for scalable data collection approaches. Finally, we show that video VLMs significantly outperform single-image VLMs with an average error rate reduction of 19% across all VQA tasks. Thanks to video conditioning and dataset diversity, the model can be used as general video value functions (e.g. success and affordance) in situations where actions needs to be recognized rather than states, expanding capabilities and environment understanding for robots. Data and videos are available at robovqa.github.io"
Robotics (cs.RO),2023,20,Sunlight-powered self-excited oscillators for sustainable autonomous soft robotics,94,N/A,https://www.semanticscholar.org/paper/cd0551470700114f677ca29b4bba21fdbe2c25fb,"Yusen Zhao, Qiaofeng Li, Zixiao Liu et al.","As the field of soft robotics advances, full autonomy becomes highly sought after, especially if robot motion can be powered by environmental energy. This would present a self-sustained approach in terms of both energy supply and motion control. Now, autonomous movement can be realized by leveraging out-of-equilibrium oscillatory motion of stimuli-responsive polymers under a constant light source. It would be more advantageous if environmental energy could be scavenged to power robots. However, generating oscillation becomes challenging under the limited power density of available environmental energy sources. Here, we developed fully autonomous soft robots with self-sustainability based on self-excited oscillation. Aided by modeling, we have successfully reduced the required input power density to around one-Sun level through a liquid crystal elastomer (LCE)–based bilayer structure. The autonomous motion of the low-intensity LCE/elastomer bilayer oscillator “LiLBot” under low energy supply was achieved by high photothermal conversion, low modulus, and high material responsiveness simultaneously. The LiLBot features tunable peak-to-peak amplitudes from 4 to 72 degrees and frequencies from 0.3 to 11 hertz. The oscillation approach offers a strategy for designing autonomous, untethered, and sustainable small-scale soft robots, such as a sailboat, walker, roller, and synchronized flapping wings. Description A liquid crystal elastomer–based oscillator can sustain various types of soft robotic locomotion powered by natural sunlight."
Robotics (cs.RO),2023,14,Trends and research foci of robotics-based STEM education: a systematic review from diverse angles based on the technology-based learning model,90,N/A,https://www.semanticscholar.org/paper/44b3e157294a9c75a620b8ba6c22d92671886cfe,"Darmawansah Darmawansah, Gwo-jen Hwang, Mei-Rong Alice Chen et al.","Fostering students’ competence in applying interdisciplinary knowledge to solve problems has been recognized as an important and challenging issue globally. This is why STEM (Science, Technology, Engineering, Mathematics) education has been emphasized at all levels in schools. Meanwhile, the use of robotics has played an important role in STEM learning design. The purpose of this study was to fill a gap in the current review of research on Robotics-based STEM (R-STEM) education by systematically reviewing existing research in this area. This systematic review examined the role of robotics and research trends in STEM education. A total of 39 articles published between 2012 and 2021 were analyzed. The review indicated that R-STEM education studies were mostly conducted in the United States and mainly in K-12 schools. Learner and teacher perceptions were the most popular research focus in these studies which applied robots. LEGO was the most used tool to accomplish the learning objectives. In terms of application, Technology (programming) was the predominant robotics-based STEM discipline in the R-STEM studies. Moreover, project-based learning (PBL) was the most frequently employed learning strategy in robotics-related STEM research. In addition, STEM learning and transferable skills were the most popular educational goals when applying robotics. Based on the findings, several implications and recommendations to researchers and practitioners are proposed."
Security (cs.CR),2019,1,Clinical Computer Security for Victims of Intimate Partner Violence,108,N/A,https://www.semanticscholar.org/paper/df8120eecb03a59ae6f94bd48e4adfaad1a699f0,"S. Havron, D. Freed, Rahul Chatterjee et al.",No Abstract
Security (cs.CR),2019,2,"""Is my phone hacked?"" Analyzing Clinical Computer Security Interventions with Survivors of Intimate Partner Violence",98,N/A,https://www.semanticscholar.org/paper/1cc3d7cbc37a51f330e9c9475b418f8870c98b72,"D. Freed, S. Havron, Emily Tseng et al.","Intimate partner abusers use technology to track, monitor, harass, and otherwise harm their victims, and prior work reports that victims have few resources for obtaining help with such attacks. This paper presents a qualitative analysis of data from a field study of an approach to helping survivors of intimate partner violence (IPV) with technology abuse. In this approach, called clinical computer security, a trained technologist performs a face-to-face consultation with an IPV survivor to help them understand and navigate technology issues. Findings from consultations with 31 survivors, as well as IPV professionals working on their behalf, uncovered a range of digital security and privacy vulnerabilities exacerbated by the nuanced social context of such abuse. In this paper we explore survivor experiences with, and reactions to, the consultations, discussing (1) the ways in which survivors present their tech concerns, (2) the cooperative work required to guide survivors towards understanding probable causes of tech insecurity, (3) survivors' reactions to the consultations, particularly when security vulnerabilities or spyware are discovered, and (4) the role we play as consultants and interventionists in the complex socio-technical systems involved in mitigating IPV. We conclude by discussing some of the broad ethical and sustainability challenges raised by our work, and provide design opportunities for tech platforms to better support survivors of IPV."
Security (cs.CR),2019,3,Computer Security and Privacy in the Interactions Between Victim Service Providers and Human Trafficking Survivors,38,N/A,https://www.semanticscholar.org/paper/a4ee9f4aa9c5adf0055c133caf227ee34d699a99,"Christine Chen, Nicola Dell, Franziska Roesner",No Abstract
Security (cs.CR),2019,14,The Effect of Entertainment Media on Mental Models of Computer Security,35,N/A,https://www.semanticscholar.org/paper/54927f7f4c3a0c0761b9ef71bbb7db84a2ec17cf,"Kelsey R. Fulton, Rebecca Gelles, A. Mckay et al.",No Abstract
Security (cs.CR),2019,4,Using deep learning to solve computer security challenges: a survey,34,1912.05721,https://www.semanticscholar.org/paper/a2e1e64f093ee9fc39d71b2f348a6c1e7033658a,"Yoon-Ho Choi, Peng Liu, Zitong Shang et al.","Although using machine learning techniques to solve computer security challenges is not a new idea, the rapidly emerging Deep Learning technology has recently triggered a substantial amount of interests in the computer security community. This paper seeks to provide a dedicated review of the very recent research works on using Deep Learning techniques to solve computer security challenges. In particular, the review covers eight computer security problems being solved by applications of Deep Learning: security-oriented program analysis, defending return-oriented programming (ROP) attacks, achieving control-flow integrity (CFI), defending network attacks, malware classification, system-event-based anomaly detection, memory forensics, and fuzzing for software security."
Security (cs.CR),2019,5,Computer-Security-Oriented Escape Room,22,N/A,https://www.semanticscholar.org/paper/35c9b8dc8a5644ffba9b3d6adb9fd85f7659f249,"Erwan Béguin, Solal Besnard, A. Cros et al.","Every day, new types of attacks are being developed with companies as their targets. If employees are not aware of the consequences and tactics of such attacks, they cannot protect the companies that employ them. Current teaching methods, such as lectures and videos, may not adequately prepare participants in security-related courses for real-life situations. To raise awareness about computer security, teachers and students of l'Instititut National des Sciences Appliquées de Toulouse developed two escape rooms with different approaches to the same goal: raising awareness. Players learn how to reduce risks from computer attacks during hour-long real-life simulations. Choosing strong passwords and spotting phishing emails are just a few of the habits our escape-room scenarios can instill in participants to mitigate the damage of hacks and social-engineering attacks."
Security (cs.CR),2019,6,Review of Human Decision-making during Computer Security Incident Analysis,17,1903.10080,https://www.semanticscholar.org/paper/9b8fc0d0f75f64d161696c4829d26b5b637b9cd4,"Jonathan M. Spring, P. Illari","We review practical advice on decision-making during computer security incident response. Scope includes standards from the IETF, ISO, FIRST, and the US intelligence community. To focus on human decision-making, the scope is the evidence collection, analysis, and reporting phases of response, which includes human decision-making within and connecting these phases. The results indicate both strengths and gaps. A strength is available advice on how to accomplish many specific tasks. However, there is little guidance on how to prioritize tasks in limited time or how to interpret, generalize, and convincingly report results. Future work should focus on these gaps in explication and specification of decision-making during incident analysis."
Security (cs.CR),2019,17,A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions,17,N/A,https://www.semanticscholar.org/paper/82a9fd1c260b1c7cdfb849937003df0d7504254a,"Alisa Frik, Nathan Malkin, Marian Harbach et al.","Commitment devices are a technique from behavioral economics that have been shown to mitigate the effects of present bias---the tendency to discount future risks and gains in favor of immediate gratifications. In this paper, we explore the feasibility of using commitment devices to nudge users towards complying with varying online security mitigations. Using two online experiments, with over 1,000 participants total, we offered participants the option to be reminded or to schedule security tasks in the future. We find that both reminders and commitment nudges can increase users' intentions to install security updates and enable two-factor authentication, but not to configure automatic backups. Using qualitative data, we gain insights into the reasons for postponement and how to improve future nudges. We posit that current nudges may not live up to their full potential, as the timing options offered to users may be too rigid."
Security (cs.CR),2019,8,Don't Paint It Black: White-Box Explanations for Deep Learning in Computer Security,9,N/A,https://www.semanticscholar.org/paper/143dc49b43d8e1b1ef9682e56ccd70b1d3358f63,"Alexander Warnecke, Daniel Arp, Christian Wressnegger et al.",No Abstract
Security (cs.CR),2019,9,A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats,6,N/A,https://www.semanticscholar.org/paper/7f4a5b3c0efae86a7d52605c10f56825a6483945,"Mahmood Sharif, Kevin A. Roundy, Matteo Dell'Amico et al.","Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users."
Security (cs.CR),2019,10,"Trends on Computer Security: Cryptography, User Authentication, Denial of Service and Intrusion Detection",6,1903.08052,https://www.semanticscholar.org/paper/c31ba7d7e0c0d01e0ed4800a058de7f9c0d4f5a5,"Pablo Daniel Marcillo Lara, Daniel Alejandro Maldonado-Ruiz, Santiago Daniel Arrais Díaz et al.","The new generation of security threats has been promoted by digital currencies and real-time applications, where all users develop new ways to communicate on the Internet. Security has evolved in the need of privacy and anonymity for all users and his portable devices. New technologies in every field prove that users need security features integrated into their communication applications, parallel systems for mobile devices, internet, and identity management. This review presents the key concepts of the main areas in computer security and how it has evolved in the last years. This work focuses on cryptography, user authentication, denial of service attacks, intrusion detection and firewalls."
Security (cs.CR),2019,7,Deviant security: the technical computer security practices of cyber criminals,5,N/A,https://www.semanticscholar.org/paper/798d1a90c27831ff85c5706f2ca98092c1b73df0,Erik van de Sandt,No Abstract
Security (cs.CR),2019,11,"End user nonmalicious, counterproductive computer security behaviors: concept, development, and validation of an instrument",5,N/A,https://www.semanticscholar.org/paper/1421684f675b2e3c3fda85a7680c5204282788fa,P. Ifinedo,"Employees' engagement in nonmalicious, counterproductive computer security behaviors (CCSB) poses a threat to organizations' information systems (IS) resources and assets. In order to understand CCSB, there is a need to propose theoretical foundations to research the phenomenon and to offer useful tools to help organizations assess such behaviors in their particular contexts. Relevant instruments that systematically measure or assess workers' participation in CCSB remain underdeveloped. This study proposes an instrument to assess engagement in CCSB. Confirmatory factor analysis confirmed three subscales of CCSB, that is, “careless use of IS resources,” “procrastinating carrying out required IS actions,” and “improper use of IS resources.” The instrument's relevance to research and practice is discussed and directions for future research are outlined."
Security (cs.CR),2019,13,Developing a mental model for use in the context of computer security,5,N/A,https://www.semanticscholar.org/paper/8750fd3a46df4d7a710fd245daf5bcd2cea5276c,"Isaiah Liljestrand, Marcelo Gonzales, Dongwan Shin","A mental model is a useful tool for describing user's general mental processes that go into certain actions. In this paper, we investigate how to enhance the usability of security applications by considering human factors. Specifically, we study how to better understand and develop the user's mental model in the context of computer security through the use of the reasoned action approach (RAA). RAA explains that a user's behavior is determined by her intention to perform the behavior and the intention is, in turn, a function of attitudes towards the behavior, perceived norms (or social pressure), and perceived behavior control (capacity and relevant skills/abilities). A user study was conducted to test the validity of each of the main components of the model. Our user study concluded that alterations to a computer security application improved by the analysis through the mental model created improved user behavior."
Security (cs.CR),2019,12,On Automation and Orchestration of an Initial Computer Security Incident Response by Introducing Centralized Incident Tracking System,4,N/A,https://www.semanticscholar.org/paper/7b08f5c4488942804275ac54c50fe0e213a152a6,Motoyuki Ohmori,": A critical computer security incident may cause great damage to an organization for example by a conﬁ-dential data breach or malware pandemic. In order to avoid or mitigate such damage, a quick and accurate response against a computer security incident is becoming more important. In order to realize these quickness and accuracy, this paper presents the Incident Tracking System (ITS) that orchestrates several information systems and automates an initial incident response. The ITS automatically locates and isolates a suspicious host, and sends a mail notiﬁcation to the person in charge of handling an incident. The ITS can also identify or suggest a user of the suspicious host by network authentication logs or other service logs"
Security (cs.CR),2019,15,Design and Realization of a Computer Security Control Circuit for Local Area Network,2,N/A,https://www.semanticscholar.org/paper/0b1e54ab2cfc7491ecc48683b6b1abc3ad3959e7,"Yiyong Lin, Lei Lin","A local area network (LAN) computer security control circuit is designed for the practical problem of LAN computer users ""one machine crosses two networks"" on this paper, which provides a protection barrier for the information security of LAN computers on the hardware. This paper briefly analyzes the risks and challenges faced by LAN security. The overall design idea, circuit design and working principle of LAN computer security control circuit are described in detail. The characteristics of the system are summarized. Finally, the design circuit is verified by practical application in the unit. The application results show that the circuit is stable in operation, simple in operation, safe and reliable, and convenient in installation and maintain, etc., which has achieved the design effect and played a good role in ensuring the security of the network information of the local area network."
Security (cs.CR),2019,16,Computer Security of NPP Instrumentation and Control Systems: Computer Security Justification Documents,2,N/A,https://www.semanticscholar.org/paper/59b51fc7a566cd839c77292f2c635a059e120f68,"A. Symonov, O. Klevtsov, S. Trubchaninov et al.","The approaches to the development and management of computer security justification documents on computer security policy, program and plan, computer incident response plan, reports related to computer security are considered in the paper. Requirements for computer security policy, program and plan are presented, and the analysis of different approaches adopted and reflected in the documents of the International Atomic Energy Agency, U.S. Nuclear Regulatory Commission and International Electrotechnical Commission is carried out. It is noted that the approaches used by these organizations to the development and management of computer security justification documents are quite similar.  The paper provides suggestions for the development of requirements for computer security justification documents on the instrumentation and control systems at Ukrainian NPPs.  The analysis of different international approaches to the development, implementation, and management of the computer security policy, program and plan has allowed developing requirements for the above-mentioned documents, which will be reflected in the new regulation taking into account the current situation at Ukrainian NPPs. Besides, it is planned to include separate requirements for computer security documentation of the developers of instrumentation and control systems regarding computer incident response plan and reporting documents on computer security in this regulation. The paper presents recommendations for the content, implementation and management of computer security justification documents."
Security (cs.CR),2019,18,Computer Security as Civil Defense,2,N/A,https://www.semanticscholar.org/paper/3e8b5b9172403f7ac75cf46d7c93c40890655308,M. Wolf,"Given the prevalence of computer systems, we must change our approaches by ensuring that civilians and companies can become responsible for much of their own cyberdefense."
Security (cs.CR),2019,19,"Managing Computer Security, Risk Analysis and Threat Using ISO 31000: 2009: Case Study at Seiyun Community College, Yemen",1,N/A,https://www.semanticscholar.org/paper/8cf893cb775ee660b392145fdd476e4a74f9e1b8,"Abdullah A. Al-khatib, Mohammed A. Hassan",No Abstract
Security (cs.CR),2019,20,Designing Computer Security Assessments to Reduce Plagiarism,1,N/A,https://www.semanticscholar.org/paper/c607a7a2099ec75a5a9e0a8f7b936287d60e4292,Rosanne English,"Plagiarism and other forms of academic dishonesty for computing science assessments is a well documented issue. A common mode of dealing with this is to apply plagiarism detector software to code submissions to check for suspected plagiarism based on how similar submissions are. However, it arguably is less well established how to design computing science specific assessments which aim to reduce the possibility of plagiarism, whilst not disadvantaging students who may struggle with some aspects of an assessment. This paper aims to report on the design and practice of such an assessment within a computer security course."
Security (cs.CR),2022,1,SoK: Explainable Machine Learning for Computer Security Applications,61,2208.10605,https://www.semanticscholar.org/paper/72c800b20d9956d9ffab855bf16f613b4b22da3e,"A. Nadeem, D. Vos, Clinton Cao et al.","Explainable Artificial Intelligence (XAI) aims to improve the transparency of machine learning (ML) pipelines. We systematize the increasingly growing (but fragmented) microcosm of studies that develop and utilize XAI methods for defensive and offensive cybersecurity tasks. We identify 3 cybersecurity stakeholders, i.e., model users, designers, and adversaries, who utilize XAI for 4 distinct objectives within an ML pipeline, namely 1) XAI-enabled user assistance, 2) XAI-enabled model verification, 3) explanation verification & robustness, and 4) offensive use of explanations. Our analysis of the literature indicates that many of the XAI applications are designed with little understanding of how they might be integrated into analyst workflows – user studies for explanation evaluation are conducted in only 14% of the cases. The security literature sometimes also fails to disentangle the role of the various stakeholders, e.g., by providing explanations to model users and designers while also exposing them to adversaries. Additionally, the role of model designers is particularly minimized in the security literature. To this end, we present an illustrative tutorial for model designers, demonstrating how XAI can help with model verification. We also discuss scenarios where interpretability by design may be a better alternative. The systematization and the tutorial enable us to challenge several assumptions, and present open problems that can help shape the future of XAI research within cybersecurity."
Security (cs.CR),2022,3,Principles Matter: Integrating an Ethics Intervention into a Computer Security Course,19,N/A,https://www.semanticscholar.org/paper/682517c409f478cffe7b9b6fb1ad8aadf493050d,"Justin Petelka, M. Finn, Franziska Roesner et al.",No Abstract
Security (cs.CR),2022,2,Impact of Capture The Flag (CTF)-style vs. Traditional Exercises in an Introductory Computer Security Class,16,N/A,https://www.semanticscholar.org/paper/0ea25bb318bac244605687955cc1f51cc135dcf8,Stephen V. Cole,"The importance of possessing hands-on skills in addition to theoretical knowledge for cybersecurity researchers and professionals cannot be overstated. Computer security educators have therefore adopted various types of hands-on exercises in their classes, from traditional ones characterized by linear instructions and progress snapshots to full-scale Capture The Flag (CTF) challenges characterized by an underspecified solution path and a tangible token of success. Educators implementing CTF exercises have reported, often informally, that the exercises increase student motivation and/or engagement without harming learning outcomes relative to traditional exercises. In this work, we systematically compare exercises imbued with the essential characteristics of CTFs to traditional exercises in terms of student experience and learning outcomes in an undergraduate Introduction to Computer Security class. Quantitative and qualitative analyses of post-assignment surveys suggest that CTF-style exercises yielded significantly higher student motivation, and analysis of scores on exam questions relevant to each type of exercise showed no significant difference between exercise types. Our work agrees with previous studies showing the effectiveness of CTF-style exercises in increasing student motivation at no cost to objective learning outcomes, and helps establish the pedagogical validity of employing CTF-style exercises in an introductory computer security class."
Security (cs.CR),2022,4,Proceedings of the 38th Annual Computer Security Applications Conference,13,N/A,https://www.semanticscholar.org/paper/0a37466583e03f905f6c9969ed6c664aec1dd8a8,Unknown,No Abstract
Security (cs.CR),2022,14,Knowledge Management Strategy for Handling Cyber Attacks in E-Commerce with Computer Security Incident Response Team (CSIRT),8,N/A,https://www.semanticscholar.org/paper/aec5119aac77a390320f6644c413d9b9ea33b000,"Fauziyah Fauziyah, Zhao Wang, Gabriel Joy",No Abstract
Security (cs.CR),2022,15,A Capture The Flag (CTF) Platform and Exercises for an Intro to Computer Security Class,8,N/A,https://www.semanticscholar.org/paper/50901d26b0076085edd6805a1e377e5661edb9bf,"Zack Kaplan, Ning Zhang, Stephen V. Cole","Cybersecurity education is becoming increasingly important as demand for cybersecurity professionals increases. Hands-on skills are a critical component of cybersecurity education, and a variety of exercise types have been developed to teach these skills. In this work, we seek to apply the benefits of gamified learning to an introductory cybersecurity curriculum in the form of a set of Capture the Flag (CTF) challenges offered as hands-on exercises for an intro-level course. We created 20 jeopardy-style challenges of varying difficulty based on prior research on the use of gamification in education, and we configured the open-source CTFd platform to host our challenges. Student responses to post-challenge surveys suggest that the CTF component of the course was effective in improving perceived learning and student engagement."
Security (cs.CR),2022,5,Design and Testing of a Computer Security Layer for the LIN Bus,5,N/A,https://www.semanticscholar.org/paper/e431c56942e9c7351f4439226145d63507e5d2e4,"Felipe Páez, Héctor Kaschel","Most modern vehicles are connected to the internet via cellular networks for navigation, assistance, etc. via their onboard computer, which can also provide onboard Wi-Fi and Bluetooth services. The main in-vehicle communication buses (CAN, LIN, FlexRay) converge at the vehicle’s onboard computer and offer no computer security features to protect the communication between nodes, thus being highly vulnerable to local and remote cyberattacks which target the onboard computer and/or the vehicle’s electronic control units through the aforementioned buses. To date, several computer security proposals for CAN and FlexRay buses have been published; a formal computer security proposal for the LIN bus communications has not been presented. So, we researched possible security mechanisms suitable for this bus’s particularities, tested those mechanisms in microcontroller and PSoC hardware, and developed a prototype LIN network using PSoC nodes programmed with computer security features. This work presents a novel combination of encryption and a hash-based message authentication code (HMAC) scheme with replay attack rejection for the LIN communications. The obtained results are promising and show the feasibility of the implementation of an LIN network with real-time computer security protection."
Security (cs.CR),2022,7,The position of the Computer Security Incidents Response Teams in the national cybersecurity system,4,N/A,https://www.semanticscholar.org/paper/f9507a2551b74cf09a4fb46322a96d4025e4e33d,J. Kostrubiec,"The purpose of the Computer Security Incident Response Teams is to ensure a coherent and complete system of risk management at the national level and, therefore, they have been obliged to perform tasks to counter cybersecurity threats of cross-sectoral and cross-border nature, as well as to ensure coordination of handling of reported incidents, i.e. events that have or may harm cybersecurity."
Security (cs.CR),2022,6,Application Research of Data Encryption Algorithm in Computer Security Management,3,N/A,https://www.semanticscholar.org/paper/68d2bfeb7526a9380aaa8e6ff7fa08d47957a831,Qianru Gong,"In order to promote the research process of information security in the whole society, improve the safety factor of computer data communication, strengthen computer security management, the author proposes a computer data encryption strategy that combines the strong security of the 3DES encryption algorithm and the asymmetric encryption advantages of the RSA algorithm. Through the detailed analysis of DES encryption algorithm and 3DES encryption, creatively uses the RSA encryption algorithm to improve the single 3DES algorithm, consolidates the performance of the 3DES encryption algorithm to ensure data communication, and ensures the data integrity, better improve encryption performance. Experiments show that: The proposed encryption algorithm improves security performance by 10 times, and the response efficiency is only 1 ms away from other algorithms, compared with other algorithms, it has better encryption performance and is suitable for actual computer data communication scenarios. Conclusion: The encryption algorithm proposed by the author has achieved good results in terms of security performance and response efficiency, it is suitable for actual computer data security communication and can effectively improve computer security management."
Security (cs.CR),2022,8,Computer Security Issues and Legal System Based on Cloud Computing,3,N/A,https://www.semanticscholar.org/paper/a2a6fb9d7f89ddea35bfaea8a429282a6d4af8d3,Hui Li,"To effectively improve the security and accuracy of computer information storage, a computer security problem and legal system based on cloud computing are proposed. Firstly, this article details the evolution of cloud computing, its characteristics, architecture, and application status of cloud computing in detail. Second, we discussed security strategies to ensure the confidentiality and integrity of cloud computing information, focuses on the data encryption technology of cloud data security, and designs and implements the data backup and recovery system based on the cloud platform. The core layers of the system are the system layer and data operation layer. The system uses multithreading technology based on epoll and thread pool to improve the efficiency of data transmission. At the same time, the basic visual page is realized, and users can use the page to create a convenient operating system. Finally, the system is built in the laboratory environment and tested as a whole. The test results show that through the performance comparison with the current commonly used systems, it is found that the system in this paper has a certain improvement in data transmission rate, but the utilization rate of node CPU is as high as 40%, which leads to certain requirements for node CPU performance. Therefore, the system meets the functional requirements proposed in the design. Compared to the existing system, its performance has been found to meet the actual requirements of use, proving that the system is accessible and efficient."
Security (cs.CR),2022,9,Topic Modelling in Computer Security Discourse: a Case Study of Whitepaper Publications and News Feeds,2,N/A,https://www.semanticscholar.org/paper/0ffe2e0f721e8a0a739aa51978b03583cc122376,Ekaterina Isaeva,"Up-to-date information plays a crucial role in modern linguistic research. For this reason,computational linguistic methods, including those aided with analytical and machine-learning tools, are attracting growing attention. Some of their applications in cognitive-discursive linguistics are keyword extraction, topic modelling, and content analysis. Text-mining tools facilitate time-consuming linguistic work andadd to the results’ reliability and greater statistical precision by processing a significantly larger data volume.Most studies, however, have overlooked interference of socially significant but context-irrelevant (e.g. political) information into a specialized discourse by focusing mainly on one data format. The current study,aimed at topic modelling, has been carried out on the computer security discourse. We have implemented theproject on the KNIME analytical platform. The model enables comparison between topics extracted frompublished articles and date-specific RSS news feeds. The study provides important insights into infodemiology and political incidental news exposure occurring in computer-security-oriented RSS feeds on theKaspersky website but untraceable in the papers published on the same website in a PDF format. The resultsreported here provide further evidence for the need to consider the hypercontext of professional communication and employ real-time data in solving similar problems within cognitive-discursive linguistics.Our contribution to the development of cognitive-discursive linguistics is the method for comparingtopics within one discourse, taking into account near-real-time data. For computational linguistics, the significance of our work lies in describing a new application of the topic extraction workflow freely available onthe KNIME hub."
Security (cs.CR),2022,10,Proposed Empirical Assessment of Remote Workers' Cyberslacking and Computer Security Posture to Assess Organizational Cybersecurity Risks,2,N/A,https://www.semanticscholar.org/paper/a93acdbdb2ee61ee28dde7fe01ef6458ec5965f5,"Ariel Luna, Y. Levy, G. Simco et al.","Cyberslacking is conducted by employees who are using their companies' equipment and network for personal purposes instead of working during work hours. Cyberslacking has a significant adverse effect on overall employee productivity., however, recently, due to COVID19 move to remote working also pose a cybersecurity risk to organizations networks and infrastructure. In this work-in-progress research study, we are developing, validating, and will empirically test a taxonomy to assess an organization's remote workers” risk level of cybersecurity threats. This study includes a three-phased developmental approach in developing the Remote Worker Cyberslacking Security Risk Taxonomy. In collaboration with cybersecurity Subject Matter Experts (SMEs) use the taxonomy to assess organization's remote workers” risk level of cybersecurity threats by using actual system indicators of productivity measures to estimate their cyberslacking along with assessing via organizational information the computer security posture of the remote device being used to access corporate resources. Anticipated results from 125 anonymous employees from one organization will then be assessed on the cybersecurity risk taxonomy where recommendation to the organization's cybersecurity leadership will be provided."
Security (cs.CR),2022,16,"Advances in Information and Computer Security: 17th International Workshop on Security, IWSEC 2022, Tokyo, Japan, August 31 – September 2, 2022, Proceedings",2,N/A,https://www.semanticscholar.org/paper/4e84af4f7e1d89fbeae8f85eabf9816ac6709075,Unknown,No Abstract
Security (cs.CR),2022,17,"Computer Security – ESORICS 2022: 27th European Symposium on Research in Computer Security, Copenhagen, Denmark, September 26–30, 2022, Proceedings, Part III",2,N/A,https://www.semanticscholar.org/paper/f6f3d5ebc498bd8411cf90ca5deecb61edc3150e,Unknown,No Abstract
Security (cs.CR),2022,11,Computer security incident response teams: are they legally regulated? The Swiss example,1,N/A,https://www.semanticscholar.org/paper/2a0fa099674b80732fd9330394b8f94f6f12dc61,"Paul Meyer, Sylvain Métille","Computer Security Incident Response Teams (CSIRTs) or Computer Emergency Response Teams (CERTs) are an integral part of incident handling capabilities and are increasingly demanded by organizations such as critical infrastructures. They can hold many different skills and are of great interest to organizations in terms of cyber security and, more concretely, cyber incident management. This contribution seeks to analyze the extent to which their activity is regulated under Swiss law, considering that private CSIRTs are not regulated in the same way as governmental and national CSIRTs such as the Computer Emergency Response Team of the Swiss government and official national CERT of Switzerland (GovCERT)."
Security (cs.CR),2022,12,Home Computer Security,1,N/A,https://www.semanticscholar.org/paper/0a609e2aff0236788613146a216d5499f8683759,"E. B. Markelova, G. Popkov","Our life is firmly connected with information technologies: messengers, social networks, online stores - we use all these means of communication and communication on a daily basis. That is why information security plays an important role. Taking into account the rapid development of information technologies, it is becoming increasingly difficult to protect information, which is why the need to protect a computer from unauthorized access, theft of confidential information, exposure to malware is a priority in the field of computer technology and information security. This article presents the main threats to the security of a home computer, presents the results of a comparative analysis of ways to protect a home computer from virus, spyware, hacker, advertising and spam attacks, as well as from unauthorized access to information stored on a personal computer."
Security (cs.CR),2022,18,"Computer Security – ESORICS 2022: 27th European Symposium on Research in Computer Security, Copenhagen, Denmark, September 26–30, 2022, Proceedings, Part I",1,N/A,https://www.semanticscholar.org/paper/f69dd4f58baa26fc2182389a79e0a8ebc23ed9b1,Unknown,No Abstract
Security (cs.CR),2022,20,Computer Security,1,N/A,https://www.semanticscholar.org/paper/fdc731939f0391876c252ca190555813af5373e7,Frans Kaashoek,No Abstract
Security (cs.CR),2022,13,Crimes against computer security,0,N/A,https://www.semanticscholar.org/paper/357f788a6864b683d89647eb9f48bc6b5c4a0e8d,"И.Ш. Арсакаев, Г.С. Султанов, М.А. Манцаева","В статье описываются основы компьютерной безопасности, в частности, формы вирусов, методы проникновения и меры защиты от них, их основным классом является концепция безопасности компьютеров с учетом соответствующих нормативных актов.  The article describes the basics of computer security, in particular, the forms of viruses, methods of penetration and measures of protection against them, their main class is the concept of computer security, taking into account the relevant regulations."
Security (cs.CR),2022,19,A Discussion on Computer Security Technology and Security Preventive Measures,0,N/A,https://www.semanticscholar.org/paper/2e5ffb954619cf89f8ffd43a2cf7583761f64d0a,"Zhongdong Wang, Liuqiang Wu, Liangjing Zhang","Along with the development of the Internet, the network plays an increasingly important role in people's work and life. Moreover, the increasing popularity of smart devices has prompted people to get used to storing various information and data on mobile phones, tablets, computers, clouds and other network media or devices. Nevertheless, the security problem of network information is still serious, and economic losses caused by information theft due to illegal network intrusion are common. Therefore, in this paper, based on the research of computer network security protection technology and consulting a large amount of data, firstly the security problems existing in computer network were discussed, then the importance of computer network security protection technology in computer network operation was expounded, and next the design scheme of computer network security protection system and computer network security protection strategies were put forward, providing theoretical reference for further application of computer network security protection technology."
Security (cs.CR),2023,3,LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?,71,2307.10719,https://www.semanticscholar.org/paper/139a0c7a60667979dcb57eae677f75ff3f0b0196,"David Glukhov, Ilia Shumailov, Y. Gal et al.","Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated; it should be treated as a security problem which warrants the adaptation of security-based approaches to mitigate potential risks."
Security (cs.CR),2023,1,Ethical Frameworks and Computer Security Trolley Problems: Foundations for Conversations,44,2302.14326,https://www.semanticscholar.org/paper/15deb60e1002cb1b5364354257fdba6a5c3c3247,"Tadayoshi Kohno, Y. Acar, Wulf Loh","The computer security research community regularly tackles ethical questions. The field of ethics / moral philosophy has for centuries considered what it means to be""morally good""or at least""morally allowed / acceptable"". Among philosophy's contributions are (1) frameworks for evaluating the morality of actions -- including the well-established consequentialist and deontological frameworks -- and (2) scenarios (like trolley problems) featuring moral dilemmas that can facilitate discussion about and intellectual inquiry into different perspectives on moral reasoning and decision-making. In a classic trolley problem, consequentialist and deontological analyses may render different opinions. In this research, we explicitly make and explore connections between moral questions in computer security research and ethics / moral philosophy through the creation and analysis of trolley problem-like computer security-themed moral dilemmas and, in doing so, we seek to contribute to conversations among security researchers about the morality of security research-related decisions. We explicitly do not seek to define what is morally right or wrong, nor do we argue for one framework over another. Indeed, the consequentialist and deontological frameworks that we center, in addition to coming to different conclusions for our scenarios, have significant limitations. Instead, by offering our scenarios and by comparing two different approaches to ethics, we strive to contribute to how the computer security research field considers and converses about ethical questions, especially when there are different perspectives on what is morally right or acceptable."
Security (cs.CR),2023,2,SecQA: A Concise Question-Answering Dataset for Evaluating Large Language Models in Computer Security,41,2312.15838,https://www.semanticscholar.org/paper/7d010e1e92ff696434e6bb0a3bbaa15d9f8683e5,Zefang Liu,"In this paper, we introduce SecQA, a novel dataset tailored for evaluating the performance of Large Language Models (LLMs) in the domain of computer security. Utilizing multiple-choice questions generated by GPT-4 based on the""Computer Systems Security: Planning for Success""textbook, SecQA aims to assess LLMs' understanding and application of security principles. We detail the structure and intent of SecQA, which includes two versions of increasing complexity, to provide a concise evaluation across various difficulty levels. Additionally, we present an extensive evaluation of prominent LLMs, including GPT-3.5-Turbo, GPT-4, Llama-2, Vicuna, Mistral, and Zephyr models, using both 0-shot and 5-shot learning settings. Our results, encapsulated in the SecQA v1 and v2 datasets, highlight the varying capabilities and limitations of these models in the computer security context. This study not only offers insights into the current state of LLMs in understanding security-related content but also establishes SecQA as a benchmark for future advancements in this critical research area."
Security (cs.CR),2023,4,Skilled or Gullibleƒ Gender Stereotypes Related to Computer Security and Privacy,13,N/A,https://www.semanticscholar.org/paper/5d5d037dd687f45f13e2fc4f044f187ad469afc3,"Miranda Wei, Pardis Emami Naeini, Franziska Roesner et al.","Gender stereotypes remain common in U.S. society and harm people of all genders. Focusing on binary genders (women and men) as a first investigation, we empirically study gender stereotypes related to computer security and privacy. We used Prolific to conduct two surveys with U.S. participants that aimed to: (1) surface potential gender stereotypes related to security and privacy (N = 202), and (2) assess belief in gender stereotypes about security and privacy engagement, personal characteristics, and behaviors (N = 190). We find that stereotype beliefs are significantly correlated with participants’ gender as well as level of sexism, and we delve into the justifications our participants offered for their beliefs. Beyond scientifically studying the existence and prevalence of such stereotypes, we describe potential implications, including biasing crowdworker-faciliated user research. Further, our work lays a foundation for deeper investigations of the impacts of stereotypes in computer security and privacy, as well as stereotypes across the whole gender and identity spectrum."
Security (cs.CR),2023,19,Power in Computer Security and Privacy: A Critical Lens,8,N/A,https://www.semanticscholar.org/paper/b1beccff30972c6d133e361cb0f8df4676463b64,"Elissa M. Redmiles, M. Bennett, Tadayoshi Kohno",No Abstract
Security (cs.CR),2023,5,Large Language Models and Computer Security,7,N/A,https://www.semanticscholar.org/paper/60a6c0800753d05094ebac1169532081b4b52406,"Arun Iyengar, Ashish Kundu","Large language models (LLMs) are having a significant impact in many different fields. Security and privacy issues related to LLMs are of paramount importance. LLMs can be used to defend against cyberattacks and thwart attackers. LLMs can enhance computer security in several ways including identifying phishing attacks, identifying malware, analyzing incident reports from security breaches, determining vulnerability to attacks, analzying log information, and providing valuable information, education, and training materials. However, large language models can also be used by malicious parties to enhance cyberattacks. This paper looks at how LLMs can be used by both defenders and attackers. We also examine attacks on large language models which have been deployed to cause LLMs to output harmful information."
Security (cs.CR),2023,16,Evaluating Docker Container Security through Penetration Testing: A Smart Computer Security,7,N/A,https://www.semanticscholar.org/paper/bd82b69ab95dab9387e45057d287e2eefdd03f2c,"Drake Mubanda, Ngaira Mandela, Tumaini Mbinda et al.","The widespread adoption of containerization, exemplified by Docker, has transformed software deployment, enabling agile applications. However, its popularity invites malicious exploits, heightening security incidents in containerized environments. This paper details a comprehensive penetration testing approach for Docker container security, spotlighting file system vulnerabilities and artifacts. Using penetration testing methodologies, the study systematically scrutinizes Docker container file systems. Detection of Common Vulnerabilities and Exposures (CVEs) and Common Exploit Weaknesses (CEWs) within the file system identifies potential attacker entry points. The paper also delves into artifact extraction from the file system, encompassing logs, configurations, and command traces. These artifacts unveil the container's activities, shedding light on potential intrusion vectors. Examination of container metadata and configurations uncovers misconfigurations and potential attack surfaces. By Exploration of file system vulnerabilities and artifacts equips security practitioners with crucial insights for bolstering Docker container defense."
Security (cs.CR),2023,6,Lessons Learned on Machine Learning for Computer Security,6,N/A,https://www.semanticscholar.org/paper/c9e0f5f518d3d8083c5105d8dd75dc1d790cc3fb,"Daniel Arp, Erwin Quiring, Feargus Pendlebury et al.",We identify 10 generic pitfalls that can affect the experimental outcome of AI driven solutions in computer security. We find that they are prevalent in the literature and provide recommendations for overcoming them in the future.
Security (cs.CR),2023,7,The Effectiveness of the Port Knocking Method in Computer Security,3,N/A,https://www.semanticscholar.org/paper/8c9222c36dbb28cec90a539cdc0fecc91f1ea805,"Muhammad Nur, Teguh, Wasis Waskito et al.","Computer network is a group of autonomous computers that are interconnected with each other using communication protocols through communication media so that they can share information, programs, share hardware devices such as printers, hard disks, and so on. One of the most important network components is network security, computer security involves various aspects, including protection against unauthorized access, data theft, system tampering, and operational disruptions. This research method uses descriptive method. At this stage specifications are determined regarding the system that will be designed to meet the objectives of this study, the Port Knocking method to secure the Router can be applied to Mikrotik routers by utilizing a firewall which functions to guard against illegal access and overcome problems caused by Attackers"
Security (cs.CR),2023,17,Protecting A Nuclear Power Plant Against A Stuxnet Attack: Power Of Computer Security,3,N/A,https://www.semanticscholar.org/paper/d78bcbe27e7a72c84139aaca47ee2a05725e5d64,"Nachiket Thapliyal, Sumit Dhariwal","In the modern world, cyber-attacks have become a major concern for critical infrastructures such as nuclear power plants. The Stuxnet attack of 2010 demonstrated the potential for a cyber-attack to cause physical damage to a nuclear power plant, making the protection of these facilities against such threats a critical priority. This paper provides a comprehensive review of the measures that can be taken to prevent a Stuxnet-like attack on a nuclear power plant. The review covers both technical and non-technical measures such as network segmentation, software patching and updating, and the implementation of effective security policies and procedures. It is important to implement a multi-layered defence system that addresses the technical, operational and organizational aspects of security, and the need for continued vigilance and improvement in the face of evolving cyber threats."
Security (cs.CR),2023,8,Keylogger Threats in Computer Security Aspects,2,N/A,https://www.semanticscholar.org/paper/200ff6af43871256dbbf4cf0541bfee72df06df6,"Samsoni, Ditonius Zebua, Basir et al.","Along with the development of increasingly advanced technology, the level of need for information security is very important. With the development of information, new problems arise regarding computer security, an example of computer security that often occurs is data theft. Data security in accessing a computer is a form that must be considered both physically and non-physically. One form of data theft crime is recording traces of a computer keyboard with the help of hardware or software. Keylogger is a data theft technique by recording typing on a computer keyboard, by recording when the computer is entered, intruders can enter and steal it. The purpose of this paper is to understand how keyloggers work so that prevention can be carried out by carrying out various kinds of solutions and also to maintain data security systems and know supporting and anti-keylogger software"
Security (cs.CR),2023,9,Eksplorasi Implementasi Kebijakan Pembentukan Computer Security Incident Response Team (Csirt) di Kementerian Perdagangan: Sebuah Studi Kualitatif,1,N/A,https://www.semanticscholar.org/paper/9daee76d34ab09cf706f132c63b27a6db81581f3,"Ana Najiyya, Stepani Sisca Wulandari"," Computer Security Incident Response Team (CSIRT) Kementerian Perdagangan adalah tim tanggap insiden siber yang dibentuk berdasarkan Peraturan BSSN No. 10/2020 tentang Tim Tanggap Insiden Siber. Tujuan dibentuknya tim ini yaitu untuk dapat memastikan bahwa sistem elektronik dan layanan publik telah berjalan dengan baik dan aman dari serangan siber. Sehingga penelitian ini bertujuan untuk mengkaji pelaksanaan kebijakan BSSN di Kementerian Perdagangan terkait pembentukan CSIRT berdasarkan Peraturan BSSN No. 10 Tahun 2020 berdasarkan implementasinya dengan menggunakan metode kualitatif melalui pendekatan deskriptif eksploratif. Hasil penelitian menunjukkan bahwa pelaksanaan CSIRT saat ini belum optimal dan tersendat oleh beberapa kendala, seperti struktur pengambilan keputusan yang birokratis, keterbatasan sumber daya manusia, dan lemahnya kewenangan unit PDSI. Untuk mengatasi kendala-kendala tersebut, diperlukan peningkatan struktur pengambilan keputusan, peningkatan jumlah dan kompetensi SDM, serta penerapan teknologi big data yang lebih efektif dan efisien dalam mengelola keamanan siber."
Security (cs.CR),2023,10,Teaching Computer Security in a Secondary School,1,N/A,https://www.semanticscholar.org/paper/4d44d51b05e75cf69f15193df38a4ae2ad5270e2,J. Mottl,"The article focuses on computer security, especially on the teaching of this topic in secondary schools. From the broad topic of security, the article focuses mainly on authorization and authentication and the related tools used for these processes in web development. The main objective of the paper is to determine the extent of education on these topics in secondary schools. The paper provides an insight into the issue by means of a questionnaire survey conducted in a secondary vocational school with a focus on computer science. The results of this survey were compared with the results of the same questionnaire given to students of the Bachelor’s degree programme in Applied Informatics at the Faculty of Informatics and Management at the University of Hradec Kralove. The paper summarizes the results of the analysis of these questionnaires and provides insight into the importance of teaching computer security in secondary schools."
Security (cs.CR),2023,11,Visual Analysis of Computer Security Data Using Artificial Neural Networks,1,N/A,https://www.semanticscholar.org/paper/9d14e005a6974ead0940178a43e800f4cacb4e79,"Ksenia Zhernova, A. Chechulin","Artificial neural networks are used in various fields of human activity, including information and computer security, for example, in biometric systems such as face and fingerprint recognition. However, in the field of visual analysis of security incident data, it is assumed that the visualization is intended for the human operator since the person makes the final decision. This paper investigates whether computer vision systems can perform the tasks of a human operator during visual data analysis. To study the question posed, the paper proposes a model architecture for classifying visualizations of traffic with anomalies and normal traffic. Experiments were also carried out using a neural network and involving subjects. Experiments show that a trained neural network can recognize anomalies in images with visualization of security events and, in some cases, even better than a human."
Security (cs.CR),2023,12,VLSI Design and Test View of Computer Security,1,N/A,https://www.semanticscholar.org/paper/706c54ddf60a4d97dd284b723518b5016802f087,Shih-Lien Lu,"Computer security is becoming more and more important as more aspects of our life rely on information technology. The fundamental building block of information technology is semiconductor. Semiconductor enables Very Large-Scale Integrated (VLSI) Circuits which power the digital infrastructure. This presentation examines the challenges and opportunities of security from the point of view of VLSI design and technology. We first explain why security in general and hardware security in particular is challenging. We present a survey of different aspects of hardware security. We argue more work needs to be done in building the components to enhance hardware security. Moreover, we look at how design considerations of these components need to be different from regular design. As an example, we will take a deeper dive into Physically Unclonable Functions (PUF). PUF have been gaining attention since early 2000s and are now an established secure alternative to other key storage methods for many integrated circuits (ICs) such as FPGAs and microcontrollers. There are many works on the design of PUFs. However, the merits of a particular PUF should go beyond the normal Power-Performance-Area (PPA) of a standard digital integrated circuit. This is because the security primitive only occupies a very small portion of the whole chip. Improving a PUF design by some percentage makes little impact on the PPA of the whole chip. As a security primitive, it should be evaluated also on what its designated functionality as well. We summarize some of the evaluation criteria important for PUF. We also discuss some experience we had with challenges of SRAM based PUF."
Security (cs.CR),2023,18,Use of Blockchain Technology in Electronic Voting Systems: An Overview from Computer Security,1,N/A,https://www.semanticscholar.org/paper/3c0ba3131b57c3ae399f703d414dd1df49135815,"Parvez Rahi, Ajay Pal Singh, Parveen Badoni et al.","Block chain is a new and growing technology in the IT world right now. This technology is a way to store data that is not based in one place. It gives centralized data storage systems an alternative that is safer from a security point of view. This paper gives an idea of how Block-chain Technology can be used to protect an e-voting system. In this paper, we looked at all the work that has been done in the same area before. We chose a number of research papers in the same field and looked at them. From what we can tell from these papers, using Block-chain Technology for voting will be very useful. And this system for voting online will be much safer than the one we have now. Electronic voting, or E-voting, is simply the use of computers to cast and count votes. This method makes the voting process faster and cheaper. When more technology is used in a certain area, security problems also get worse. When you vote online, security is important. By using the Block chain and its distributed database system, we can make it harder for people with bad intentions to change the database. This makes the e- voting system more secure."
Security (cs.CR),2023,13,Computer Security Algorithm Based on Convolutional Neural Network,0,N/A,https://www.semanticscholar.org/paper/c4975faec71331fbcff1c9509a7ea427ddcc7729,"Jun Yin, Bizhou He, Jianye Zhang","Computer security is a global issue, and it has always been the focus of attention of all countries on a global scale. Neural network is a new subject, which is widely used in the computer field. In the Internet information age, the number of computer users is increasing rapidly, and network security risks are increasing. How to apply various technologies to solve safety problems in a complex and changeable environment is the focus of research. This article mainly conducts research on the comparison of computer security related technologies through experimental methods and comparison methods. The experimental results show that the safety performance of the two times two out of two secure computer system is the highest, and the error time is ultimately within 1 to 2 seconds. The use of convolutional neural networks is effective and fast for computer security calculations."
Security (cs.CR),2023,14,Application of Computer Security Management in Internet Finance,0,N/A,https://www.semanticscholar.org/paper/d4e846dc03b23cd2de960b365166dad89fd64991,Zhibin Yu,"Internet finance is based on more advanced and mature computer security management technology. On the way of its development, it should continue to strengthen the optimization and upgrading of computer security, improve the quality of financial services, reduce the cost of financial services, avoid the risks of financial services, and further expand the scope of Internet finance services. This paper preliminarily explores the application of computer security technology in the network system, plays a certain reference role in the development of computer security management technology in the network, analyzes some problems in the current financial technology risks, and then discusses the role of computer security management in the interconnected finance. The research will help us to better prevent the risks of financial technology, and the exhibition is for reference. According to the data, it can be seen that when the equivalent reaches 0.2, the risk reaches 0.4, 0.6.0.8 respectively, and when the maximum value reaches 0.8, the risk value is 0.2, 0.3 and 0.8 respectively, which shows that there is still a great risk in Internet finance."
Security (cs.CR),2023,15,Sniffing and Spoofing in Computer Security,0,N/A,https://www.semanticscholar.org/paper/cec8f64a0dfccc87b70cb650162edb1f9eeb578d,"Saddam RA, Angga Pranata, Sugiono et al.","The development of Information Technology (IT) has changed people's mindset. The presence of the Internet as the main platform for online activity is vulnerable to criminal acts by irresponsible parties. Criminal acts in cyberspace, of course, pose a major threat to the governance of online activities. One of these major threats is the threat of network security. Networks connected to the internet are basically insecure and can always be exploited by hackers, both LAN and wireless networks. The internet network has two data transmission media, namely wired and wireless. what happens is open. Examples of network security threats that often occur are sniffing of activities on the network (sniffing) and also impersonation by other people (spoofing). This resume article aims to identify criminal acts that threaten computer security, namely Sniffing and Spoofing"
Security (cs.CR),2023,20,2023 IEEE 36th Computer Security Foundations Symposium,0,N/A,https://www.semanticscholar.org/paper/285ee078521f7de978fefcfe49681f7c43711274,Unknown,No Abstract
Security (cs.CR),2024,1,Data Stewardship in Clinical Computer Security: Balancing Benefit and Burden in Participatory Systems,18,N/A,https://www.semanticscholar.org/paper/d5e1211b4e6ae894596784b34342bf33b2e8f074,"Emily Tseng, Rosanna Bellini, Yeuk-Yu Lee et al.","The mass collection and reuse of social data requires a reimagining of privacy and consent, with particular attention to the (in)equitable distribution of benefits and burdens between researchers and subjects. Instrumenting frontline clinical services to collect and steward data might mitigate the exploitation inherent to data collection---with attention to how subjects can meaningfully participate in stewardship. We explore participatory data stewardship in the context of clinical computer security for survivors of intimate partner violence (IPV). Via semi-structured interviews with IPV support workers, we explore how data are produced within the IPV care ecosystem at the Clinic to End Tech Abuse (CETA). We then conduct design provocations with clients of IPV services and their support workers, exploring possibilities for participatory data mechanisms like open records and dynamic consent. We find participation in data stewardship may benefit clients through improved agency, self-reflection, and control of self-narrative, and that incurred burdens may be alleviated by enlisting trusted stewards. We close with future work for CSCW interrogating how knowledge of digital-safety harms can and should be produced from clinical encounters, towards more equitable ways of knowing."
Security (cs.CR),2024,4,Computer security technology in E-commerce platform business model construction,10,N/A,https://www.semanticscholar.org/paper/709cf3220662e2a2548bd4c0c8fffc5825ec8cc2,"Xiuli Ma, Zehao Wang",No Abstract
Security (cs.CR),2024,2,SoK (or SoLK?): On the Quantitative Study of Sociodemographic Factors and Computer Security Behaviors,9,2404.10187,https://www.semanticscholar.org/paper/b4ac36c3ec567e4344a59082cd80013fb0cd4dce,"Miranda Wei, Jaron Mink, Yael Eiger et al.","Researchers are increasingly exploring how gender, culture, and other sociodemographic factors correlate with user computer security and privacy behaviors. To more holistically understand relationships between these factors and behaviors, we make two contributions. First, we broadly survey existing scholarship on sociodemographics and secure behavior (151 papers) before conducting a focused literature review of 47 papers to synthesize what is currently known and identify open questions for future research. Second, by incorporating contemporary social and critical theories, we establish guidelines for future studies of sociodemographic factors and security behaviors that address how to overcome common pitfalls. We present a case study to demonstrate our guidelines in action, at-scale, that conduct a measurement study of the relationships between sociodemographics and de-identified, aggregated log data of security and privacy behaviors among 16,829 users on Facebook across 16 countries. Through these contributions, we position our work as a systemization of a lack of knowledge (SoLK). Overall, we find contradictory results and vast unknowns about how identity shapes security behavior. Through our guidelines and discussion, we chart new directions to more deeply examine how and why sociodemographic factors affect security behaviors."
Security (cs.CR),2024,6,Triboelectric sensor-empowered intelligent mouse combined with machine learning technology strides toward a computer security system,9,N/A,https://www.semanticscholar.org/paper/b453fb271e050e8faf814e8d224dadf8b0c079d5,"Weiqiang Zhang, Xinming Liu, Xiaozhou Lü et al.",No Abstract
Security (cs.CR),2024,3,Pitfalls in Machine Learning for Computer Security,6,N/A,https://www.semanticscholar.org/paper/db80f8b0015ff20866cb0941823d171767e5c796,"Daniel Arp, Erwin Quiring, Feargus Pendlebury et al.","With the growing processing power of computing systems and the increasing availability of massive datasets, machine learning algorithms have led to major breakthroughs in many different areas. This development has influenced computer security, spawning a series of work on learning-based security systems, such as for malware detection, vulnerability discovery, and binary code analysis. Despite great potential, machine learning in security is prone to subtle pitfalls that undermine its performance and render learning-based systems potentially unsuitable for security tasks and practical deployment. In this paper, we look at this problem with critical eyes. First, we identify common pitfalls in the design, implementation, and evaluation of learning-based security systems. We conduct a study of 30 papers from top-tier security conferences within the past 10 years, confirming that these pitfalls are widespread in the current security literature. In an empirical analysis, we further demonstrate how individual pitfalls can lead to unrealistic performance and interpretations, obstructing the understanding of the security problem at hand. As a remedy, we propose actionable recommendations to support researchers in avoiding or mitigating the pitfalls where possible. Furthermore, we identify open problems when applying machine learning in security and provide directions for further research."
Security (cs.CR),2024,5,Navigating Traumatic Stress Reactions During Computer Security Interventions,4,N/A,https://www.semanticscholar.org/paper/607d096429cfd0fdc345d0e8eacfb0c2895b927e,"Lana Ramjit, Natalie Dolci, Francesca Rossi et al.",No Abstract
Security (cs.CR),2024,13,Enhancing Computer Security through Formal Verification of Cryptographic Protocols Using Model Checking and Partial Order Techniques,2,N/A,https://www.semanticscholar.org/paper/9c7123c62edf2d29f9008efebc56aa1315ff94a1,"Mahlaqa Saeed, Muhammad Ibrar, Dua Mahmood et al.","This study explores the integration of partial, order reduction techniques with model checking to enhance the verification of cryptographic protocols. Cryptographic, protocols are essential for securing digital communications, and data; however, ensuring their robustness and reliability through traditional verification methods can be challenging due to, their complexity and the vast number of potential executions, paths. This research utilizes the SPIN, model checker and PROMELA language to model and verify three types of, cryptographic protocols: a basic authentication handshake, an encrypted data transfer, protocol, and a complex, multi-factor authentication process. Each protocol was, verified with and, without the application of partial order reduction techniques. The findings demonstrate that partial order, reduction, not only significantly reduces the computational resources, required—by approximately 40%—but also maintains the thoroughness needed to identify critical, security flaws such as replay, attacks, data integrity breaches, and authentication failures. This study, underscores the, efficacy of combining partial order reduction with model, checking, proposing that this, approach significantly improves the scalability and efficiency, of cryptographic protocol, verification. The results advocate, for the continued development and application of these, techniques to ensure the secure and reliable deployment of cryptographic protocols in various digital environments"
Security (cs.CR),2024,15,Comparative study of computer security methodologies for countering cyber attacks,2,N/A,https://www.semanticscholar.org/paper/65a68b816bca902e0a3237d0b3dac4ab6b090d11,"Francisco Manuel Hilario Falcón, Milner David Liendo Arévalo, Giancarlo Sanchez Atuncar et al.",No Abstract
Security (cs.CR),2024,16,Transforming Computer Security and Public Trust Through the Exploration of Fine-Tuning Large Language Models,2,2406.00628,https://www.semanticscholar.org/paper/a379aa7c4a51f0068c485ca78b168263ea850c9f,"Garrett Crumrine, I. Alsmadi, Jesus Guerrero et al.","Large language models (LLMs) have achieved groundbreaking advancements in natural language processing (NLP) that hold the promise of revolutionizing the relationship between humans and technology. However, this technological advancement has been joined by the emergence of “Mallas” (a term coined by Lin et al. [4]). These services facilitate the creation of malware, phishing attacks, deceptive websites, and most concerning, exploit code. This paper delves into the proliferation of Mallas by examining the use of various pretrained language models and their efficiency at generating vulnerabilities and exploits when being misused. Leveraging a comprehensive dataset from the Common Vulnerabilities and Exposures (CVE) program, it explores dataset creation, prompt engineering and fine-tuning methodologies needed to generate code and explanatory text related to vulnerabilities identified in the CVE database. Furthermore, this research aims to shed light on the strategies and exploitation techniques of Mallas; ultimately assisting the development of more secure and trustworthy AI applications. The paper concludes by emphasizing the critical need for further research into LLM-related cyber threat intelligence and advocating for the development of enhanced safeguards and ethical guidelines to mitigate the risks associated with these malicious applications of LLMs. We propose a novel Dynamic Ethical Boundary Reinforcement (DEBR) system as a proactive measure against LLM exploitation."
Security (cs.CR),2024,14,"Computer Security – ESORICS 2023: 28th European Symposium on Research in Computer Security, The Hague, The Netherlands, September 25–29, 2023, Proceedings, Part I",1,N/A,https://www.semanticscholar.org/paper/0854de0f29f46d064a89ef66d5d92432fa47a8c1,Unknown,No Abstract
Security (cs.CR),2024,7,Cryptography and Computer Security: A View From the Year 2100,0,N/A,https://www.semanticscholar.org/paper/7a68cbc789c01b799cc2269bafb10921e0be7696,D. Boneh,"What will computer security look like in the year 2100? This talk will begin with a few predictions that aim to suggest a few research directions in the present. We will then transition to the exciting area of applied zero knowledge proofs, an area that has seen tremendous growth in recent years. We will describe some of the new ideas in the space and focus on a number of remarkable real-word applications of these techniques. The talk will be self contained and accessible to all."
Security (cs.CR),2024,8,APPLICATION OF COMPUTER SECURITY TECHNOLOGIES IN CORPORATE E-COMMERCE,0,N/A,https://www.semanticscholar.org/paper/db53e0a96f0eadf2edf648909bb01803e12828ed,"Alu A. Taramov, Aidar I. Vagapov, Ilyas A. Dzhabrailov","In the modern development of the economy, e-commerce has become an important component under the influence of electronic information technologies and the Internet. Moreover, consumption through online platforms has become a relatively common method of consumption among the country’s citizens. Due to the strong information interactivity, pricing, warehousing and other advantages that are gradually emerging, e-commerce plays an important role in meeting current social consumption. It was with the rapid development of e-commerce that a series of technical computer security problems followed one after another. How to ensure computer security technology in the development of a fast, efficient and secure e-commerce model has become an urgent problem. This article examines the state of e-commerce development and, by studying and analyzing the main technical security risks that exist in e-commerce, he will further carry out a comprehensive and effective optimization development in order to better contribute."
Security (cs.CR),2024,9,Competencies in Computer Security and Resolution of Technological Problems in Higher Education Students,0,N/A,https://www.semanticscholar.org/paper/c161d4c01a3de7929ea3f8f00c38ab766741c079,"Esteban Pérez Flores, Alejandra Aldrette Malacara, Sandra R. Murillo Cano et al.","Starting from the importance of preserving our information and protecting our devices against attacks on their vulnerabilities, this article aims to establish the level of knowledge in computer security and problem-solving of students at a university in northwest Mexico. This research has a quantitative approach where the European Framework of Digital Competencies for Citi-zenship was used as a reference to identify and establish the level of the competencies that were evaluated. The IKANOS Test was used as a data collection tool. The results show that students know the importance of keeping their devices safe and how valuable the information found on them is. On the other hand, the results also show a considerable percentage of students who do not have the knowledge and are at a basic level of knowledge to solve technical problems with their devices."
Security (cs.CR),2024,10,Factors Influencing Gen Z Awareness of Computer Security Using Protection Motivation Theory (PMT),0,N/A,https://www.semanticscholar.org/paper/43df281a7baed0b35c6edb0836c10d6ccc65eb84,"Rahma Sahwahita, R. G. Utomo","This study aims to analyze the factors that influence Generation Z’s awareness of computer security using the Protection Motivation Theory (PMT) approach. In the growing digital era, threats to computer security are becoming a very important issue, and responsive education is also needed to monitor the balance of gen Z in the growing digital era. This study involved 403 respondents consisting of university students and active computer users in Indonesia. Data was collected through a survey distributed using social media platforms. The results of the analysis show that there is a significant relationship between awareness of security threats and precautionary measures taken by Gen Z. The findings indicate that increased awareness of security risks may encourage better protective behaviors among Gen Z. This research is expected to provide recommendations for the development of more effective and relevant computer security education programs for Gen Z."
Security (cs.CR),2024,11,Design and Analysis of Cybersecurity Information Sharing Mechanism Between Computer Security Incident Response Teams (CSIRT) in Indonesia on Blockchain Technology Through Hyperledger Composer and Interplanetary File System (IPFS),0,N/A,https://www.semanticscholar.org/paper/26dc31b3bc9654add0fec90b743acc8a7518bce4,"Fajar Hariyanto, Kalamullah Ramli","Sharing cybersecurity information among the Computer Security Incident Response Team (CSIRT) is a crucial step in enhancing organizational cybersecurity. However, a primary challenge faced is the lack of trust among users regarding the confidentiality, integrity, and availability of shared information. This study proposes a new approach by designing a mechanism for sharing cybersecurity information among CSIRTs in Indonesia on blockchain technology using Hyperledger Composer. This approach offers an innovative solution by leveraging the advantages of blockchain technology. Through this approach, cybersecurity information can be shared in a decentralized manner, overcoming the weaknesses of centralized systems, and enhancing overall information security. Another advantage of blockchain technology is its high performance and scalability, enabling increased speed, and user capacity in the process of sharing information. By implementing a blockchain-based mechanism for sharing cybersecurity information, this research aims to ensure crucial aspects of information security, namely confidentiality, integrity, and availability. The contribution of this study is not only in enhancing organizational cybersecurity but also in providing an innovative solution to practical challenges in sharing cybersecurity information among CSIRTs."
Security (cs.CR),2024,12,RESEARCH IN THE FIELD OF COMPUTER SECURITY AND PREVENTION OF COMPUTER VIRUSES,0,N/A,https://www.semanticscholar.org/paper/58ad2335e16674bac428c2d26c77dd46f916fee1,"Myalkhazni L. Suleymanova, O. Y. Yanova","With the rapid development of computer technology, the use of computers is becoming more common. However, at the same time, computer security problems are becoming more serious. Computer viruses always threaten people’s computer security. To effectively solve this problem, this article first analyzes computer security issues, then explains the main characteristics of computer viruses, and finally conducts a series of discussions on how to improve computer security."
Security (cs.CR),2024,17,Usage of Blockchain Technology for Improving Computer Security,0,N/A,https://www.semanticscholar.org/paper/fd13c7c70ed85c90b7b362a11bead165082492fc,"Adai Almomani, Mohammed N. Al-Refai, Ahmad Aburomman et al.","Cyber threats have grown increasingly sophisticated, surpassing the capabilities of traditional security measures. Blockchain technology, with its decentralized and immutable structure, offers a potential solution to these challenges. This study examines the role of blockchain tools such as smart contracts, decentralized identity management, and secure data sharing in enhancing cybersecurity. A review of key literature and analysis of survey data from cybersecurity professionals demonstrate blockchain's effectiveness in improving data integrity, access control, and secure communications. The results show significant correlations between the adoption of blockchain technologies and the mitigation of threats like data breaches and unauthorized access. While blockchain presents promising advancements, scalability, regulatory barriers, and energy consumption remain challenges. The study provides valuable insights for researchers, practitioners, and policymakers on how blockchain can be integrated into modern cybersecurity strategies to create more secure digital environments."
Security (cs.CR),2024,18,"Computer Security – ESORICS 2023: 28th European Symposium on Research in Computer Security, The Hague, The Netherlands, September 25–29, 2023, Proceedings, Part III",0,N/A,https://www.semanticscholar.org/paper/b83efb4c45d1324f662f7df6d13250fbb9066b3e,Unknown,No Abstract
Security (cs.CR),2024,19,"Computer Security – ESORICS 2024: 29th European Symposium on Research in Computer Security, Bydgoszcz, Poland, September 16–20, 2024, Proceedings, Part I",0,N/A,https://www.semanticscholar.org/paper/fe6a1c73be2c1ec56af062df901dca753fbf38a4,Unknown,No Abstract
Security (cs.CR),2024,20,"Computer Security – ESORICS 2023: 28th European Symposium on Research in Computer Security, The Hague, The Netherlands, September 25–29, 2023, Proceedings, Part IV",0,N/A,https://www.semanticscholar.org/paper/0c1670d698d1b7456bcbc00fbfd4037ae58adf65,Unknown,No Abstract
Software Engineering (cs.SE),2020,1,Sampling in software engineering research: a critical review and guidelines,360,2002.07764,https://www.semanticscholar.org/paper/849a6be5adf1b9a2b6e59ba0290bca06692c0efd,"Sebastian Baltes, P. Ralph","Representative sampling appears rare in empirical software engineering research. Not all studies need representative samples, but a general lack of representative sampling undermines a scientific field. This article therefore reports a critical review of the state of sampling in recent, high-quality software engineering research. The key findings are: (1) random sampling is rare; (2) sophisticated sampling strategies are very rare; (3) sampling, representativeness and randomness often appear misunderstood. These findings suggest that software engineering research has a generalizability crisis. To address these problems, this paper synthesizes existing knowledge of sampling into a succinct primer and proposes extensive guidelines for improving the conduct, presentation and evaluation of sampling in software engineering research. It is further recommended that while researchers should strive for more representative samples, disparaging non-probability sampling is generally capricious and particularly misguided for predominately qualitative research."
Software Engineering (cs.SE),2020,2,Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure,298,2010.13561,https://www.semanticscholar.org/paper/300fa071d990d5c48385da39dccea6b7b280edec,"Ben Hutchinson, A. Smart, A. Hanna et al.","Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decision-making, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes."
Software Engineering (cs.SE),2020,3,A Survey on Deep Learning for Software Engineering,197,2011.14597,https://www.semanticscholar.org/paper/bea6af010fc02f5ac29edfc17096be6078edab46,"Yanming Yang, Xin Xia, David Lo et al.","In 2006, Geoffrey Hinton proposed the concept of training “Deep Neural Networks (DNNs)” and an improved model training method to break the bottleneck of neural network development. More recently, the introduction of AlphaGo in 2016 demonstrated the powerful learning ability of deep learning and its enormous potential. Deep learning has been increasingly used to develop state-of-the-art software engineering (SE) research tools due to its ability to boost performance for various SE tasks. There are many factors, e.g., deep learning model selection, internal structure differences, and model optimization techniques, that may have an impact on the performance of DNNs applied in SE. Few works to date focus on summarizing, classifying, and analyzing the application of deep learning techniques in SE. To fill this gap, we performed a survey to analyze the relevant studies published since 2006. We first provide an example to illustrate how deep learning techniques are used in SE. We then conduct a background analysis (BA) of primary studies and present four research questions to describe the trend of DNNs used in SE (BA), summarize and classify different deep learning techniques (RQ1), and analyze the data processing including data collection, data classification, data pre-processing, and data representation (RQ2). In RQ3, we depicted a range of key research topics using DNNs and investigated the relationships between DL-based model adoption and multiple factors (i.e., DL architectures, task types, problem types, and data types). We also summarized commonly used datasets for different SE tasks. In RQ4, we summarized the widely used optimization algorithms and provided important evaluation metrics for different problem types, including regression, classification, recommendation, and generation. Based on our findings, we present a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work."
Software Engineering (cs.SE),2020,4,Quantum Software Engineering: Landscapes and Horizons,182,2007.07047,https://www.semanticscholar.org/paper/d0d3f83a5e03ce71fc41852bcda22129d9bdedc0,Jianjun Zhao,"Quantum software plays a critical role in exploiting the full potential of quantum computing systems. As a result, it is drawing increasing attention recently. This paper defines the term ""quantum software engineering"" and introduces a quantum software life cycle. Based on these, the paper provides a comprehensive survey of the current state of the art in the field and presents the challenges and opportunities that we face. The survey summarizes the technology available in the various phases of the quantum software life cycle, including quantum software requirements analysis, design, implementation, test, and maintenance. It also covers the crucial issue of quantum software reuse."
Software Engineering (cs.SE),2020,8,A Systematic Literature Review on the Use of Deep Learning in Software Engineering Research,138,2009.06520,https://www.semanticscholar.org/paper/f16d68f8a949d8995322abb229436fa0bd45fb62,"Cody Watson, Nathan Cooper, David Nader-Palacio et al.","An increasingly popular set of techniques adopted by software engineering (SE) researchers to automate development tasks are those rooted in the concept of Deep Learning (DL). The popularity of such techniques largely stems from their automated feature engineering capabilities, which aid in modeling software artifacts. However, due to the rapid pace at which DL techniques have been adopted, it is difficult to distill the current successes, failures, and opportunities of the current research landscape. In an effort to bring clarity to this cross-cutting area of work, from its modern inception to the present, this article presents a systematic literature review of research at the intersection of SE & DL. The review canvasses work appearing in the most prominent SE and DL conferences and journals and spans 128 papers across 23 unique SE tasks. We center our analysis around the components of learning, a set of principles that governs the application of machine learning techniques (ML) to a given problem domain, discussing several aspects of the surveyed work at a granular level. The end result of our analysis is a research roadmap that both delineates the foundations of DL techniques applied to SE research and highlights likely areas of fertile exploration for the future."
Software Engineering (cs.SE),2020,5,Adoption and Effects of Software Engineering Best Practices in Machine Learning,136,2007.14130,https://www.semanticscholar.org/paper/2243a9d77d351f318ea93a6638879238ba2c8d21,"A. Serban, K. Blom, H. Hoos et al.","Background. The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner. Aim. We aim to empirically determine the state of the art in how teams develop, deploy and maintain software with ML components. Method. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses, we quantified practice adoption, differentiated along demographic characteristics, such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models. Results. Our findings indicate, for example, that larger teams tend to adopt more practices, and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also, the statistical models can accurately predict perceived effects such as agility, software quality and traceability, from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance, as revealed by statistical models, we identify practices that are important but have low adoption, as well as practices that are widely adopted but are less important for the effects we studied. Conclusion. Overall, our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams."
Software Engineering (cs.SE),2020,6,Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?,110,N/A,https://www.semanticscholar.org/paper/b252328704c5a7d9cebd8e29b0210f3bc2f214a2,"Ting Zhang, Bowen Xu, Ferdian Thung et al.","Extensive research has been conducted on sentiment analysis for software engineering (SA4SE). Researchers have invested much effort in developing customized tools (e.g., SentiStrength-SE, SentiCR) to classify the sentiment polarity for Software Engineering (SE) specific contents (e.g., discussions in Stack Overflow and code review comments). Even so, there is still much room for improvement. Recently, pre-trained Transformer-based models (e.g., BERT, XLNet) have brought considerable breakthroughs in the field of natural language processing (NLP). In this work, we conducted a systematic evaluation of five existing SA4SE tools and variants of four state-of-the-art pre-trained Transformer-based models on six SE datasets. Our work is the first to fine-tune pre-trained Transformer-based models for the SA4SE task. Empirically, across all six datasets, our fine-tuned pre-trained Transformer-based models outperform the existing SA4SE tools by 6.5-35.6% in terms of macro/micro-averaged F1 scores."
Software Engineering (cs.SE),2020,7,A practical guide on conducting eye tracking studies in software engineering,106,N/A,https://www.semanticscholar.org/paper/4644afca80b98dc39ee8ad4cf1ce1e940214c366,"Zohreh Sharafi, Bonita Sharif, Yann-Gaël Guéhéneuc et al.",No Abstract
Software Engineering (cs.SE),2020,11,The Talavera Manifesto for Quantum Software Engineering and Programming,93,N/A,https://www.semanticscholar.org/paper/bf26163ea06e71684f78a59bbb720509f349dfb7,"M. Piattini, G. Peterssen, Ricardo Pérez-Castillo et al.",No Abstract
Software Engineering (cs.SE),2020,9,How to Evaluate Solutions in Pareto-Based Search-Based Software Engineering: A Critical Review and Methodological Guidance,88,2002.09040,https://www.semanticscholar.org/paper/3587d2d031e53a5455d9bc6f023aece5c6a61f64,"Tao Chen, M. Li, Xin Yao","With modern requirements, there is an increasing tendency of considering multiple objectives/criteria simultaneously in many Software Engineering (SE) scenarios. Such a multi-objective optimization scenario comes with an important issue — how to evaluate the outcome of optimization algorithms, which typically is a set of incomparable solutions (i.e., being Pareto nondominated to each other). This issue can be challenging for the SE community, particularly for practitioners of Search-Based SE (SBSE). On one hand, multi-objective optimization could still be relatively new to SE/SBSE researchers, who may not be able to identify the right evaluation methods for their problems. On the other hand, simply following the evaluation methods for general multi-objective optimization problems may not be appropriate for specific SBSE problems, especially when the problem nature or decision maker’s preferences are explicitly/implicitly known. This has been well echoed in the literature by various inappropriate/inadequate selection and inaccurate/misleading use of evaluation methods. In this paper, we first carry out a systematic and critical review of quality evaluation for multi-objective optimization in SBSE. We survey 717 papers published between 2009 and 2019 from 36 venues in seven repositories, and select 95 prominent studies, through which we identify five important but overlooked issues in the area. We then conduct an in-depth analysis of quality evaluation indicators/methods and general situations in SBSE, which, together with the identified issues, enables us to codify a methodological guidance for selecting and using evaluation methods in different SBSE scenarios."
Software Engineering (cs.SE),2020,12,Applications of AI in classical software engineering,87,N/A,https://www.semanticscholar.org/paper/f2a621a360a13211a877923b68af3c147155c9a6,"Marco Barenkamp, Jonas Rebstadt, Oliver Thomas","Although Artificial Intelligence (AI) has become a buzzword for self-organizing IT applications, its relevance to software engineering has hardly been analyzed systematically. This study combines a systematic review of previous research in the field and five qualitative interviews with software developers who use or want to use AI tools in their daily work routines, to assess the status of development, future development potentials and equally the risks of AI application to software engineering. The study classifies the insights in the software development life cycle. The analysis results that major achievements and future potentials of AI are a) the automation of lengthy routine jobs in software development and testing using algorithms, e.g. for debugging and documentation, b) the structured analysis of big data pools to discover patterns and novel information clusters and c) the systematic evaluation of these data in neural networks. AI thus contributes to speed up development processes, realize development cost reductions and efficiency gains. AI to date depends on man-made structures and is mainly reproductive, but the automation of software engineering routines entails a major advantage: Human developers multiply their creative potential when using AI tools effectively."
Software Engineering (cs.SE),2020,10,A Comparison of Natural Language Understanding Platforms for Chatbots in Software Engineering,85,2012.02640,https://www.semanticscholar.org/paper/1931447908586e7fceb480b9142c29018f3cbf5b,"Ahmad Abdellatif, K. Badran, D. Costa et al.","Chatbots are envisioned to dramatically change the future of Software Engineering, allowing practitioners to chat and inquire about their software projects and interact with different services using natural language. At the heart of every chatbot is a Natural Language Understanding (NLU) component that enables the chatbot to understand natural language input. Recently, many NLU platforms were provided to serve as an off-the-shelf NLU component for chatbots, however, selecting the best NLU for Software Engineering chatbots remains an open challenge. Therefore, in this paper, we evaluate four of the most commonly used NLUs, namely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on which NLU should be used in Software Engineering based chatbots. Specifically, we examine the NLUs’ performance in classifying intents, confidence scores stability, and extracting entities. To evaluate the NLUs, we use two datasets that reflect two common tasks performed by Software Engineering practitioners, 1) the task of chatting with the chatbot to ask questions about software repositories 2) the task of asking development questions on Q&A forums (e.g., Stack Overflow). According to our findings, IBM Watson is the best performing NLU when considering the three aspects (intents classification, confidence scores, and entity extraction). However, the results from each individual aspect show that, in intents classification, IBM Watson performs the best with an F1-measure$>$>84%, but in confidence scores, Rasa comes on top with a median confidence score higher than 0.91. Our results also show that all NLUs, except for Dialogflow, generally provide trustable confidence scores. For entity extraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE tasks. Our results provide guidance to software engineering practitioners when deciding which NLU to use in their chatbots."
Software Engineering (cs.SE),2020,14,Software Engineering Education: Challenges and Perspectives,83,N/A,https://www.semanticscholar.org/paper/a5ce20acd5d7733d0959de5a5dea403054597c65,"Sofia Ouhbi, Nuno Pombo","The software engineering community celebrated, in 2018, the 50th anniversary of what is considered to be the official start of the profession of software engineering. Software engineering is a young and promising discipline which is still under development and improvement. This is reflected when teaching software engineering in higher education. The aim of this study is to investigate the challenges and perspectives of software engineering education. To do so, a questionnaire study was conducted. 21 software engineering faculty and experts in teaching software engineering related courses participated in this study. The questionnaire contained demographic questions, questions related to students’ engagement and to different methodologies adopted by respondents in the classroom. Results showed that the majority of respondents found engaging students in software engineering courses to be the biggest challenge they faced in the classroom. Almost half of the participants found difficulties designing practical activities for students. Results also revealed that the problem-based learning approach is the most used in software engineering lectures, followed by gamification techniques and role-playing which are new trends used to engage students. Moreover, the majority of the participants considered that the adoption of new teaching methodologies in the classroom produced high impact in the students’ learning experience. Based on the outcomes of this questionnaire study, a conceptual model to engage students in software engineering courses is proposed. For future work, complementary studies should be implemented to evaluate the proposed model in a real-world scenarios including its effect on the achievement of learning outcomes."
Software Engineering (cs.SE),2020,18,Sustainability in Software Engineering Education: a case of general professional competencies,83,N/A,https://www.semanticscholar.org/paper/efab8b53ddad88535952511dc23840e061d741bd,"S. Semerikov, A. Striuk, L. Striuk et al.","The article considers the application of the sustainable development concept to software engineering specialists training. A system of general professional competencies is designed to build sustainable professional competence of software engineering specialist: 1) ability for abstract thinking, analysis and synthesis; 2) ability to apply knowledge in practical situations; 3) ability to communicate in native language; 4) ability to communicate in a foreign language; 5) ability to learn and acquire up-to-date knowledge; 6) ability to search, process and analyze information from various sources; 7) ability to work in a team; 8) ability to act on the basis of ethical considerations; 9) commitment to preserving the environment; 10) ability to act in a socially responsible and conscious manner; 11) ability to realize the rights and obligations as a member of society, to recognize the civil society values and the need for its sustainable development, the rule of law, human rights and freedoms; 12) ability to preserve and enhance the moral, cultural, scientific values and society achievements based on an understanding of the history and patterns of the subject area development, its place in the general system of knowledge about nature and society and in the development of society, equipment’s and technology, to use various types and forms of physical activity for active recreation and healthy lifestyle; 13) ability to apply fundamental and interdisciplinary knowledge to successfully solve software engineering problems; 14) ability to evaluate and take into account economic, social, technological and environmental factors affecting the sphere of professional activity; 15) ability for lifelong learning."
Software Engineering (cs.SE),2020,13,Robotics software engineering: a perspective from the service robotics domain,72,2006.10608,https://www.semanticscholar.org/paper/f2b32fdc6bffa89ec8bdcc78cde7a9e39ef51bcf,"Sergio García, D. Strüber, D. Brugali et al.","Robots that support humans by performing useful tasks (a.k.a., service robots) are booming worldwide. In contrast to industrial robots, the development of service robots comes with severe software engineering challenges, since they require high levels of robustness and autonomy to operate in highly heterogeneous environments. As a domain with critical safety implications, service robotics faces a need for sound software development practices. In this paper, we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering. We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain. Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners, including processes, paradigms, languages, tools, frameworks, and reuse practices, (ii) the distinguishing characteristics of robotics software engineering, and (iii) recurrent challenges usually faced, together with adopted solutions. The paper concludes by discussing observations, derived hypotheses, and proposed actions for researchers and practitioners."
Software Engineering (cs.SE),2020,20,Explainable AI for Software Engineering,70,2012.01614,https://www.semanticscholar.org/paper/73bb47d973d2c8aca4f697c83a99af0e9edba68f,"C. Tantithamthavorn, Jirayus Jiarpakdee, J. Grundy","The success of software engineering projects largely depends on complex decision-making. For example, which tasks should a developer do first, who should perform this task, is the software of high quality, is a software system reliable and resilient enough to deploy, etc. However, erroneous decision-making for these complex questions is costly in terms of money and reputation. Thus, Artificial Intelligence/Machine Learning (AI/ML) techniques have been widely used in software engineering for developing software analytics tools and techniques to improve decision-making, developer productivity, and software quality. However, the predictions of such AI/ML models for software engineering are still not practical (i.e., coarse-grained), not explainable, and not actionable. These concerns often hinder the adoption of AI/ML models in software engineering practices. In addition, many recent studies still focus on improving the accuracy, while a few of them focus on improving explainability. Are we moving in the right direction? How can we better improve the SE community (both research and education)?In this tutorial, we first provide a concise yet essential introduction to the most important aspects of Explainable AI and a hands-on tutorial of Explainable AI tools and techniques. Then, we introduce the fundamental knowledge of defect prediction (an example application of AI for Software Engineering). Finally, we demonstrate three successful case studies on how Explainable AI techniques can be used to address the aforementioned challenges by making the predictions of software defect prediction models more practical, explainable, and actionable. The materials are available at https://xai4se.github.io."
Software Engineering (cs.SE),2020,17,Achieving Reliable Sentiment Analysis in the Software Engineering Domain using BERT,60,N/A,https://www.semanticscholar.org/paper/ecb1e4738c14d6cf1c68f04afa6e7d509767f83e,"Eeshita Biswas, M. Karabulut, L. Pollock et al.","Researchers have shown that sentiment analysis of software artifacts can potentially improve various software engineering tools, including API and library recommendation systems, code suggestion tools, and tools for improving communication among software developers. However, sentiment analysis techniques applied to software artifacts still have not yet yielded very high accuracy. Recent adaptations of sentiment analysis tools to the software domain have reported some improvements, but the f-measures for the positive and negative sentences still remain in the 0.4-0.64 range, which deters their practical usefulness for software engineering tools.In this paper, we explore the potential effectiveness of customizing BERT, a language representation model, which has recently achieved very good results on various Natural Language Processing tasks on English texts, for the task of sentiment analysis of software artifacts. We describe our application of BERT to analyzing sentiments of sentences in Stack Overflow posts and compare the impact of a BERT sentiment classifier to state-of-the-art sentiment analysis techniques when used on a domain-specific data set created from Stack Overflow posts. We also investigate how the performance of sentiment analysis changes when using a much (3 times) larger data set than previous studies. Our results show that the BERT classifier achieves reliable performance for sentiment analysis of software engineering texts. BERT combined with the larger data set achieves an overall f-measure of 0.87, with the f-measures for the negative and positive sentences reaching 0.91 and 0.78 respectively, a significant improvement over the state-of-the-art."
Software Engineering (cs.SE),2020,15,Extracting and Classifying Requirements from Software Engineering Contracts,58,N/A,https://www.semanticscholar.org/paper/03cbba9ffc7fb32ecddcf72fb1adf1c1c8afdfaf,"A. Sainani, P. Anish, V. Joshi et al.","In this paper, we present our work on extracting and classifying requirements from large software engineering contracts. Typically, the process of requirements elicitation begins after a contractual agreement is signed by all participants. Our interactions with the legal compliance team in a large vendor organization reveal that business contracts can help in the identification of high-level requirements relevant to the success of software engineering projects. We posit that requirements engineering as a discipline has an even wider scope than software engineering of which it is traditionally considered to be a sub-discipline. This is because software engineering-specific requirements are but a part of the success story of any large project. The requirements that emerge from contracts are obligatory in nature, whether or not they pertain to core software development. Therefore, it is important that these are extracted and classified for the benefit of software engineers and other stakeholders responsible for a project. We discuss the results of an exploratory study and a range of experiments from the use of regular expressions to Bidirectional Encoder Representations from Transformers for automating the extraction and classification of requirements from software engineering contracts. With Bidirectional Encoder Representations from Transformers, we obtained a high f-score of greater than eighty four percent for classification of requirements."
Software Engineering (cs.SE),2020,16,Rapid Reviews in Software Engineering,49,2003.10006,https://www.semanticscholar.org/paper/7462d9419314313abbfb577e84f8c5364db1c440,"Bruno Cartaxo, G. Pinto, S. Soares","Integrating research evidence into practice is one of the main goals of evidence-based software engineering (EBSE). Secondary studies, one of the main EBSE products, are intended to summarize the “best” research evidence and make them easily consumable by practitioners. However, recent studies show that some secondary studies lack connections with software engineering practice. In this chapter, we present the concept of Rapid Reviews, which are lightweight secondary studies focused on delivering evidence to practitioners in a timely manner. Rapid reviews support practitioners in their decision-making, and should be conducted bounded to a practical problem, inserted into a practical context. Thus, Rapid Reviews can be easily integrated in a knowledge/technology transfer initiative. After describing the basic concepts, we present the results and experiences of conducting two Rapid Reviews. We also provide guidelines to help researchers and practitioners who want to conduct Rapid Reviews, and we finally discuss topics that may concern the research community about the feasibility of Rapid Reviews as an evidence-based method. In conclusion, we believe Rapid Reviews might be of interest to researchers and practitioners working on the intersection of software engineering research and practice."
Software Engineering (cs.SE),2020,19,Authorship attribution of source code: a language-agnostic approach and applicability in software engineering,43,2001.11593,https://www.semanticscholar.org/paper/c5b6c4e651123270ebc8df3a4b5705d0e61431ff,"Egor Bogomolov, V. Kovalenko, Alberto Bacchelli et al.","Authorship attribution (i.e., determining who is the author of a piece of source code) is an established research topic. State-of-the-art results for the authorship attribution problem look promising for the software engineering field, where they could be applied to detect plagiarized code and prevent legal issues. With this article, we first introduce a new language-agnostic approach to authorship attribution of source code. Then, we discuss limitations of existing synthetic datasets for authorship attribution, and propose a data collection approach that delivers datasets that better reflect aspects important for potential practical use in software engineering. Finally, we demonstrate that high accuracy of authorship attribution models on existing datasets drastically drops when they are evaluated on more realistic data. We outline next steps for the design and evaluation of authorship attribution models that could bring the research efforts closer to practical use for software engineering."
Software Engineering (cs.SE),2021,2,Software Engineering for AI-Based Systems: A Survey,272,2105.01984,https://www.semanticscholar.org/paper/1a6fc05a37ae1b2fc7c6193cb6dc8282767c2cb6,"Silverio Mart'inez-Fern'andez, J. Bogner, Xavier Franch et al.","AI-based systems are software systems with functionalities enabled by at least one AI component (e.g., for image-, speech-recognition, and autonomous driving). AI-based systems are becoming pervasive in society due to advances in AI. However, there is limited synthesized knowledge on Software Engineering (SE) approaches for building, operating, and maintaining AI-based systems. To collect and analyze state-of-the-art knowledge about SE for AI-based systems, we conducted a systematic mapping study. We considered 248 studies published between January 2010 and March 2020. SE for AI-based systems is an emerging research area, where more than 2/3 of the studies have been published since 2018. The most studied properties of AI-based systems are dependability and safety. We identified multiple SE approaches for AI-based systems, which we classified according to the SWEBOK areas. Studies related to software testing and software quality are very prevalent, while areas like software maintenance seem neglected. Data-related issues are the most recurrent challenges. Our results are valuable for: researchers, to quickly understand the state-of-the-art and learn which topics need more research; practitioners, to learn about the approaches and challenges that SE entails for AI-based systems; and, educators, to bridge the gap among SE and AI in their curricula."
Software Engineering (cs.SE),2021,3,PLS-SEM for Software Engineering Research,179,N/A,https://www.semanticscholar.org/paper/72420df89e0c96d531e66dcac15f4e9411307ad9,"Daniel Russo, Klaas-Jan Stol","Software Engineering (SE) researchers are increasingly paying attention to organizational and human factors. Rather than focusing only on variables that can be directly measured, such as lines of code, SE research studies now also consider unobservable variables, such as organizational culture and trust. To measure such latent variables, SE scholars have adopted Partial Least Squares Structural Equation Modeling (PLS-SEM), which is one member of the larger SEM family of statistical analysis techniques. As the SE field is facing the introduction of new methods such as PLS-SEM, a key issue is that not much is known about how to evaluate such studies. To help SE researchers learn about PLS-SEM, we draw on the latest methodological literature on PLS-SEM to synthesize an introduction. Further, we conducted a survey of PLS-SEM studies in the SE literature and evaluated those based on recommended guidelines."
Software Engineering (cs.SE),2021,15,Exploring the intersection between software industry and Software Engineering education - A systematic mapping of Software Engineering Trends,125,N/A,https://www.semanticscholar.org/paper/1c11551dc313de80afe3c39f68f0cdb51aaf319a,"Orges Cico, M. L. Jaccheri, Anh Nguyen-Duc et al.",No Abstract
Software Engineering (cs.SE),2021,5,Perceived diversity in software engineering: a systematic literature review,119,N/A,https://www.semanticscholar.org/paper/68c9ed6d0dd8c8fb405d085be9c112e47dd43896,"Gema Rodríguez-Pérez, Reza Nadri, M. Nagappan","We define perceived diversity as the diversity factors that individuals are born with. Perceived diversity in Software Engineering has been recognized as a high-value team property and companies are willing to increase their efforts to create more diverse work teams. The current diversity state-of-the-art shows that gender diversity studies have been growing during the past decade, and they have shown the benefits of including women in software teams. However, less is known about how other perceived diversity factors such as race, nationality, disability, and age of developers are related to Software Engineering. Through a systematic literature review, we aim to clarify the research area concerned with perceived diversity in Software Engineering. Our goal is to identify (1) what issues have been studied and what results have been reported; (2) what methods, tools, models, and processes have been proposed to help perceived diversity issues; and (3) what limitations have been reported when studying perceived diversity in Software Engineering. Furthermore, our ultimate goal is to identify gaps in the current literature and create a call for future action in perceived diversity in Software Engineering. Our results indicate that the individual studies have typically had a gender diversity perspective focusing on showing gender bias or gender differences instead of developing methods and tools to mitigate the gender diversity issues faced in SE. Moreover, perceived diversity aspects related to SE participants’ race, age, and disability need to be further analyzed in Software Engineering research. From our systematic literature review, we conclude that researchers need to consider a wider set of perceived diversity aspects for future research."
Software Engineering (cs.SE),2021,4,Socio-Technical Grounded Theory for Software Engineering,118,2103.14235,https://www.semanticscholar.org/paper/baa9c3ab68755fcb91de5ba4247cac376df87bc9,Rashina Hoda,"Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence."
Software Engineering (cs.SE),2021,6,Multilingual training for Software Engineering,87,2112.02043,https://www.semanticscholar.org/paper/775a9c722262c7b656876a5fef20f4577afd8981,"Toufique Ahmed, Prem Devanbu","Well-trained machine-learning models, which leverage large amounts of open-source software data, have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach, with performance gradually improving over the past several years with better models and training methods. More, and more diverse, clean, labeled data is better for training; but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean, labeled data generally have wide applicability. For some languages (e.g., Ruby) labeled data is less abundant; in others (e.g., JavaScript) the available data maybe more focused on some application domains, and thus less diverse. As a way around such data bottlenecks, we present evidence suggesting that human-written code in different languages (which performs the same function), is rather similar, and particularly preserving of identifier naming patterns; we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization, code retrieval, and function naming. We note that this data-augmenting approach is broadly compatible with different tasks, languages, and machine-learning models."
Software Engineering (cs.SE),2021,8,Toward a Quantum Software Engineering,82,N/A,https://www.semanticscholar.org/paper/daa868d74daf4c808729c34255671833b4dd9aab,"M. Piattini, M. Serrano, Ricardo Pérez-Castillo et al.","Nowadays, we are at the dawn of a new age, the quantum era. Quantum computing is no longer a dream; it is a reality that needs to be adopted. But this new technology is taking its first steps, so we still do not have models, standards, or methods to help us in the creation of new systems and the migration of current ones. Given the current state of quantum computing, we need to go back to the path software engineering took in the last century to achieve the new golden age for quantum software engineering."
Software Engineering (cs.SE),2021,9,On the Validity of Pre-Trained Transformers for Natural Language Processing in the Software Engineering Domain,77,2109.04738,https://www.semanticscholar.org/paper/11907f691e9b7fc32a492e1de676a4b788add155,"Julian von der Mosel, Alexander Trautsch, Steffen Herbold","Transformers are the current state-of-the-art of natural language processing in many domains and are using traction within software engineering research as well. Such models are pre-trained on large amounts of data, usually from the general domain. However, we only have a limited understanding regarding the validity of transformers within the software engineering domain, i.e., how good such models are at understanding words and sentences within a software engineering context and how this improves the state-of-the-art. Within this article, we shed light on this complex, but crucial issue. We compare BERT transformer models trained with software engineering data with transformers based on general domain data in multiple dimensions: their vocabulary, their ability to understand which words are missing, and their performance in classification tasks. Our results show that for tasks that require understanding of the software engineering context, pre-training with software engineering data is valuable, while general domain models are sufficient for general language understanding, also within the software engineering domain."
Software Engineering (cs.SE),2021,11,UML Diagrams in Software Engineering Research: A Systematic Literature Review,73,N/A,https://www.semanticscholar.org/paper/f1e8848f66d377a58c87809b574724fef7b718e7,"H. Koç, A. Erdoğan, Yousef Barjakly et al.","Software engineering is a discipline utilizing Unified Modelling Language (UML) diagrams, which are accepted as a standard to depict object-oriented design models. UML diagrams make it easier to identify the requirements and scopes of systems and applications by providing visual models. In this manner, this study aims to systematically review the literature on UML diagram utilization in software engineering research. A comprehensive review was conducted over the last two decades, spanning from 2000 to 2019. Among several papers, 128 were selected and examined. The main findings showed that UML diagrams were mostly used for the purpose of design and modeling, and class diagrams were the most commonly used ones."
Software Engineering (cs.SE),2021,7,An assessment of student satisfaction with e-learning: An empirical study with computer and software engineering undergraduate students in Turkey under pandemic conditions,70,N/A,https://www.semanticscholar.org/paper/915e475bdd4334e4c0ff4f8158545507e743b48e,G. Giray,"As COVID-19 reached Turkey in March 2020, all universities switched to e-learning in a very short period. Computer and software engineering (CE/SE) undergraduate students studying at university campuses have switched to e-learning. This paper seeks to understand the e-learning experience of CE/SE undergraduate students. A questionnaire was created and applied to CE/SE undergraduate students in Turkish universities. The data were analyzed using quantitative and qualitative techniques. The questionnaire received 290 usable responses. The highlights from the findings include: the participants (1) used video recordings intensively for e-learning and found them useful; (2) found face-to-face lectures more beneficial compared to digital live lectures; (3) used external online resources to improve their learning performance in courses; (4) thought that the materials and methods utilized for assessment should be adapted to e-learning for a better and fair evaluation; (5) perceived significantly less instructor support and classmate interaction and collaboration in e-learning compared to on-campus education settings; (6) rated their perceived satisfaction from e-learning as 2.85, slightly under the mid-level of the 5-point Likert scale; (7) perceived instructor support, student interaction and collaboration, and student autonomy as noteworthy factors in high-quality e-learning."
Software Engineering (cs.SE),2021,10,Topic modeling in software engineering research,64,N/A,https://www.semanticscholar.org/paper/9a3db72f11b3f93f05419a84aacb7f52e88eff35,"Camila Costa Silva, M. Galster, Fabian Gilson","Topic modeling using models such as Latent Dirichlet Allocation (LDA) is a text mining technique to extract human-readable semantic “topics” (i.e., word clusters) from a corpus of textual documents. In software engineering, topic modeling has been used to analyze textual data in empirical studies (e.g., to find out what developers talk about online), but also to build new techniques to support software engineering tasks (e.g., to support source code comprehension). Topic modeling needs to be applied carefully (e.g., depending on the type of textual data analyzed and modeling parameters). Our study aims at describing how topic modeling has been applied in software engineering research with a focus on four aspects: (1) which topic models and modeling techniques have been applied, (2) which textual inputs have been used for topic modeling, (3) how textual data was “prepared” (i.e., pre-processed) for topic modeling, and (4) how generated topics (i.e., word clusters) were named to give them a human-understandable meaning. We analyzed topic modeling as applied in 111 papers from ten highly-ranked software engineering venues (five journals and five conferences) published between 2009 and 2020. We found that (1) LDA and LDA-based techniques are the most frequent topic modeling techniques, (2) developer communication and bug reports have been modelled most, (3) data pre-processing and modeling parameters vary quite a bit and are often vaguely reported, and (4) manual topic naming (such as deducting names based on frequent words in a topic) is common."
Software Engineering (cs.SE),2021,13,BERT-Based Sentiment Analysis: A Software Engineering Perspective,49,2106.02581,https://www.semanticscholar.org/paper/4d84a0950255447f0efa297d2fa15ef0c9a605f4,"Himanshu Batra, N. S. Punn, S. K. Sonbhadra et al.","Sentiment analysis can provide a suitable lead for the tools used in software engineering along with the API recommendation systems and relevant libraries to be used. In this context, the existing tools like SentiCR, SentiStrength-SE, etc. exhibited low f1-scores that completely defeats the purpose of deployment of such strategies, thereby there is enough scope for performance improvement. Recent advancements show that transformer based pre-trained models (e.g., BERT, RoBERTa, ALBERT, etc.) have displayed better results in the text classification task. Following this context, the present research explores different BERT-based models to analyze the sentences in GitHub comments, Jira comments, and Stack Overflow posts. The paper presents three different strategies to analyse BERT based model for sentiment analysis, where in the first strategy the BERT based pre-trained models are fine-tuned; in the second strategy an ensemble model is developed from BERT variants, and in the third strategy a compressed model (Distil BERT) is used. The experimental results show that the BERT based ensemble approach and the compressed BERT model attain improvements by 6-12% over prevailing tools for the F1 measure on all three datasets."
Software Engineering (cs.SE),2021,12,Understanding Quantum Software Engineering Challenges An Empirical Study on Stack Exchange Forums and GitHub Issues,45,2205.03181,https://www.semanticscholar.org/paper/4d5c4d056ddb2eda874d2430e3af65f91a9ba652,"Mohamed Raed El aoun, Heng Li, Foutse Khomh et al.","With the advance of quantum computing, quantum software becomes critical for exploring the full potential of quantum computing systems. Recently, quantum software engineering (QSE) becomes an emerging area attracting more and more attention. However, it is not clear what are the challenges and opportunities of quantum computing facing the software engineering community. This work aims to understand the QSE-related challenges perceived by developers. We perform an empirical study on Stack Exchange forums where developers post-QSE-related questions & answers and Github issue reports where developers raise QSE-related issues in practical quantum computing projects. Based on an existing taxonomy of question types on Stack Overflow, we first perform a qualitative analysis of the types of QSE-related questions asked on Stack Exchange forums. We then use automated topic modeling to uncover the topics in QSE-related Stack Exchange posts and GitHub issue reports. Our study highlights some particularly challenging areas of QSE that are different from that of traditional software engineering, such as explaining the theory behind quantum computing code, interpreting quantum program outputs, and bridging the knowledge gap between quantum computing and classical computing, as well as their associated opportunities."
Software Engineering (cs.SE),2021,14,Construct Validity in Software Engineering,41,N/A,https://www.semanticscholar.org/paper/7896a717786f839c3911021a0913df7b8f8f0dd2,"Dag I.K. Sjøberg, Gunnar R. Bergersen","Empirical research aims to establish generalizable claims from data. Such claims may involve concepts that must be measured indirectly by using indicators. Construct validity is concerned with whether one can justifiably make claims at the conceptual level that are supported by results at the operational level. We report a quantitative analysis of the awareness of construct validity in the software engineering literature between 2000 and 2019 and a qualitative review of 83 articles about human-centric experiments published in five high-quality journals between 2015 and 2019. Over the two decades, the appearance in the literature of the term construct validity increased sevenfold. Some of the reviewed articles we reviewed employed various ways to ensure that the indicators span the concept in an unbiased manner. We also found articles that reuse formerly validated constructs. However, the articles disagree about how to define construct validity. Several interpret construct validity excessively by including threats to internal, external, or statistical conclusion validity. A few articles also include fundamental challenges of a study, such as cheating and misunderstanding of experiment material. The diversity of topics included as threats to construct validity calls for a more minimalist approach. Based on the review, we propose seven guidelines to improve how construct validity is handled and reported in software engineering."
Software Engineering (cs.SE),2021,16,Evaluating pre-trained models for user feedback analysis in software engineering: a study on classification of app-reviews,38,2104.05861,https://www.semanticscholar.org/paper/44725678a7e2b48fdcf6ad3b86d1a96dec736a9e,"M. Hadi, F. H. Fard","Context Automatic classification of mobile applications users’ feedback is studied for different areas of software engineering. However, supervised classification requires a lot of manually labeled data, and with introducing new classes or new platforms, new labeled data and models are required. Employing Pre-trained neural Language Models (PLMs) have found success in the Natural Language Processing field. However, their applicability has not been explored for app review classification. Objective We evaluate using PLMs for issue classification from app reviews in multiple settings and compare them with the existing models. Method We set up different studies to evaluate the performance and time efficiency of PLMs compared to Prior approaches on six datasets: binary vs. multi-class, zero-shot, multi-task, and multi-resource settings. In addition, we train and study domain-specific (Custom) PLMs by incorporating app reviews in the pre-training. We report Micro and Macro Precision, Recall, and F1 scores and the time required for training and predicting with the models. Results Our results show that PLMs can classify the app issues with higher scores, except in multi-resource setting. On the largest dataset, results are improved by 13 and 8 micro- and macro-average F1-scores, respectively, compared to the Prior approaches. Domain-specific PLMs achieve the highest scores in all settings with less prediction time, and they benefit from pre-training with a larger number of app reviews. On the largest dataset, we obtain 98 and 92 micro- and macro-average F1-score (from 4.5 to 8.3 more F1-score compared to general pre-trained models), 71 F1-score in zero-shot setting, and 93 and 92 F1-score in multi-task and multi-resource settings, respectively, using the large domain-specific PLMs. Conclusion Although prior approaches achieve high scores in some settings, PLMs are the only models that can work well in the zero-shot setting. When trained on the app review dataset, the Custom PLMs have higher performance and lower prediction times."
Software Engineering (cs.SE),2021,18,Benchmarking as Empirical Standard in Software Engineering Research,37,2105.00272,https://www.semanticscholar.org/paper/51b1dbe20bb4cf79729601ae429b8137cdac9685,W. Hasselbring,"In empirical software engineering, benchmarks can be used for comparing different methods, techniques and tools. However, the recent ACM SIGSOFT Empirical Standards for Software Engineering Research do not include an explicit checklist for benchmarking. In this paper, we discuss benchmarks for software performance and scalability evaluation as example research areas in software engineering, relate benchmarks to some other empirical research methods, and discuss the requirements on benchmarks that may constitute the basis for a checklist of a benchmarking standard for empirical software engineering research."
Software Engineering (cs.SE),2021,17,Development and Application of Sentiment Analysis Tools in Software Engineering: A Systematic Literature Review,36,2105.02703,https://www.semanticscholar.org/paper/4d3f9a314cdba9aec33a18ea4ccd53fbf635a860,"Martin Obaidi, J. Klünder","Software development is a collaborative task and, hence, involves different persons. Research has shown the relevance of social aspects in the development team for a successful and satisfying project closure. Especially the mood of a team has been proven to be of particular importance. Thus, project managers or project leaders want to be aware of situations in which negative mood is present to allow for interventions. So-called sentiment analysis tools offer a way to determine the mood based on text-based communication. In this paper, we present the results of a systematic literature review of sentiment analysis tools developed for or applied in the context of software engineering. Our results summarize insights from 80 papers with respect to (1) the application domain, (2) the purpose, (3) the used data sets, (4) the approaches for developing sentiment analysis tools and (5) the difficulties researchers face when applying sentiment analysis in the context of software projects. According to our results, sentiment analysis is frequently applied to open-source software projects, and most tools are based on support-vector machines. Despite the frequent use of sentiment analysis in software engineering, there are open issues, e.g., regarding the identification of irony or sarcasm, pointing to future research directions."
Software Engineering (cs.SE),2021,19,History of Software Engineering,36,N/A,https://www.semanticscholar.org/paper/055ab97caf9d80f6af77b81b4eb28e4c3d72fc08,Gerard O'Regan,No Abstract
Software Engineering (cs.SE),2021,20,The realist approach for evaluation of computational intelligence in software engineering,36,N/A,https://www.semanticscholar.org/paper/4e22078a76c5cd3e1357dd9a891224ccf361fe53,"Raghavendra Rao Althar, D. Samanta",No Abstract
Software Engineering (cs.SE),2021,1,Accurate Simulation of Operating System Updates in Neuroimaging Using Monte-Carlo Arithmetic,8,2108.03129,https://www.semanticscholar.org/paper/4940d2a96d8bf2275f327230bfd86c87bb986343,"A. Salari, Yohan Chatelain, Gregory Kiar et al.","Operating system (OS) updates introduce numerical perturbations that impact the reproducibility of computational pipelines. In neuroimaging, this has important practical implications on the validity of computational results, particularly when obtained in systems such as high-performance computing clusters where the experimenter does not control software updates. We present a framework to reproduce the variability induced by OS updates in controlled conditions. We hypothesize that OS updates impact computational pipelines mainly through numerical perturbations originating in mathematical libraries, which we simulate using Monte-Carlo arithmetic in a framework called “fuzzy libmath” (FL). We applied this methodology to pre-processing pipelines of the Human Connectome Project, a flagship open-data project in neuroimaging. We found that FL-perturbed pipelines accurately reproduce the variability induced by OS updates and that this similarity is only mildly dependent on simulation parameters. Importantly, we also found between-subject differences were preserved in both cases, though the between-run variability was of comparable magnitude for both FL and OS perturbations. We found the numerical precision in the HCP preprocessed images to be relatively low, with less than 8 significant bits among the 24 available, which motivates further investigation of the numerical stability of components in the tested pipeline. Overall, our results establish that FL accurately simulates results variability due to OS updates, and is a practical framework to quantify numerical uncertainty in neuroimaging."
Software Engineering (cs.SE),2022,2,Analysing app reviews for software engineering: a systematic literature review,71,N/A,https://www.semanticscholar.org/paper/695886bf2b7bf90e98e98f630b26dabcdbe78247,"Jacek Dąbrowski, Emmanuel Letier, A. Perini et al.","App reviews found in app stores can provide critically valuable information to help software engineers understand user requirements and to design, debug, and evolve software products. Over the last ten years, a vast amount of research has been produced to study what useful information might be found in app reviews, and how to mine and organise such information as efficiently as possible. This paper presents a comprehensive survey of this research, covering 182 papers published between 2012 and 2020. This survey classifies app review analysis not only in terms of mined information and applied data mining techniques but also, and most importantly, in terms of supported software engineering activities. The survey also reports on the quality and results of empirical evaluation of existing techniques and identifies important avenues for further research. This survey can be of interest to researchers and commercial organisations developing app review analysis techniques and to software engineers considering to use app review analysis."
Software Engineering (cs.SE),2022,1,Towards a Roadmap on Software Engineering for Responsible AI,68,2203.08594,https://www.semanticscholar.org/paper/dccd738bc67c1e4b807b07872ff065fadc4253da,"Q. Lu, Liming Zhu, Xiwei Xu et al.","Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques. CCS CONCEPTS • Software and its engineering;"
Software Engineering (cs.SE),2022,3,Software Engineering for Quantum Programming: How Far Are We?,62,2203.16969,https://www.semanticscholar.org/paper/5decb10453a5349aa3c51ff948b95b7c95a08932,"Manuel De Stefano, Fabiano Pecorelli, Dario Di Nucci et al.","Quantum computing is no longer only a scientiﬁc interest but is rapidly becoming an industrially available technology that can potentially overcome the limits of classical computation. Over the last years, all major companies have provided frameworks and programming languages that allow developers to create their quantum applications. This shift has led to the deﬁnition of a new discipline called quantum software engineering , which is demanded to deﬁne novel methods for engineering large-scale quantum applications. While the research community is successfully embracing this call, we notice a lack of systematic investigations into the state of the practice of quantum programming. Understanding the challenges that quantum developers face is vital to precisely deﬁne the aims of quantum software engineering. Hence, in this paper, we ﬁrst mine all the GitHub repositories that make use of the most used quantum programming frameworks currently on the market and then conduct coding analysis sessions to produce a taxonomy of the purposes for which quantum technologies are used. In the second place, we conduct a survey study that involves the contributors of the considered repositories, which aims to elicit the developers’ opinions on the current adoption and challenges of quantum programming. On the one hand, the results highlight that the current adoption of quantum programming is still limited. On the other hand, there are many challenges that the software engineering community should carefully consider: these do not strictly pertain to technical concerns but also socio-technical matters."
Software Engineering (cs.SE),2022,4,Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models of Source Code,57,2205.11739,https://www.semanticscholar.org/paper/2417ab25a53e97410f44a20af69b82fff077fd53,"Changan Niu, Chuanyi Li, Bin Luo et al.","Recent years have seen the successful application of deep learning to software engineering (SE). In particular, the development and use of pre-trained models of source code has enabled state-of-the-art results to be achieved on a wide variety of SE tasks. This paper provides an overview of this rapidly advancing field of research and reflects on future research directions."
Software Engineering (cs.SE),2022,5,Comparing the Effectiveness of Video-Based Learning and Game-Based Learning Using Teacher-Authored Video Games for Online Software Engineering Education,49,N/A,https://www.semanticscholar.org/paper/e951b1dfbe8e56d5ae6d551036564807c7a69338,"A. Gordillo, D. López-fernández, E. Tovar","Contribution: This article compares the effectiveness for online software engineering education of video-based learning and game-based learning using teacher-authored educational video games created by using authoring tools. Background: Although substantial research has evaluated the impact of video-based and game-based learning versus traditional teaching approaches, little research has been done comparing the effectiveness of video-based learning and video game-based learning. Furthermore, the few studies that performed this comparison did not compare the effectiveness for online education or examined teacher-authored video games. Research Questions: Is game-based learning using teacher-authored video games more effective than video-based learning in terms of knowledge acquisition for software engineering students in online settings? Is game-based learning using teacher-authored video games more effective than video-based learning in terms of motivation for software engineering students in online settings? Methodology: A quasi-experimental design with control and experimental groups and pre- and post-tests was employed. A total of 180 software engineering students participated in this study, 81 of which belonged to the control group while the other 99 were part of the experimental group. The students in the control group took an online lesson in which they learned exclusively by watching videos, whereas the students in the experimental group took the same lesson but learned exclusively by playing an educational video game created by a teacher through an authoring tool. Findings: The results show that game-based learning using teacher-authored educational video games was more effective than video-based learning in terms of both knowledge acquisition and motivation."
Software Engineering (cs.SE),2022,6,Human Values in Software Engineering: Contrasting Case Studies of Practice,44,N/A,https://www.semanticscholar.org/paper/05f4ee34883735ce98d01fc39abd91975e293c76,"Waqar Hussain, Harsha Perera, J. Whittle et al.","The growing diffusion of software in society and its influence on people demands from its creators that their work carefully considers human values such as transparency, social responsibility, and equality. But how do software practitioners address human values in software engineering practice? We interviewed 31 software practitioners from two organizations, each having a strong values framework, with the aim to understand: (a) practitioners’ perceptions of human values and their role in software engineering; (b) practices that practitioners use to address human values in software; and (c) challenges they face during this process. We report our findings from two contrasting case organizations on how practitioners “engineer” values in their unique organizational settings. We found evidence that organizational culture significantly contributes to how values are addressed in software. We summarize recommendations from the practitioners to support proactive engineering of values-conscious software."
Software Engineering (cs.SE),2022,7,Improving learning experiences in software engineering capstone courses using artificial intelligence virtual assistants,44,N/A,https://www.semanticscholar.org/paper/2f773e3ccd664e48293520a322bdefd908e5b3e5,"L. A. González, Andrés Neyem, Ignacio Contreras-McKay et al.","Students of Software Engineering Capstone Courses face situations and challenges that grant them valuable experiences. However, as this knowledge is acquired through real‐life exposure, it is difficult to transmit it across different generations. To deal with this problem, it has been proposed that students record their learnings through a lesson learned model. But the question of how future students can best benefit from these records remains unanswered. This study addresses this problem through the use of Artificial Intelligence (AI) Virtual Assistant combined with a recommender system. Artificial Intelligence Virtual Assistants, as conversational chatbots, are a manifestation of AI via the simulation of conversation with human users. The technology has the potential to provide personalized service to a range of stakeholders. Thus, we seek to move this trend forward by now pushing these capabilities into the field of higher education. Consequently, we aim to assist software engineering students by leveraging collective knowledge to enhance learning experiences."
Software Engineering (cs.SE),2022,9,The Weights Can Be Harmful: Pareto Search versus Weighted Search in Multi-objective Search-based Software Engineering,42,2202.03728,https://www.semanticscholar.org/paper/82fd766ef7ee3944f4feb4a8c8812c93631c57a2,"Tao Chen, Miqing Li","In presence of multiple objectives to be optimized in Search-Based Software Engineering (SBSE), Pareto search has been commonly adopted. It searches for a good approximation of the problem’s Pareto-optimal solutions, from which the stakeholders choose the most preferred solution according to their preferences. However, when clear preferences of the stakeholders (e.g., a set of weights that reflect relative importance between objectives) are available prior to the search, weighted search is believed to be the first choice, since it simplifies the search via converting the original multi-objective problem into a single-objective one and enables the search to focus on what only the stakeholders are interested in. This article questions such a “weighted search first” belief. We show that the weights can, in fact, be harmful to the search process even in the presence of clear preferences. Specifically, we conduct a large-scale empirical study that consists of 38 systems/projects from three representative SBSE problems, together with two types of search budget and nine sets of weights, leading to 604 cases of comparisons. Our key finding is that weighted search reaches a certain level of solution quality by consuming relatively less resources at the early stage of the search; however, Pareto search is significantly better than its weighted counterpart the majority of the time (up to 77% of the cases), as long as we allow a sufficient, but not unrealistic search budget. This is a beneficial result, as it discovers a potentially new “rule-of-thumb” for the SBSE community: Even when clear preferences are available, it is recommended to always consider Pareto search by default for multi-objective SBSE problems, provided that solution quality is more important. Weighted search, in contrast, should only be preferred when the resource/search budget is limited, especially for expensive SBSE problems. This, together with other findings and actionable suggestions in the article, allows us to codify pragmatic and comprehensive guidance on choosing weighted and Pareto search for SBSE under the circumstance that clear preferences are available. All code and data can be accessed at https://github.com/ideas-labo/pareto-vs-weight-for-sbse."
Software Engineering (cs.SE),2022,8,Analysis of Software Engineering Skills Gap in the Industry,40,N/A,https://www.semanticscholar.org/paper/e0e60fbd0219251c45936ff9e6652426b2af927d,Deniz Akdur,"Many practitioners might struggle with becoming productive in different software engineering (SE) roles due to misalignment of the skills learnt during the university time with what is expected in the industry. Companies spend significant resources to train the personnel, whose academic backgrounds are not only based on “computing disciplines”. Hiring properly trained practitioners allows employers to spend less time while incorporating them more efficiently into the workforce; for employees, knowing the most important skillset is helpful to increase their chance of employability. On the other hand, for academia, understanding the necessary skillset is critical to make curriculum updates. To achieve these objectives, we conducted a survey, which was responded to by 628 software practitioners, who completed their undergraduate degree in Turkey, working in 13 countries. This paper sheds light on the most important (hard and soft) skills in the industry by presenting various cross-factor analyses as well as their coverage in the academic curriculum (mostly in Turkish universities). The results showed that the most important skills are related to various factors such as profiles of the practitioners (e.g., SE role(s), work experience) and the characteristics of the product developed by the practitioner. The findings revealed that both academia and industry should invest in skills improvement: academia can make necessary educational updates according to industrial needs; whereas industry can provide practical experiences to students. By creating the awareness of the expected skillset, both practitioners and academics will benefit from the results, which help close the gaps that can and should be achieved through more Industry Academia Collaborations (IACs)."
Software Engineering (cs.SE),2022,11,Machine Learning for Software Engineering: A Tertiary Study,34,2211.09425,https://www.semanticscholar.org/paper/4493aa3f41deb145ad385d7fa6e2fb4805da03ab,"Zoe Kotti, R. Galanopoulou, D. Spinellis","Machine learning (ML) techniques increase the effectiveness of software engineering (SE) lifecycle activities. We systematically collected, quality-assessed, summarized, and categorized 83 reviews in ML for SE published between 2009 and 2022, covering 6,117 primary studies. The SE areas most tackled with ML are software quality and testing, while human-centered areas appear more challenging for ML. We propose a number of ML for SE research challenges and actions, including conducting further empirical validation and industrial studies on ML, reconsidering deficient SE methods, documenting and automating data collection and pipeline processes, reexamining how industrial practitioners distribute their proprietary data, and implementing incremental ML approaches."
Software Engineering (cs.SE),2022,12,Overview of the IRSE track at FIRE 2022: Information Retrieval in Software Engineering,33,N/A,https://www.semanticscholar.org/paper/a8c1f78bfc279b0e74e695610ce4ab8f5f217d56,"Srijoni Majumdar, Ayan Bandyopadhyay, S. Chattopadhyay et al.",No Abstract
Software Engineering (cs.SE),2022,19,Bots in software engineering: a systematic mapping study,33,N/A,https://www.semanticscholar.org/paper/8bd3a130e82b672aaea40e7752eab9c270f0615a,"S. Santhanam, Tobias Hecking, A. Schreiber et al.","Bots have emerged from research prototypes to deployable systems due to the recent developments in machine learning, natural language processing and understanding techniques. In software engineering, bots range from simple automated scripts to decision-making autonomous systems. The spectrum of applications of bots in software engineering is so wide and diverse, that a comprehensive overview and categorization of such bots is needed. Existing works considered selective bots to be analyzed and failed to provide the overall picture. Hence it is significant to categorize bots in software engineering through analyzing why, what and how the bots are applied in software engineering. We approach the problem with a systematic mapping study based on the research articles published in this topic. This study focuses on classification of bots used in software engineering, the various dimensions of the characteristics, the more frequently researched area, potential research spaces to be explored and the perception of bots in the developer community. This study aims to provide an introduction and a broad overview of bots used in software engineering. Discussions of the feedback and results from several studies provide interesting insights and prospective future directions."
Software Engineering (cs.SE),2022,20,The Impact and Measurement of Today’s Learning Technologies in Teaching Software Engineering Course Using Design-Based Learning and Project-Based Learning,33,N/A,https://www.semanticscholar.org/paper/313a8f0c62dffd4dededfcea5e4a238fcade5fcf,Chetna Gupta,"Contribution: This article demonstrates the impact of today’s Information and Communication Technologies (ICT) in teaching software engineering (SE) course with design-based learning (DBL) and project-based learning (PBL). The results show a positive influence of integration of DBL and PBL in reducing industry gaps with improved student performance, engagement, and learning through designed PBL activities. Background: For an engineering graduate analysis, design, thinking, and validation of complex systems interactions is a desirable skill to support sustainability goals. A restructuring in delivery of the course through interactive lecture time and more project-based activities can improve students’ engagement, performance, and overall achievement in attaining desirable program learning outcomes (LOs). Intended Outcome: The objective is to provide student learning with an experience on how to apply critical thinking and creativity to specify, design, and validate software systems by focusing on challenges faced in the software industry. Application Design: Google classroom was used to conduct interactive class and tutorial sessions, design various PBL activities, exchange information, and work in teams. Throughout the semester, all learning and practice modules of the course were linked sequentially with intermediate milestones. Findings: The results show a positive outcome in helping students in attaining the knowledge, and understanding of both theoretical and practical concepts. These findings are based on academic results, PBL activities, and two anonymous surveys. The findings of statistical analysis suggest a positive influence of DBL and PBL in SE course to meet industry challenges, expectations, and overall course and program LOs."
Software Engineering (cs.SE),2022,13,Can pre-trained code embeddings improve model performance? Revisiting the use of code embeddings in software engineering tasks,32,N/A,https://www.semanticscholar.org/paper/a9e50a97cc7fa77ffd69a74c38cc23663506b1f6,"Zishuo Ding, Heng Li, Weiyi Shang et al.",No Abstract
Software Engineering (cs.SE),2022,17,Software-Engineering Design Patterns for Machine Learning Applications,32,N/A,https://www.semanticscholar.org/paper/490a0302116255f75d62a590177a87e301538402,"H. Washizaki, Foutse Khomh, Yann-Gaël Guéhéneuc et al.","In this study, a multivocal literature review identified 15 software-engineering design patterns for machine learning applications. Findings suggest that there are opportunities to increase the patterns’ adoption in practice by raising awareness of such patterns within the community."
Software Engineering (cs.SE),2022,10,"The Pandora's box of social, process, and people debts in software engineering",31,N/A,https://www.semanticscholar.org/paper/82e59ac183ae4ce22d30df028a7f8da9e32f7630,"M. Ahmad, Tomas Gustavsson","In software engineering, technical debt (TD) has been widely investigated, but debt regarding social issues, people, and processes has not been explored as much. It should be noted here that we use nontechnical debt (NTD) as an umbrella term to cover social, process, and people debts. Although the number of studies on NTD in software is increasing, the majority of them are descriptive rather than rigorous, and there is no systematic development of cumulative knowledge. As a result, identifying the fundamental causes of NTD and the associated mitigation techniques in software engineering is challenging. Therefore, this study investigates the scientific evidence regarding NTD till date by conducting a systematic mapping review of software engineering research between January 2000 and October 2021. The search strategy resulted in 175 studies, 17 of which were identified as unique and relevant primary papers. The primary studies show that NTD and TD are inextricably linked. In addition, this study also captured a plethora of causes and mitigation strategies for managing NTD and thus makes four important contributions: (i) highlighting state‐of‐the‐art NTD research; (ii) identification of the reported causes and mitigation strategies in the primary papers; and (iii) determination of opportunities for future NTD research."
Software Engineering (cs.SE),2022,14,A systematic mapping study of source code representation for deep learning in software engineering,31,N/A,https://www.semanticscholar.org/paper/66ae49fdc8c911062456669693071f0c61b8b735,"H. Samoaa, Firas Bayram, P. Salza et al.","The usage of deep learning (DL) approaches for software engineering has attracted much attention, particularly in source code modelling and analysis. However, in order to use DL, source code needs to be formatted to fit the expected input form of DL models. This problem is known as source code representation. Source code can be represented via different approaches, most importantly, the tree ‐ based, token ‐ based, and graph ‐ based approaches. We use a systematic mapping study to investigate i detail the representation approaches adopted in 103 studies that use DL in the context of software engineering. Thus, studies are collected from 2014 to 2021 from 14 different journals and 27 conferences. We show that each way of representing source code can provide a different, yet orthogonal view of the same source code. Thus, different software engineering tasks might require different (combinations of) code representation approaches, depending on the nature and complexity of the task. Particularly, we show that it is crucial to define whether the DL approach requires lexical, syntactical, or semantic code information. Our analysis shows that a wide range of different representations and combinations of representations (hybrid representations) are used to solve a wide range of common software engineering problems. However, we also observe that current research does not generally attempt to transfer existing representations or models to other studies even though there are other contexts in which these representations and models may also be useful. We believe that there is potential for more reuse and the application of transfer learning when applying DL to software engineering tasks."
Software Engineering (cs.SE),2022,15,Frustrations Steering Women Away From Software Engineering,31,N/A,https://www.semanticscholar.org/paper/8b841fa3ea4f28e0b69bff38aea0276c2383f4c1,"Lucia Happe, Barbora Buhnova","We share findings from a study of 139 women, revealing the frustrations they felt along their way to software engineering and pinpointing promising solutions, such as interdisciplinary education, which could be of enormous help to retaining women in computing."
Software Engineering (cs.SE),2022,18,Quantum Software Engineering,31,N/A,https://www.semanticscholar.org/paper/8936935554f19ebbf00a62b03b269b9ec03ca402,"∗. ShaukatAli, ∗. JohannaBarzen, ∗. AndreaDelgado et al.",No Abstract
Software Engineering (cs.SE),2022,16,Systematic Mapping: Artificial Intelligence Techniques in Software Engineering,30,N/A,https://www.semanticscholar.org/paper/5329f48ce81e100081bfac562e603ddd09c3077d,"Hazrina Sofian, Nur Arzilawati Md Yunus, R. Ahmad","Artificial Intelligence (AI) has become a core feature of today’s real-world applications, making it a trending topic within the software engineering (SE) community. The rise in the availability of AI techniques encompasses the capability to make rapid, automated, impactful decisions and predictions, leading to the adoption of AI techniques in SE. With industry revolution 4.0, the role of software engineering has become critical for developing productive, efficient, and quality software. Thus, there is a major need for AI techniques to be applied to enhance and improve the critical activities within the software engineering phases. Software is developed through intelligent software engineering phases. This paper concerns a systematic mapping study that aimed to characterize the publication landscape of AI techniques in software engineering. Gaps are identified and discussed by mapping these AI techniques against the SE phases to which they contributed. Many systematic mapping review papers have been produced only for a specific AI technique or a specific SE phase or activity. Hence, to our best of knowledge within the last decade, there is no systematic mapping review that has fully explored the overall trends in AI techniques and their application to all SE phases."
Software Engineering (cs.SE),2023,1,Large Language Models for Software Engineering: A Systematic Literature Review,718,2308.10620,https://www.semanticscholar.org/paper/000f964393dafe113a8e66734d63b2a145844159,"Xinying Hou, Yanjie Zhao, Yue Liu et al.","Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a Systematic Literature Review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research articles from January 2017 to January 2024 to answer four key Research Questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, pre-processing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at https://github.com/security-pride/LLM4SE_SLR."
Software Engineering (cs.SE),2023,2,Large Language Models for Software Engineering: Survey and Open Problems,348,2310.03533,https://www.semanticscholar.org/paper/4fbd174e80502f8f3c4b9f48054872b028e2445a,"Angela Fan, Beliz Gokkaya, Mark Harman et al.","This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE."
Software Engineering (cs.SE),2023,4,"Application of Large Language Models to Software Engineering Tasks: Opportunities, Risks, and Implications",162,N/A,https://www.semanticscholar.org/paper/4294a8399e549dc36b16c8f13156a0e0eb986396,Ipek Ozkaya,No Abstract
Software Engineering (cs.SE),2023,3,Navigating the Complexity of Generative AI Adoption in Software Engineering,144,2307.06081,https://www.semanticscholar.org/paper/0e41ae9360a962430650d5bb174de223aa8deea5,Daniel Russo,"This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies."
Software Engineering (cs.SE),2023,5,Towards an understanding of large language models in software engineering tasks,130,2308.11396,https://www.semanticscholar.org/paper/681f9009e22c947007b53455e9f8f22e29209010,"Zibin Zheng, Kai-Chun Ning, Jiachi Chen et al.","Large Language Models (LLMs) have drawn widespread attention and research due to their astounding performance in text generation and reasoning tasks. Derivative products, like ChatGPT, have been extensively deployed and highly sought after. Meanwhile, the evaluation and optimization of LLMs in software engineering tasks, such as code generation, have become a research focus. However, there is still a lack of systematic research on applying and evaluating LLMs in software engineering. Therefore, this paper comprehensively investigate and collate the research and products combining LLMs with software engineering, aiming to answer two questions: (1) What are the current integrations of LLMs with software engineering? (2) Can LLMs effectively handle software engineering tasks? To find the answers, we have collected related literature as extensively as possible from seven mainstream databases and selected 123 timely papers published starting from 2022 for analysis. We have categorized these papers in detail and reviewed the current research status of LLMs from the perspective of seven major software engineering tasks, hoping this will help researchers better grasp the research trends and address the issues when applying LLMs. Meanwhile, we have also organized and presented papers with evaluation content to reveal the performance and effectiveness of LLMs in various software engineering tasks, guiding researchers and developers to optimize."
Software Engineering (cs.SE),2023,6,How ChatGPT Will Change Software Engineering Education,115,N/A,https://www.semanticscholar.org/paper/c886d0e3bffa478bf5e01f2b9f4231d1d5e3fbd0,"Marian Daun, Jennifer Brings","This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning."
Software Engineering (cs.SE),2023,7,SEGRESS: Software Engineering Guidelines for REporting Secondary Studies,100,N/A,https://www.semanticscholar.org/paper/7d546e9a0b02845a2e79aedc7be30ac82d0df77f,"B. Kitchenham, L. Madeyski, D. Budgen","Context: Several tertiary studies have criticized the reporting of software engineering secondary studies. Objective: Our objective is to identify guidelines for reporting software engineering (SE) secondary studies which would address problems observed in the reporting of software engineering systematic reviews (SRs). Method: We review the criticisms of SE secondary studies and identify the major areas of concern. We assess the PRISMA 2020 (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) statement as a possible solution to the need for SR reporting guidelines, based on its status as the reporting guideline recommended by the Cochrane Collaboration whose SR guidelines were a major input to the guidelines developed for SE. We report its advantages and limitations in the context of SE secondary studies. We also assess reporting guidelines for mapping studies and qualitative reviews, and compare their structure and content with that of PRISMA 2020. Results: Previous tertiary studies confirm that reports of secondary studies are of variable quality. However, ad hoc recommendations that amend reporting standards may result in unnecessary duplication of text. We confirm that the PRISMA 2020 statement addresses SE reporting problems, but is mainly oriented to quantitative reviews, mixed-methods reviews and meta-analyses. However, we show that the PRISMA 2020 item definitions can be extended to cover the information needed to report mapping studies and qualitative reviews. Conclusions: In this paper and its Supplementary Material, we present and illustrate an integrated set of guidelines called SEGRESS (Software Engineering Guidelines for REporting Secondary Studies), suitable for quantitative systematic reviews (building upon PRISMA 2020), mapping studies (PRISMA-ScR), and qualitative reviews (ENTREQ and RAMESES), that addresses reporting problems found in current SE SRs."
Software Engineering (cs.SE),2023,12,Quantum machine learning: from physics to software engineering,91,2301.01851,https://www.semanticscholar.org/paper/fce88146673049269135617d162ffb2acffba5d1,"A. Melnikov, Mohammad Kordzanganeh, A. Alodjants et al.","ABSTRACT Quantum machine learning is a rapidly growing field at the intersection of quantum technology and artificial intelligence. This review provides a two-fold overview of several key approaches that can offer advancements in both the development of quantum technologies and the power of artificial intelligence. Among these approaches are quantum-enhanced algorithms, which apply quantum software engineering to classical information processing to improve keystone machine learning solutions. In this context, we explore the capability of hybrid quantum-classical neural networks to improve model generalization and increase accuracy while reducing computational resources. We also illustrate how machine learning can be used both to mitigate the effects of errors on presently available noisy intermediate-scale quantum devices, and to understand quantum advantage via an automatic study of quantum walk processes on graphs. In addition, we review how quantum hardware can be enhanced by applying machine learning to fundamental and applied physics problems as well as quantum tomography and photonics. We aim to demonstrate how concepts in physics can be translated into practical engineering of machine learning solutions using quantum software. GRAPHICAL ABSTRACT AI-generated image of a quantum robotic Schrödinger's cat that reads a quantum machine learning review paper."
Software Engineering (cs.SE),2023,11,Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code,89,2311.07989,https://www.semanticscholar.org/paper/f3e83c544a001f72ebd0e8131368cbf52070ab2b,"Ziyin Zhang, Chaoyu Chen, Bingchang Liu et al.","In this work we systematically review the recent advancements in software engineering with language models, covering 70+ models, 40+ evaluation tasks, 180+ datasets, and 900 related works. Unlike previous works, we integrate software engineering (SE) with natural language processing (NLP) by discussing the perspectives of both sides: SE applies language models for development automation, while NLP adopts SE tasks for language model evaluation. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also go beyond programming and review LLMs' application in other software engineering activities including requirement engineering, testing, deployment, and operations in an endeavor to provide a global view of NLP in SE, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on GitHub at https://github.com/codefuse-ai/Awesome-Code-LLM."
Software Engineering (cs.SE),2023,10,The Scope of ChatGPT in Software Engineering: A Thorough Investigation,77,N/A,https://www.semanticscholar.org/paper/4de51b343e703e1d07d78952c8b21d608f5ad7f2,"Wei Ma, Shangqing Liu, Wenhan Wang et al.",No Abstract
Software Engineering (cs.SE),2023,18,A Critical Review of Large Language Model on Software Engineering: An Example from ChatGPT and Automated Program Repair,76,2310.08879,https://www.semanticscholar.org/paper/b33ee4c8c707db84fc0cf8176a9d8e3ae69e3378,"Quanjun Zhang, Tongke Zhang, Juan Zhai et al.","Large Language Models (LLMs) have been gaining increasing attention and demonstrated promising performance across a variety of Software Engineering (SE) tasks, such as Automated Program Repair (APR), code summarization, and code completion. For example, ChatGPT, the latest black-box LLM, has been investigated by numerous recent research studies and has shown impressive performance in various tasks. However, there exists a potential risk of data leakage since these LLMs are usually close-sourced with unknown specific training details, e.g., pre-training datasets. In this paper, we seek to review the bug-fixing capabilities of ChatGPT on a clean APR benchmark with different research objectives. We first introduce {\benchmark}, a new benchmark with buggy and the corresponding fixed programs from competitive programming problems starting from 2023, after the training cutoff point of ChatGPT. The results on {\benchmark} show that ChatGPT is able to fix 109 out of 151 buggy programs using the basic prompt within 35 independent rounds, outperforming state-of-the-art LLMs CodeT5 and PLBART by 27.5\% and 62.4\% prediction accuracy. We also investigate the impact of three types of prompts, i.e., problem description, error feedback, and bug localization, leading to additional 34 fixed bugs. Besides, we provide additional discussion from the interactive nature of ChatGPT to illustrate the capacity of a dialog-based repair workflow with 9 additional fixed bugs. Inspired by the findings, we further pinpoint various challenges and opportunities for advanced SE study equipped with such LLMs (e.g.,~ChatGPT) in the near future. More importantly, our work calls for more research on the reevaluation of the achievements obtained by existing black-box LLMs across various SE tasks, not limited to ChatGPT on APR."
Software Engineering (cs.SE),2023,9,A Survey on Large Language Models for Software Engineering,75,2312.15223,https://www.semanticscholar.org/paper/a79f6474f0bec1cf0501e48dfc7b2b36cf7338dc,"Quanjun Zhang, Chunrong Fang, Yang Xie et al.","Software Engineering (SE) is the systematic design, development, maintenance, and management of software applications underpinning the digital infrastructure of our modern world. Very recently, the SE community has seen a rapidly increasing number of techniques employing Large Language Models (LLMs) to automate a broad range of SE tasks. Nevertheless, existing information of the applications, effects, and possible limitations of LLMs within SE is still not well-studied. In this paper, we provide a systematic survey to summarize the current state-of-the-art research in the LLM-based SE community. We summarize 62 representative LLMs of Code across three model architectures, 15 pre-training objectives across four categories, and 16 downstream tasks across five categories. We then present a detailed summarization of the recent SE studies for which LLMs are commonly utilized, including 947 studies for 112 specific code-related tasks across five crucial phases within the SE workflow. We also discuss several critical aspects during the integration of LLMs into SE, such as empirical evaluation, benchmarking, security and reliability, domain tuning, compressing and distillation. Finally, we highlight several challenges and potential opportunities on applying LLMs for future SE studies, such as exploring domain LLMs and constructing clean evaluation datasets. Overall, our work can help researchers gain a comprehensive understanding about the achievements of the existing LLM-based SE studies and promote the practical application of these techniques. Our artifacts are publicly available and will be continuously updated at the living repository: https://github.com/iSEngLab/AwesomeLLM4SE."
Software Engineering (cs.SE),2023,8,Prompt Engineering or Fine Tuning: An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks,69,N/A,https://www.semanticscholar.org/paper/59e0e0c1aa06d51430792eb5d8308911a1b0110f,"Jiho Shin, Clark Tang, Tahmineh Mohati et al.",No Abstract
Software Engineering (cs.SE),2023,13,Trustworthy and Synergistic Artificial Intelligence for Software Engineering: Vision and Roadmaps,56,2309.04142,https://www.semanticscholar.org/paper/30c4271ac929af5c5c3b4f5afba8e0beb215138e,David Lo,"For decades, much software engineering research has been dedicated to devising automated solutions aimed at enhancing developer productivity and elevating software quality. The past two decades have witnessed an unparalleled surge in the development of intelligent solutions tailored for software engineering tasks. This momentum established the Artificial Intelligence for Software Engineering (AI4SE) area, which has swiftly become one of the most active and popular areas within the software engiueering field. This Future of Software Engineering (FoSE) paper navigates through several focal points. It commences with a succinct introduction and history of AI4SE. Thereafter, it underscores the core challenges inherent to AI4SE, particularly highlighting the need to realize trustworthy and synergistic AI4SE. Progressing, the paper paints a vision for the potential leaps achievable if AI4SE's key challenges are surmounted, suggesting a transition toward Software Engineering 2.0. Two strategic roadmaps are then laid out: one centered on realizing trustworthy AI4SE, and the other on fostering synergistic AI4SE. While this paper may not serve as a conclusive guide, its intent is to catalyze further progress. The ultimate aspiration is to position AI4SE as a linchpin in redefining the horizons of software engineering, propelling us toward Software Engineering 2.0."
Software Engineering (cs.SE),2023,14,"A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions",56,2305.00237,https://www.semanticscholar.org/paper/a0dca1c35f698b7b7af91449427ed035d9e4e049,"Mohammad Fraiwan, Natheer Khasawneh","ChatGPT is a type of artificial intelligence language model that uses deep learning algorithms to generate human-like responses to text-based prompts. The introduction of the latest ChatGPT version in November of 2022 has caused shockwaves in the industrial and academic communities for its powerful capabilities, plethora of possible applications, and the great possibility for abuse. At the time of writing this work, several other language models (e.g., Google Bard and Meta LLaMA) just came out in an attempt to get a foothold in the vast possible market. These models have the ability to revolutionize the way we interact with computers and have potential applications in many fields, including education, software engineering, healthcare, and marketing. In this paper, we will discuss the possible applications, drawbacks, and research directions using advanced language Chatbots (e.g., ChatGPT) in each of these fields. We first start with a brief introduction and the development timeline of artificial intelligence based language models, then we go through possible applications of such models, after that we discuss the limitations and drawbacks of the current technological state of the art, and finally we point out future possible research directions."
Software Engineering (cs.SE),2023,15,"Large Language Model Assisted Software Engineering: Prospects, Challenges, and a Case Study",50,N/A,https://www.semanticscholar.org/paper/e7b7ba8689cd200083ac07c66e1898d71aff46b1,"Lenz Belzner, Thomas Gabor, M. Wirsing",No Abstract
Software Engineering (cs.SE),2023,16,ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks,50,2305.16837,https://www.semanticscholar.org/paper/49f8a40aea0e945bd8b15019a3e4b1bb1c9279ea,"G. Sridhara, Ranjani H.G., Sourav Mazumdar","ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by OpenAI on November 30, 2022. OpenAI's GPT-3 family of large language models serve as the foundation for ChatGPT. ChatGPT is fine-tuned with both supervised and reinforcement learning techniques and has received widespread attention for its articulate responses across diverse domains of knowledge. In this study, we explore how ChatGPT can be used to help with common software engineering tasks. Many of the ubiquitous tasks covering the breadth of software engineering such as ambiguity resolution in software requirements, method name suggestion, test case prioritization, code review, log summarization can potentially be performed using ChatGPT. In this study, we explore fifteen common software engineering tasks using ChatGPT. We juxtapose and analyze ChatGPT's answers with the respective state of the art outputs (where available) and/or human expert ground truth. Our experiments suggest that for many tasks, ChatGPT does perform credibly and the response from it is detailed and often better than the human expert output or the state of the art output. However, for a few other tasks, ChatGPT in its present form provides incorrect answers and hence is not suited for such tasks."
Software Engineering (cs.SE),2023,17,Machine/Deep Learning for Software Engineering: A Systematic Literature Review,49,N/A,https://www.semanticscholar.org/paper/0fc64af26a442735c704ae094107fc6b090811f8,"Simin Wang, LiGuo Huang, Amiao Gao et al.","Since 2009, the deep learning revolution, which was triggered by the introduction of ImageNet, has stimulated the synergy between Software Engineering (SE) and Machine Learning (ML)/Deep Learning (DL). Meanwhile, critical reviews have emerged that suggest that ML/DL should be used cautiously. To improve the applicability and generalizability of ML/DL-related SE studies, we conducted a 12-year Systematic Literature Review (SLR) on 1,428 ML/DL-related SE papers published between 2009 and 2020. Our trend analysis demonstrated the impacts that ML/DL brought to SE. We examined the complexity of applying ML/DL solutions to SE problems and how such complexity led to issues concerning the reproducibility and replicability of ML/DL studies in SE. Specifically, we investigated how ML and DL differ in data preprocessing, model training, and evaluation when applied to SE tasks, and what details need to be provided to ensure that a study can be reproduced or replicated. By categorizing the rationales behind the selection of ML/DL techniques into five themes, we analyzed how model performance, robustness, interpretability, complexity, and data simplicity affected the choices of ML/DL models."
Software Engineering (cs.SE),2023,19,A systematic literature review of capstone courses in software engineering,40,2301.03554,https://www.semanticscholar.org/paper/64a4016621e85ea76e2be70f66a8d880759faba7,"Saara Tenhunen, T. Männistö, Matti Luukkainen et al.","Tertiary education institutions aim to prepare their computer science and software engineering students for working life. While much of the technical principles are covered in lower-level courses, team-based capstone projects are a common way to provide students with hands-on experience and teach soft skills. This paper explores the characteristics of software engineering capstone courses presented in the literature. The goal of this work is to understand the pros and cons of different approaches by synthesising the various aspects of software engineering capstone courses and related experiences. In a systematic literature review for 2007-2022, we identified 127 primary studies. These studies were analysed based on their presented course characteristics and the reported course outcomes. The characteristics were synthesised into a taxonomy consisting of duration, team sizes, client and project sources, project implementation, and student assessment. We found out that capstone courses generally last one semester and divide students into groups of 4-5 where they work on a project for a client. For a slight majority of courses, the clients are external to the course staff and students are often expected to produce a proof-of-concept level software product as the main end deliverable. The courses also offer versatile assessments for students throughout the project. This paper provides researchers and educators with a classification of characteristics of software engineering capstone courses based on previous research. We further synthesise insights on the reported outcomes of capstone courses. Our review study aims to help educators to identify various ways of organising capstones and effectively plan and deliver their own capstone courses. The characterisation also helps researchers to conduct further studies on software engineering capstones."
Software Engineering (cs.SE),2023,20,Ethical Aspects of ChatGPT in Software Engineering Research,34,2306.07557,https://www.semanticscholar.org/paper/0a5f818915de233b1ce8262a47e78290c84af866,"M. Akbar, A. Khan, Peng Liang","ChatGPT can improve software engineering (SE) research practices by offering efficient, accessible information analysis, and synthesis based on natural language interactions. However, ChatGPT could bring ethical challenges, encompassing plagiarism, privacy, data security, and the risk of generating biased or potentially detrimental data. This research aims to fill the given gap by elaborating on the key elements: motivators, demotivators, and ethical principles of using ChatGPT in SE research. To achieve this objective, we conducted a literature survey, identified the mentioned elements, and presented their relationships by developing a taxonomy. Furthermore, the identified literature-based elements (motivators, demotivators, and ethical principles) were empirically evaluated by conducting a comprehensive questionnaire-based survey involving SE researchers. In addition, we employed an interpretive structure modeling approach to analyze the relationships between the ethical principles of using ChatGPT in SE research and develop a level-based decision model. We further conducted a cross-impact matrix multiplication applied to classification analysis to create a cluster-based decision model. These models aim to help SE researchers devise effective strategies for ethically integrating ChatGPT into SE research by following the identified principles by adopting the motivators and addressing the demotivators. The findings of this study will establish a benchmark for incorporating ChatGPT services in SE research with an emphasis on ethical considerations."
